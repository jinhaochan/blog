
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/font-awesome/css/font-awesome.min.css">







<meta name="author" content="Chan Jin Hao" />
<meta name="description" content="I&#39;m branching out my learning into Data Science, mostly from Kaggle. You&#39;ll find my Kaggle kernels here. Predicting Taxi Fare https://www.kaggle.com/c/new-york-city-taxi-fare-prediction Notebook: https://github.com/Chan Jin Hao/TaxiFare/blob/master/Taxi%20Fares.ipynb RMSE: 3.88522 Model: XGBoost In this problem, I was supposed …" />
<meta name="keywords" content="">

<meta property="og:site_name" content="glob"/>
<meta property="og:title" content="Kaggle Data Science"/>
<meta property="og:description" content="I&#39;m branching out my learning into Data Science, mostly from Kaggle. You&#39;ll find my Kaggle kernels here. Predicting Taxi Fare https://www.kaggle.com/c/new-york-city-taxi-fare-prediction Notebook: https://github.com/Chan Jin Hao/TaxiFare/blob/master/Taxi%20Fares.ipynb RMSE: 3.88522 Model: XGBoost In this problem, I was supposed …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/datascience.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-10-31 22:11:00+08:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/chan-jin-hao.html">
<meta property="article:section" content="misc"/>
<meta property="og:image" content="">

  <title>glob &ndash; Kaggle Data Science</title>

</head>
<body>
  <aside>
    <div>
      <a href="">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>


      <nav>
        <ul class="list">

          <li><a href="/">All</a></li>
          <li><a href="/category/data-science.html">Data Science</a></li>
          <li><a href="/category/security.html">Cyber Security</a></li>
          <li><a href="/category/software-engineering.html">Software Engineering</a></li>
          <li><a href="/category/review.html">Book Reviews</a></li>
          <li><a href="/category/ramblings.html">Ramblings</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-linkedin" href="https://www.linkedin.com/in/jinhao-hao-chan-162630120/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-github" href="https://www.github.com/jinhaochan" target="_blank"><i class="fa fa-github"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>


<article class="single">
  <header>
      
    <h1 id="datascience">Kaggle Data Science</h1>
    <p>
          Posted on Wed 31 October 2018 in <a href="/category/misc.html">misc</a>


        &#8226; 2 min read
    </p>
  </header>


  <div>
    <p>I'm branching out my learning into Data Science, mostly from Kaggle.</p>
<p>You'll find my Kaggle kernels here.</p>
<h2>Predicting Taxi Fare</h2>
<hr>
<p><a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction">https://www.kaggle.com/c/new-york-city-taxi-fare-prediction</a></p>
<p>Notebook: <a href="https://github.com/Chan Jin Hao/TaxiFare/blob/master/Taxi%20Fares.ipynb">https://github.com/Chan Jin Hao/TaxiFare/blob/master/Taxi%20Fares.ipynb</a></p>
<p><strong>RMSE: 3.88522</strong></p>
<p><strong>Model: XGBoost</strong></p>
<p>In this problem, I was supposed to predict taxi fares in NYC. It can be modeled as a regression problem.</p>
<p>There was a lot of data cleaning to do, with many odd numbered features such as passenger size, and coordinates on the water.</p>
<p>Without the airport features, my model has an RMSE of 4.14398. After adding in those features, it drastically dropped to 3.88522. Those are some really strong features!</p>
<h2>Movie Sentiment Analysis</h2>
<hr>
<p><a href="https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only">https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only</a><a href="https://www.kaggle.com/earthshaker/lstm-cnn-glove-bidirectional-gru-aggregation"></a></p>
<p>Notebook: <a href="https://github.com/Charmanderander/SentimentAnalysis/blob/master/sentanalysis.ipynb">https://github.com/Chan Jin Hao/SentimentAnalysis/blob/master/sentanalysis.ipynb</a></p>
<p><strong>Accuracy: 0.65095</strong></p>
<p><strong>Model: Ensemble by Voting</strong></p>
<p>In this problem, we were given a collection of phrases, which were broken down from sentences. Instead of predicting the sentiment for each sentence, we had to predict the sentiment for each phrase.</p>
<p>The pre-processing steps I did were</p>
<!-- wp:list {"ordered":true} -->

<ol>
<li>Lower casing</li>
<li>Removing non alphabets</li>
<li>Lemmatization</li>
</ol>
<p>The final output for each phrase was then chosen by voting from all the models.</p>
<!-- wp:list {"ordered":true} -->

<ol>
<li>LSTM</li>
<li>CNN</li>
<li>Glove Transfer-Learning with Bidirectional GRU</li>
</ol>
<p>Interestingly enough, Glove + CNN performs poorer than just CNN. This may be because the word vectors trained in Glove were in a different context (i.e. not Movie Sentiment Analysis)</p>
<h2>Predicting Future Sales</h2>
<hr>
<p><a href="https://www.kaggle.com/c/competitive-data-science-predict-future-sales">https://www.kaggle.com/c/competitive-data-science-predict-future-sales</a></p>
<p>Notebook: <a href="https://github.com/Charmanderander/salesforcast/blob/master/saleforecast.ipynb">https://github.com/Chan Jin Hao/salesforcast/blob/master/saleforecast.ipynb</a></p>
<p><strong>RMSE: 1.16462</strong></p>
<p><strong>Model: LSTM + GRU</strong></p>
<p>In this competition, we had to predict what the next month's sale was for each item for each shop.</p>
<p>The data given to us was daily sales for each item, so we had to do some data aggregation to convert it to a monthly sales value.</p>
<p>We were given 33 months of training data, so I modeled it to a time series problem.</p>
<p>For training, months 0 - 32 was the training data, and month 33 was the target value.</p>
<p>For testing, months 1 - 33 was the testing data, and we need to predict the values for month 34.</p>
<p>The model I used was a 2 layer GRU using a dropout layer of 0.3  </p>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>





</article>

    <footer>
<p>&copy;  </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " glob ",
  "url" : "",
  "image": "",
  "description": ""
}
</script>

</body>
</html>