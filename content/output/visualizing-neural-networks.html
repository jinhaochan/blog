<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Visualizing Neural Networks</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="A Pelican Blog Atom Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">A Pelican Blog </a></h1>
                <nav><ul>
                    <li><a href="/category/book-review.html">Book Review</a></li>
                    <li class="active"><a href="/category/data-science.html">Data Science</a></li>
                    <li><a href="/category/misc.html">misc</a></li>
                    <li><a href="/category/ramblings.html">Ramblings</a></li>
                    <li><a href="/category/review.html">Review</a></li>
                    <li><a href="/category/security.html">Security</a></li>
                    <li><a href="/category/software-engineering.html">Software Engineering</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/visualizing-neural-networks.html" rel="bookmark"
           title="Permalink to Visualizing Neural Networks">Visualizing Neural Networks</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2019-05-19T09:31:00+00:00">
                Published: Sun 19 May 2019
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/jinhaochan.html">jinhaochan</a>
        </address>
<p>In <a href="/category/data-science.html">Data Science</a>.</p>

</footer><!-- /.post-info -->      <p>Neural Networks have always been sort of a black box when it comes to it's implementation, and how it produces good results. I came across some material that shows visually, how the neural networks morph the problem space so that they are separable.</p>
<!-- wp:heading {"level":3} -->

<h3>Simple Data</h3>
<hr>
<p>Here's a sample graph that is not linearly separable:</p>
<!-- wp:image {"id":302,"align":"center","width":284,"height":277} -->

<p><img alt="placeholder" class="wp-image-302" height="277" src="/media/2019/02/simple2_data.png" width="284"></p>
<p>When we try to use a linear model to discriminate the two data, we get a poorly separated model:</p>
<!-- wp:image {"id":303,"align":"center","width":278,"height":271} -->

<p><img alt="placeholder" class="wp-image-303" height="271" src="/media/2019/02/simple2_linear.png" width="278"></p>
<p>Neural Networks, with the interactions of their hidden layers and nodes, are able to learn more complex information about the graph to plot a non-linear separation:</p>
<!-- wp:image {"id":304,"align":"center","width":270,"height":263} -->

<p><img alt="placeholder" class="wp-image-304" height="263" src="/media/2019/02/simple2_0.png" width="270"></p>
<p>What a Neural Networks does is that it warps the space of the problem so that it becomes more separable. The hidden layers in the network transforms the problem space by representing it in a different way</p>
<!-- wp:image {"id":305,"align":"center","width":281,"height":274} -->

<p><img alt="placeholder" class="wp-image-305" height="274" src="/media/2019/02/simple2_1.png" width="281"></p>
<p>By warping the problem space with the hidden layers, we see that it's able to linearly separate the two distributions. That's pretty cool! So what the neural network is doing is finding the most optimal way to represent the problem that is discriminative.</p>
<p>So what happens if the data distribution is too complex, or your neural network model is too simple (too shallow) that it can't properly represent the data?</p>
<!-- wp:heading {"level":3} -->

<h3>Spiral Data</h3>
<hr>
<p>Given a complex data set that resembles a spiral shape, and a neural network model that is too simple, we can see it struggling to find a representation that is separable. This means that there is not enough hidden layers and hidden nodes to transform the data. We need to go deeper!</p>
<!-- wp:image {"id":308,"align":"center","width":364,"height":355} -->

<p><img alt="placeholder" class="wp-image-308" height="355" src="/media/2019/02/spiral.2.2-2-2-2-2-2-2.gif" width="364"></p>
<p>Here's the same spiral graph, but with enough hidden layers and nodes to transform the spiral data to a separable space. We can see the model separating the data very clearly</p>
<!-- wp:image {"id":307,"align":"center","width":344,"height":336} -->

<p><img alt="placeholder" class="wp-image-307" height="336" src="/media/2019/02/spiral.1-2.2-2-2-2-2-2-1.gif" width="344"></p>
<!-- wp:heading {"level":3} -->

<h3>More Complex Data</h3>
<hr>
<p>In the last example, we see a more complex example, and see how a neural network can separate the data.</p>
<!-- wp:image {"id":309,"align":"center","width":376,"height":283} -->

<p><img alt="placeholder" class="wp-image-309" height="283" src="/media/2019/02/topology_base.png" width="376"></p>
<p>Given a circular topology data, a shallow neural network will have difficulties trying to separate the data from the inside and outer ring. We see it trying to pull apart the data like how it did with the spiral data, but it fails to do so</p>
<!-- wp:image {"id":310,"align":"center","width":351,"height":343} -->

<p><img alt="placeholder" class="wp-image-310" height="343" src="/media/2019/02/topology_2d-2d_train.gif" width="351"></p>
<p>By introducing more hidden layers and nodes and going deeper, we see that the data is able to be extracted out into another dimension, making it separable!  </p>
<!-- wp:image {"id":311} -->

<p><img alt="placeholder" class="wp-image-311" src="/media/2019/02/topology_3d.png"></p>
<!-- wp:heading {"level":3} -->

<h3>Conclusion</h3>
<hr>
<p>In this post, I wanted to show how neural networks warp the space of the data make them separable, and how a shallow network might fail to perform well.</p>
<p>By adding more hidden layers and nodes, we are able to morph and warp the space into different dimensions, representing them differently and making them discriminative</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>