<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog</title><link href="/" rel="alternate"></link><link href="/feeds/all-en.atom.xml" rel="self"></link><id>/</id><updated>2019-09-23T14:16:00+00:00</updated><entry><title>DNSSEC</title><link href="/dnssec.html" rel="alternate"></link><published>2019-09-23T14:16:00+00:00</published><updated>2019-09-23T14:16:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-09-23:/dnssec.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the previous post, we talked about some of the attack vectors on the DNS. In this post, we're going to be talking about DNSSEC, which is an attempt to make the DNS more secure.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A point to note, DNSSEC does not provide Confidentiality, but only Integrity. Integrity in this …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the previous post, we talked about some of the attack vectors on the DNS. In this post, we're going to be talking about DNSSEC, which is an attempt to make the DNS more secure.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A point to note, DNSSEC does not provide Confidentiality, but only Integrity. Integrity in this case is ensuring that the reply that you received from the DNS is truly the reply, and not altered by any MITM means. The lack of Confidentiality is due to the fact that it does not encrypt your DNS traffic data, and all your queries are still exposed in plain text. These are several technologies out there now that are branching out into encryption of DNS data, named DNS over HTTPS (DoH). But for DNSSEC, there is no encryption.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This post assumes you have knowledge of recursive DNS resolving of hostnames.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNSSEC introduces several new resources that are used by the DNSSEC verification process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;RRSIG (Resource Record Signature)&lt;/li&gt;
&lt;li&gt;DNSKEY (Public Key for Verification)&lt;/li&gt;
&lt;li&gt;DS (Delegation Signer)&lt;/li&gt;
&lt;li&gt;NSEC (Proof of Nonexistence - No encryption)&lt;/li&gt;
&lt;li&gt;NSEC3 ( Proof of Nonexistence - Encryption)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We'll go through each one of them, and explain how they are being used in the verification process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;RRSIG&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;With DNSSEC, every reply comes with at least one RRSIG reply. RRSIG acts like a digital certification, to verify that this reply is indeed authentic.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;DNSKEY&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNSSEC operates on asymmetric encryption, and DNSKEY is the public key. The RRSIG is encrypted with the private key, and verification of the response is done by decrypting it with DNSKEY.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;DS&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;During the recursive DNS resolution process, the parent has to verify the authenticity of the child server. This is done by signing the hash of the child. The parent becomes the Delegation Signing (DS) of the child&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;NSEC/NSEC3&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Without DNSSEC, non-existent domains are return with NXDOMAIN. With DNSSEC, non-existent domains are handled by NSEC and NSEC3 records to prove that they really don't exist. NSEC3 is the encrypted version of NSEC. We'll talk about this in a section later below.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Difference in DNS lookup with DNSSEC&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;p&gt;&lt;img alt="DNS resolution with DNSSEC" src="/media/2019/09/untitled-1.png"&gt;&lt;/p&gt;
&lt;p&gt;Up front, you can see that there is an additional layer called the Validating Resolver, which handles the DNSSEC process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The recursive DNS resolution to obtain the IP address of isc.org still remains the same (asking &lt;code&gt;.&lt;/code&gt;, &lt;code&gt;.org&lt;/code&gt; and &lt;code&gt;isc.org&lt;/code&gt;). We start the phase above when we finally get the address of the authoritative server for the address of &lt;code&gt;isc.org&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Ask the authoritative server for the IP address of &lt;code&gt;isc.org&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reply the IP address of &lt;code&gt;isc.org&lt;/code&gt;. Also, send the encrypted RRSIG&lt;/li&gt;
&lt;li&gt;Ask for the public DNSKEY of &lt;code&gt;isc.org&lt;/code&gt; to verify the RRSIG obtained in step 2&lt;/li&gt;
&lt;li&gt;Reply with the DNSKEY to decrypt the RRSIG, and verify the reply from &lt;code&gt;isc.org&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.org&lt;/code&gt; is the parent of &lt;code&gt;isc.org&lt;/code&gt;, and thus is the DS of &lt;code&gt;isc.org&lt;/code&gt;. As part of the DNSSEC process, &lt;code&gt;isc.org&lt;/code&gt; has to the hash of it's DNSKEY to &lt;code&gt;.org&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The hash of the child's DNSKEY is signed by the parent's DNSKEY&lt;/li&gt;
&lt;li&gt;i.e. the hash of &lt;code&gt;isc.org&lt;/code&gt; DNSKEY is signed by &lt;code&gt;.org&lt;/code&gt; DNSKEY&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ask for the hash of &lt;code&gt;isc.org&lt;/code&gt; DNSKEY, and ensure that the DNSKEY obtained in step 4 is correct&lt;/li&gt;
&lt;li&gt;Reply with the hash of &lt;code&gt;isc.org&lt;/code&gt; DNSKEY, along with the RRSIG of &lt;code&gt;.org&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Ask for the public DNSKEY of &lt;code&gt;.org&lt;/code&gt; to verify the RRSIG obtained in step 6&lt;/li&gt;
&lt;li&gt;Reply with the DNSKEY to decrypt the RRSIG, and verify the reply from &lt;code&gt;.org&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ask for the hash of &lt;code&gt;.org&lt;/code&gt; DNSKEY, and ensure that the DNSKEY obtained in step 8 is correct&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reply with the hash of &lt;code&gt;.org&lt;/code&gt; DNSKEY, along with the RRSIG of the root server&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ask for the public DNSKEY of the root server to verify the RRSIG obtained in step 10&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reply with the DNSKEY to decrypt the RRSIG, and verify the reply from the root server&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You can see the pattern of these 4 sets of communication repeating. I've bolded steps 9, 10, 11, 12, as they are the same steps being repeated for each recursive step of DNS resolution.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;These Are Not The Records You're Looking For&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The typical response from a DNS server when a non-existent domain is requested is returning an &lt;code&gt;NXDOMAIN&lt;/code&gt; response. However, a simple &lt;code&gt;NXDOMAIN&lt;/code&gt; will not suffice, as an attacker can simply spoof this reply to deny services to customers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;With DNSSEC implemented, instead of using an &lt;code&gt;NXDOMAIN&lt;/code&gt; to indicate a non-existent record, we use NSEC as a proof of non-existence. NSEC stands for Next-Secure-Record, and a gist of how it works is by providing information above records before and after the requested domain.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For NSEC to work, the records need to be sorted alphabetically so that by showing the previous and next record, we can determine if the request domain does not exist.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;An example of this in action: We have 3 employees working at a company: Alice, Edward and Susan (already sorted alphabetically). When some one calls and asks for an employee called Bob (which doesn't exist), NSEC will reply the previous and next records (alphabetically), Alice and Edward.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can see an obvious problem over here. Probe for many non-existent domains, and NSEC will return to you all of the records in the DNS, something which we don't want. This act is called zone-walking, or zone enumeration.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The solution to zone walking is simply to encrypt the information being sent over, which is what is implemented in NSEC3. NSEC3 hashes the entries before sending the data over to the requesting machine&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Credits&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This post was a summary of this guide by ISC: &lt;a href="https://downloads.isc.org/isc/dnssec-guide/dnssec-guide.pdf"&gt;https://downloads.isc.org/isc/dnssec-guide/dnssec-guide.pdf&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The above documentation is a lot more comprehensive, and this post is meant to highlight content that is important.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="DNSSEC"></category></entry><entry><title>DNS Attack Vectors</title><link href="/dns-attack-vectors.html" rel="alternate"></link><published>2019-07-07T14:50:00+00:00</published><updated>2019-07-07T14:50:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-07-07:/dns-attack-vectors.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before looking at DNS Attack Vectors, let's do a quick recap of what a DNS is, and what are it's functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is a DNS?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;DNS, or Domain Name System, is a server that provides Name to IP Address resolution. When people visit websites, it's much easier for them to …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before looking at DNS Attack Vectors, let's do a quick recap of what a DNS is, and what are it's functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is a DNS?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;DNS, or Domain Name System, is a server that provides Name to IP Address resolution. When people visit websites, it's much easier for them to remember words, such as Facebook or Hotmail, and the DNS server translates these URLs to IP address such as 73.22.512.31.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Machines in a network, and groups of networks references a DNS server which manages a huge database of domain names to IP addresses. The act of mapping a domain name to an IP is called &lt;code&gt;DNS Name Resolution&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When you connect to a home or business network, the service providers that assign your IP address also sends network configurations that includes 1 or more DNS servers that the device should use to perform DNS Name Resolution.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNS traffic takes place on port 53, and has both TCP and UDP protocols&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;DNS Attacks&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Now that we have a rough idea of what a DNS does, lets look at the attack vectors that can target DNS servers&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;1. DNS Tunneling&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNS tunneling is a method of attack that encodes data of programs into DNS queries and responses&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The malicious actor must first own a domain name, and his own local DNS server. In this example, we have the domain &lt;code&gt;server1.test.com&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The typical steps of a DNS tunneling attack is as follows:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Client sends out a DNS Name Resolution request to the DNS server, but the domain is modified to contain pieces of data: &lt;code&gt;MYDATA.server1.test.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The DNS server does the IP address resolution of &lt;code&gt;server1.test.com&lt;/code&gt;, and sends the modified request to that server&lt;/li&gt;
&lt;li&gt;The information of &lt;code&gt;MYDATA.server1.test.com&lt;/code&gt; is forwarded to the malicious server&lt;/li&gt;
&lt;li&gt;The bad actor can inspect the packets to view information from the DNS queries, thus achieving data exfiltration&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNS tunneling takes advantage of the fact that domain names are allowed up to 255 characters, but most domain names typically do not go that long. The additional data can thus be appended into the unused character space&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;2. DNS Cache Poisoning&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNS cache poisoning is an attack that corrupts the DNS cache so that when DNS Name Resolution is done, it points to a malicious IP address instead of the legitimate one.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The internet has more than one DNS servers for name resolution, and DNS servers would cache information from other DNS servers for efficiency in querying. Your machine also has a local DNS cache which performs a quick lookup, instead of performing DNS Name Resolution again.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;3. DNS Zone Transfer Attack&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A legitimate DNS Zone Transfer occurs when a slave DNS server requests for information from the master DNS server to update it's DNS records&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;DNS Zone Transfers are performed by TCP protocols to ensure lossless data transfer.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Bad actors can leverage on this to pose as a slave DNS server, and download all information from the master DNS server, thus revealing information about the network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;4. DNS Domain Lock-Up&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Domains are setup by attackers. When the target DNS server sends a request to one of the malicious Domains, the domains don't send the proper reply to end the connection, but instead send random junk to keep the TCP connection to the DNS alive.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When enough connections are kept alive, this exhausts the DNS resources to perform further Name Resolutions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;5. DNS Water Torture Attack and NXDomain (Non-Existent Domain)&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When requests with invalid domain names are sent to the DNS server, the DNS server replies with NXDomain, which indicates that the domain names are not valid.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The DNS stores all these queries and NXDomain responses in the cache, and if these requests happens on a large scale, it can flood the cache, thus preventing further Name Resolutions from happening. This essentially is a DDoS on DNS servers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This attack is analogous to a MAC flooding attack, which fills up the cache with bogus MAC addresses.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>LSTM</title><link href="/lstm.html" rel="alternate"></link><published>2019-06-30T15:33:00+00:00</published><updated>2019-06-30T15:33:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-30:/lstm.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the previous post, we talked about RNN, and how performing Backpropagation through time (BPTT) on an unrolled RNN with many time steps can lead to the problems of vanishing / exploding gradients, and difficulties in learning long term dependencies.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to look at a the LSTM …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the previous post, we talked about RNN, and how performing Backpropagation through time (BPTT) on an unrolled RNN with many time steps can lead to the problems of vanishing / exploding gradients, and difficulties in learning long term dependencies.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to look at a the LSTM (Long Short Term Memory) model that is a variant of an RNN, but is designed specifically to combat the 2 issues.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;LSTM Structure&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Lets visually inspect the difference between a normal RNN cell and an LSTM cell.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":362} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-simplernn.png){.wp-image-362}

&lt;figcaption&gt;
An unrolled RNN cell

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:image {"id":356} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-chain.png){.wp-image-356}

&lt;figcaption&gt;
An unrolled LSTM cell

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The A on each of the cells represent the Activation in the cell. In the RNN, this can either be a Sigmoid, tanh, ReLU, or other activation functions. In the LSTM however, its a combination of 3 Sigmoids and a tanh function.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The biggest difference, aside from the more complex internal structure of the LSTM, is that it has two connecting data pipelines from cell to cell.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Cell State&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The top line of an LSTM cell represents the cell state&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":357,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/lstm3-c-line.png){.wp-image-357}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The LSTM has the ability to modify the cell state by removing information (through the multiplicative forget gate), or adding information (through the additive input gate)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This data flow from cell to cell is modified by two operators: The multiplication operator, and the addition operator denoted by the two pink nodes&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;LSTM Gates&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The LSTM has 3 gates in the cell:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Forget Gate&lt;/li&gt;
&lt;li&gt;Input gate&lt;/li&gt;
&lt;li&gt;Output Gate&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These gates modify the data that is flowing in and out of the LSTM cell&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;The Common Sigmoid Layer&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In all the 3 gates, there exists the common Sigmoid layer. This layer outputs a value from 0 to 1 for each state in the cell state.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":365,"align":"center","width":87,"height":106} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/03/lstm3-gate.png){.wp-image-365 width="87" height="106"}  
&lt;figcaption&gt;
The common Sigmoid layer in all 3 gates
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Sigmoid layer outputs a value from 0 to 1. This value corresponds to a value in the cell state, and this would mean different things for different gates.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the Forget gate, 0 would mean forget the value in the cell state, and 1 would mean remember the value entirely.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the Input gate, 0 would mean do not update this value at all, and 1 would mean update the value entirely.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the Output gate, 0 would mean do not output this cell state value, and 1 would mean output this value entirely.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Forget Gate&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The first gate is the forget gate. This gate decides what information to discard from the cell state.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This gate has the Sigmoid activation function. It takes in the previous time step's output, and the current time step input.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":359} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-focus-f.png){.wp-image-359}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The two inputs are concatenated, and passed through the Sigmoid layer.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Recall that a Sigmoid activation function outputs a value from 0 to 1. A value of 0 means completely forget this input value, while 1 means to remember the value entirely.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Input Gate&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The next gate is the input gate, which is a combination of both the Sigmoid and tanh activation function. This gate decides what new information to add to the cell state.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":360} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-focus-i.png){.wp-image-360}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are two steps in the input gate phase&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the first step, the output of the previous time step and the input of the current time step are concatenated together, and passed into a Sigmoid. This layer decides which cell state values to update. (0 means do not update, 1 means update entirely)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The inputs are also passed into a tanh activation function, which tells the model what to update the cells states with.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The multiplicative combination of these two outputs tells us which cell state to update (from the sigmoid layer), and what to update it with (tanh layer)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Output Gate&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The last gate, output gate, decides what value the cell would output. The output is derived from multiplying the outputs from the Sigmoid layer and tanh layer&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":361} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-focus-o.png){.wp-image-361}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Sigmoid layer takes in the previous and current time step values, and outputs values 0 to 1 for each value in the cell. A value of 0 means do not output this cell state value at all, and 1 means to output the entire value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The tanh layer takes in the current cell state, which scales the values to be from -1 to 1. This value is then multiplied by the output of the Sigmoid layer to get the final output value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Modification of the Cell State&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The cell states in each LSTM cell are modified either by the forget gate, or the input gate.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":364} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/lstm3-focus-c-2.png){.wp-image-364}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The forget gate outputs values 0-1, and is multiplied by the cell state. Cell states multiplied by 0 will be completely forgotten, while those multiplied by value &amp;gt; 0 will be remembered by varying degrees.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The input gate then updates each value in the cell state by a candidate amount (from the tanh layer), scaled by a factor (decided from the Sigmoid layer)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In each LSTM cell, there contains a cell state.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Forget gate decides what to drop from the cell state&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Input gate creates candidate values to update the cell state&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Output gate decides what values to output from the cell state&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Final Notes&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;I usually end with the conclusion, but all the information above was all the technical aspects of an LSTM. Here are some further questions relating to LSTM.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Q: What are you actually training when you do your Backpropagation through time on an LSTM?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A: Recall that the gates have to control what to forget, input and output from each LSTM cell. What exactly to forget, input and output are the variables being trained.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Q: So... how does it combat vanishing/exploding gradients?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Gradients explode when their values are greater than 1, and vanish when their values are lesser than 1, and are backpropagated for too large a time step.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The key to LSTM preventing the vanexplgrad (I just made that up) is cell state updating step. Below shows the formula for updating the cell&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":369,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/untitled-1.png){.wp-image-369}  
&lt;figcaption&gt;
Calculating the current cell state using values from the previous cell state
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;c(t)&lt;/code&gt; is the current cell state to compute&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i&lt;/code&gt; is the input gate that decides which cell state to update, &lt;code&gt;g&lt;/code&gt; is the actual value changes to be made to the cell state. These two are multiplied together to get final cell state changes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is the forget gate, and &lt;code&gt;c(t-1)&lt;/code&gt; is the previous cell state. These two are multiplied to drop values from the previous cell state.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When performing backpropagation, we find the derivative w.r.t the error. This gives us the formula&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":368,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/2.png){.wp-image-368}  
&lt;figcaption&gt;
Derivative of w.r.t the error
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This formula does not have any multiplicative element in it, and so when BPTT occurs, a &lt;em&gt;linear carousel&lt;/em&gt; occurs, thus preventing vanexplgrad.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;</content><category term="Exploding Gradients"></category><category term="LSTM"></category><category term="Vanishing Gradients"></category></entry><entry><title>RNN and Vanishing/Exploding Gradients</title><link href="/rnn-and-vanishing-exploding-gradients.html" rel="alternate"></link><published>2019-06-23T16:23:00+00:00</published><updated>2019-06-23T16:23:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-23:/rnn-and-vanishing-exploding-gradients.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to be looking at:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Recurrent Neural Networks (RNN)&lt;/li&gt;
&lt;li&gt;Weight updates in an RNN&lt;/li&gt;
&lt;li&gt;Unrolling an RNN&lt;/li&gt;
&lt;li&gt;Vanishing/Exploding Gradient Problem&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;A Recurrent Neural Network (RNN) is a variant of neural networks, where in each neuron, the outputs cycle back to themselves, hence …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to be looking at:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Recurrent Neural Networks (RNN)&lt;/li&gt;
&lt;li&gt;Weight updates in an RNN&lt;/li&gt;
&lt;li&gt;Unrolling an RNN&lt;/li&gt;
&lt;li&gt;Vanishing/Exploding Gradient Problem&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;A Recurrent Neural Network (RNN) is a variant of neural networks, where in each neuron, the outputs cycle back to themselves, hence being recurrent.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":345} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/0_mrhhgabskajpbt21.png){.wp-image-345}

&lt;figcaption&gt;
Each neuron's output cycle back to themselves, as compared to a feed-forward neural network

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This means that each neuron in an RNN has two sources of inputs:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;The present data (Which can be one or more inputs)&lt;/li&gt;
&lt;li&gt;The recent past data (A single output based on the previous set of inputs)&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Intuitively, this means that the network can learn whats happening now, and what happened before.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The RNN has a Short-Term memory, as the recurrent input is only derived from it's most recent past. Anything that happened way before is "forgotten".&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, if we feed in the word "neuron" letter by letter, in a feed-forward NN, when we reach the letter "r", the model would have forgotten "n", "e", "u".&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In an RNN, the model would remember the immediate past, that previously we have seen the letter "u".&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Like a normal feed-forward NN, the RNN also has a weight matrix, but with one additional weight to include the recurrent input. When doing backpropagation, this recurrent weights is also subjected to tweaking.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Weight Updates in an RNN&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;This weight updating phase for an RNN is called Backpropagation Though Time. Lets examine first how a feed-forward NN does forward and backward propagation for weight correction&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In a feed-forward NN, forward propagation is done to get the predicted output. An error estimate is gotten from the predicted output and the true label.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Using the error estimate, we do backpropgation to find the partial derivatives of the error with respect to the weights of the network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These derivatives are then used by Gradient Descent to tweak the weights of the model, and ultimately try to minimize the error estimate, so that the predicted output is close to the true output.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":346,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/0_fbugysciqjnfi3n6.png){.wp-image-346}  
&lt;figcaption&gt;
Forward propagation to get the outputs, error estimate calculation, and backpropgation to get the gradients of the error w.r.t. the weights, and apply gradient descent.  
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In an RNN, there is an additional component of the recurrent input in each neuron. This input also has its corresponding weight that needs to be tweaked. To understand how that happens, we need to be able to visualize "unrolling" an RNN&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Unrolling an RNN&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;As mentioned earlier, each neuron will 2 sources of inputs: The current input, and the most recent previous input.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":348,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/0_ynlojw7yvjarwmd4-copy.png){.wp-image-348}  
&lt;figcaption&gt;
The output of the RNN cell is fed back.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the next time step, it will take the current input plus the previous output. We can visualize this by "unrolling" the RNN, so we can see what happens at each time step.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":349,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/0_ynlojw7yvjarwmd4.png){.wp-image-349}  
&lt;figcaption&gt;
An unolled RNN to visualize what happens to the cell at each time step
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The image above shows what happens when you unroll one recurrent neuron. In a network with 100s of neurons, some layers recurrent, things can get really messy.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":350,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/dpln_0423.png){.wp-image-350}  
&lt;figcaption&gt;
Hidden layers 1 and 2 are recurrent. Here we unroll them for 3 time steps
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Vanishing/Exploding Gradient Problem&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When we combine the two concepts of applying Backpropagation on an unrolled RNN, we get Backpropagation through time (BPTT).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Recall that we also need to learn the weights of the recurrent input, and BPTT is done to get the gradient by finding the partial derivatives of the error with respect to the recurrent inputs. (Just like how in a normal feed-forward NN, backpropagation is done to get the partial derivatives of the error with respect to the weights). Using the gradients, Gradient Descent is then applied.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In BPTT, the error is backpropagated from the last time step all the way to the first time step to update the weights of the recurrent input.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The problem comes when there are too many time steps, and BPTT has to propagate error back too many times, which will result in the gradients exploding, or vanishing.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;At each time step, the gradients are multiplied by each other via matrix multiplication because of chain rule. If the gradient is greater than 1.0, a large number of time steps will cause the gradient to "explode", or become too large.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Likewise, when the gradient is less than 1.0, multiplying it too many times by itself will cause the gradient to "vanish", or become close to zero.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Both exploding and vanishing gradients are problematic, because then Gradient Descent will performing poorly on overly large values, or overly small values.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Summary&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To recap on a feed-forward NN:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Forward propagation is done get the output prediction&lt;/li&gt;
&lt;li&gt;An error estimate is calculated from the model output to the the true values&lt;/li&gt;
&lt;li&gt;Backpropagation is done using the error, to get partial derivative of the error w.r.t. the weights&lt;/li&gt;
&lt;li&gt;Gradient Descent is applied using the gradients to minimize the error&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;And for an RNN:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Forward propagation is done get the output prediction&lt;/li&gt;
&lt;li&gt;An error estimate is calculated from the model output to the the true values&lt;/li&gt;
&lt;li&gt;The RNN is unrolled by the total number of time steps&lt;/li&gt;
&lt;li&gt;BPTT is done to get partial derivative of the error w.r.t. the weights&lt;/li&gt;
&lt;li&gt;Gradient Descent is applied using the gradients to minimize the error&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The problem comes when there are too many times steps, and performing BPTT causes the gradients to explode or vanish. This affects the final step of applying Gradient Descent.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;</content><category term="RNN"></category><category term="Vanishing Gradients"></category></entry><entry><title>What are Proxies?</title><link href="/what-are-proxies.html" rel="alternate"></link><published>2019-06-21T09:57:00+00:00</published><updated>2019-06-21T09:57:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-21:/what-are-proxies.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Proxy, or a Proxy Server / Web Proxy, is something that sits between the source of the network traffic, and the desired destination of the traffic. What the proxy will do is relay the network traffic across to the other side.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Typically, it would sit between a client and a …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Proxy, or a Proxy Server / Web Proxy, is something that sits between the source of the network traffic, and the desired destination of the traffic. What the proxy will do is relay the network traffic across to the other side.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Typically, it would sit between a client and a server, where the client is usually a web browser, and the server being the web server that hosts its resources.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Forward Proxies&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":457} --&gt;&lt;/p&gt;
&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/06/1-1.png){.wp-image-457}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Forward proxies are setup such that the clients are behind a proxy server that passes all the network traffic from the clients to the server.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Such a setup is viable for several security reasons, such as centralized scanning of traffic, identify protection and blocking of content.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The downsides of this is that all the clients share the same bandwidth on the proxy server, thus potentially slowing the network speed for everyone.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Reverse Proxy&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":458} --&gt;&lt;/p&gt;
&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/06/2-1.png){.wp-image-458}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A reverse proxy is the same as the forward proxy, but it's implemented on the server side instead. Multiple servers sit behind the reverse proxy, and the proxy routes the network traffic to the correct servers based on packet information.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The reasons for a reverse proxy also pertain to security such as DDoS protection, but also includes load balancing, where the reverse proxy can detect which server is being overloaded, and redirect the traffic to other servers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Types of Proxies&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;HTTP Proxies&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;HTTP proxies are designed specifically for proxying HTTP information. HTTP proxies cannot proxy for other types of protocols.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There is also an encrypted version of a HTTPS proxy to prevent the proxy (or anyone along the pipeline) from seeing any data being transferred.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Because HTTP or HTTPS runs on TCP, this means that the HTTP proxy only supports TCP protocols&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;SOCKS Proxies&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;While HTTP proxies are only meant for HTTP traffic, SOCKS operate on a lower level, and thus can support almost all protocols including both TCP and UDP types, as well as HTTP traffic.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The SOCKS proxy server establishes the TCP connection on behalf of the client with an external server, and then uses that connection to route traffic between the client and server.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SOCKS does not touch the data stream at all, only setting up the connection and routing the traffic.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Comparison between the Proxies&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;Security&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In both proxies (HTTPS and SOCKS, not HTTP), encryption is present, thus your data flowing through is secure.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Speed&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As SOCKS proxies only route data traffic and never touches the data inside, they can route the data much faster. However, most of the time the speed differences are negligible.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Features&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Since SOCKS proxies supports multiple protocols including HTTP, why still do we need a HTTP proxy?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Because HTTP proxies understand the HTTP traffic that is flowing through, the client and the external server can both talk to the proxy server over HTTP. This can allow the HTTP proxy to do things like caching to improve performance.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The SOCKS proxy on the other hand, does not understand HTTP traffic, and only routes the data that is flowing through. You cannot talk directly to the SOCKS server in HTTP.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, SOCKS proxies support both TCP and UDP connections, which can be used by more programs.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Proxy"></category></entry><entry><title>K-Means Clustering</title><link href="/k-means-clustering.html" rel="alternate"></link><published>2019-06-16T21:18:00+00:00</published><updated>2019-06-16T21:18:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-16:/k-means-clustering.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;K-Means Clustering is an unsupervised learning algorithm. It works by grouping similar data points together to try to find underlying patterns.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The number of groups are pre-defined by the user as K.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How the Algorithm works&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Before the iterative update starts, a random selection of centroid locations are picked on …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;K-Means Clustering is an unsupervised learning algorithm. It works by grouping similar data points together to try to find underlying patterns.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The number of groups are pre-defined by the user as K.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How the Algorithm works&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Before the iterative update starts, a random selection of centroid locations are picked on the graph. These centroids act as the beginning points for each cluster. (if K = 5, there will be 5 random centroids)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Data Assignment Step&lt;ul&gt;
&lt;li&gt;Each data point is assigned to its nearest centroid, based on the squared Euclidean distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Centroid Update&lt;ul&gt;
&lt;li&gt;Given the new data points, re-calculate the centroid value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Repeat until centroid no longer changes, or until a stopping criteria.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Choosing K&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;How do we choose K? Well, iteratively of cause. We define K to be a range of values, and run K-mean clustering through those values.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":341} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/03/introduction-to-k-means-clustering-elbow-point-example-1.jpg){.wp-image-341}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conlcusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;This was a pretty short post, but it acts as a summary of how K-means clustering works!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="K means clustering"></category></entry><entry><title>Domain Fronting and SNI</title><link href="/domain-fronting-and-sni.html" rel="alternate"></link><published>2019-06-13T10:54:00+00:00</published><updated>2019-06-13T10:54:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-13:/domain-fronting-and-sni.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Domain fronting is a malicious act of appearing to request to visit a legitimate site (the front), while in actual fact, the request is going to another website.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Domain fronting relies on the SSL technology to work, where the service provider is unable to see the actual malicious hostname the …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Domain fronting is a malicious act of appearing to request to visit a legitimate site (the front), while in actual fact, the request is going to another website.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Domain fronting relies on the SSL technology to work, where the service provider is unable to see the actual malicious hostname the request is going to, but can only see fronted domain the SNI data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;SNI&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;SNI, which stands for Server Name Indication, helps solves the issue introduced with TLS on HTTP connections.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A server can be shared by many users to host their own websites. For example: AWS, Google Cloud or Azure all host multiple websites that clients can visit.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In a non-TLS connection, when the request is made from the client to the server, the hostname is visible in clear text. The server then simply serves the requested hostname to the client.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In a TLS connection, it gets slightly complicated. A TLS connection requires the certificate of the website to complete the handshake. Each website hosted on the server has their own certificate. However, the hostname is encrypted in the incoming request from the client. Without the hostname, how will the server know which website the client wants to visit, and which certificate to present to the client?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A simple solution is presented by SNI, which indicates the hostname in the initial TLS connection (TLS Hello). This way, the server knows which website to get the certificate from to complete the TLS handshake.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;SNI-Hostname Mismatch&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Domain fronting takes advantage of SNI presented to the server. The hostname is the actual destination the packet is going to, and it's encrypted. The only information the servers have is from the SNI, and attackers can simply spoof the SNI value to something legitimate.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;An example scenario:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Hostname : &lt;code&gt;www.badsite.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;SNI spoofed to show: &lt;code&gt;www.goodsite.com&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Since the hostname is encrypted, no one knows im going to &lt;code&gt;www.badsite.com&lt;/code&gt;, and they can only access the SNI data to assume that i'm visiting &lt;code&gt;www.goodsite.com&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":452} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/06/1.png){.wp-image-452}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:image {"id":453} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/06/2.png){.wp-image-453}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Detection&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Domain fronting is used in other malicious scenarios, such as C2 communication and data exfiltration&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Detection of domain fronting obviously can't work just by observing the packet, as the contents are encrypted. Detection can thus only be done through behavioral analysis such as regular beaconing intervals, or suspicious packet sizes.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Domain Fronting"></category><category term="SNI"></category></entry><entry><title>Random Forests</title><link href="/random-forests.html" rel="alternate"></link><published>2019-06-09T20:43:00+00:00</published><updated>2019-06-09T20:43:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-09:/random-forests.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A random forest is an ensemble approach of combining multiple decision trees. Ensembling and Decision Trees, we first need to explain what these two things are&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Decision Trees&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Decision Trees try to encode and separate the data into if-else rules. It breaks the data down into smaller and smaller subsets …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A random forest is an ensemble approach of combining multiple decision trees. Ensembling and Decision Trees, we first need to explain what these two things are&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Decision Trees&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Decision Trees try to encode and separate the data into if-else rules. It breaks the data down into smaller and smaller subsets. Each node poses the question, and each branch represents the decision.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":331,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/1_jaey3kp7tu2q6hn6lasmrw.png){.wp-image-331}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Given the example above, how do we know which question to ask first at the root node? Do we first split by Age, Pizza consumption, or Exercise? This decision is made by calculating the &lt;strong&gt;Entropy Loss&lt;/strong&gt;, or &lt;strong&gt;Information Gain&lt;/strong&gt;. Information gain is calculated using Entropy loss, so the two variables are closely linked.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Intuitively, we want to reduce entropy of the data, so that we can separate them nicely. A 0 entropy data means that all the samples are the same, and an entropy of 1 means that the samples are split evenly between the classes.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":332,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/0_klhgarh43lgdoksn.png){.wp-image-332}  
&lt;figcaption&gt;
When there are 0 samples of class P, Entropy is 0.  
When 0.5 of the samples are class P, Entropy is 1.  
When all the samples are class P, Entropy is 0.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We want to make splits that &lt;strong&gt;Maximizes Information Gain&lt;/strong&gt; (or making the resulting data sets more homogeneous). The following steps are involved:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;For each target feature (Age, Pizza consumption, Exercise), calculate the current Entropy value.&lt;/li&gt;
&lt;li&gt;Split the data on each target feature, and calculate the resulting entropy after splitting.&lt;/li&gt;
&lt;li&gt;Choose the feature that results in the largest information gain, or entropy loss.&lt;/li&gt;
&lt;li&gt;Repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;That was a gist of a decision tree, now lets look at ensembling and Random Forest&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Ensembling and Random Forest&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Ensembling revolves around the idea of putting together several weak learners to form a strong learner. In Random Forest, the weak learners are Decision Trees&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":333,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/03/skitch.jpg){.wp-image-333}  
&lt;figcaption&gt;
Blue dots represent the data points.  
Grey lines represent the weak learners.  
The red line represents the single strong learner.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Here's the process of a Random Forest:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;From the full data set, create several subsets by random sampling with replacement.&lt;/li&gt;
&lt;li&gt;Using these subsets, we create Decision Trees from them.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Now that we created the Random Forest, when we get a new input to predict, we pass the input to all the Decision Trees in the Random Forest. This gives up multiple outputs, one output for each tree. The final result of the Random Forest would then be an average of the trees (if it's a regression problem), or voting by majority (if it's a classification problem).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Downside of Random Forest are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Random Forest that are used for regression cannot predict beyond the range in the training data they are fed with&lt;/li&gt;
&lt;li&gt;Random Forests may overfit noisy data sets&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;This post was a fairly simple and straightforwad one, cover basic, but essential topics.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We have seen how a Decision Tree works, and the how the Random Forest makes use of multiple Decision Trees.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Decision Tree"></category><category term="Random Forest"></category></entry><entry><title>Branches of Machine Learning</title><link href="/branches-of-machine-learning.html" rel="alternate"></link><published>2019-06-02T15:30:00+00:00</published><updated>2019-06-02T15:30:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-06-02:/branches-of-machine-learning.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just finished reading the book "The Master Algorithm", where the author tries to find the ultimate Machine Learning algorithm that can solve different varieties of problems (text, image, predictive, time series etc)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the book, he goes over the 5 main branches (or tribes) of Machine Learning. They are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;The …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just finished reading the book "The Master Algorithm", where the author tries to find the ultimate Machine Learning algorithm that can solve different varieties of problems (text, image, predictive, time series etc)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the book, he goes over the 5 main branches (or tribes) of Machine Learning. They are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;The Evoluntionaries&lt;/li&gt;
&lt;li&gt;The Connectionist&lt;/li&gt;
&lt;li&gt;The Symbolist&lt;/li&gt;
&lt;li&gt;The Bayesians&lt;/li&gt;
&lt;li&gt;The Analogizers&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:image {"id":323,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/02/master-algo_thumb.png){.wp-image-323}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lets look at what the 5 tribes have to offer, and their each individual "Master Algorithm"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Evolutionaries&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Master Algorithm: &lt;strong&gt;Genetic Algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Loss Function: &lt;strong&gt;Fitness Function&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Optimization Function: &lt;strong&gt;Genetic Search&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This tribe tries to represent learning by mimicking evolution, where the it uses survival-of-the-fittest idea to pick the best model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Starting with weak and not-fit models, the models go through different biologically inspired evolutionary stages: Mutation, Cross Over and Selection&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Evolutionaries focus on learning the structure of the model, and not so much of the parameters (something which Connectionist with neural networks focus on)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Connectionists&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Master Algorithm: &lt;strong&gt;Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Loss Function: &lt;strong&gt;RMSE&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Optimization Function: &lt;strong&gt;Gradient Descent and Back Propagation&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Connectionist represent learning by modelling it after the brain and the neuron connections inside them. Dendrites, Axons and the Cell made up the Neural Network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In Neural Networks, we are trying to learn the weights of the connections between the cells, and not the structure of the neural network itself (Perhaps there could be a combination of GA and NN, where GA finds the structure, and NN finds the weights)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;It follows the notion that a concept can be represented by firing various neurons, and concepts that are similar to each other will cause the same set of neurons firing.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Symbolist&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Master Algorithm: &lt;strong&gt;Logic&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Loss Function: &lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Optimization Function: &lt;strong&gt;Inverse Deduction&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Symbolist believe that all intelligence can be reduced to symbols, or rules. They build rule base systems, which obviously have huge limitations, because we can't possibly convert all intelligence and edge cases to a hard coded rule. The moment the rule encounters just a slightest bit of noise, it fails to perform.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, real life scenarios and concepts are seldom defined in black and white rules, and are usually stochastic and in the grey area.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In some cases, they can perform quite well. A model that Symbolist use are decision trees, which are huge tree that have if-else rules at each branch.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Bayesians&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Master Algorithm: &lt;strong&gt;Graphical Models&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Loss Function: &lt;strong&gt;Posterior Probability&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Optimization Function: &lt;strong&gt;Probabilistic Inference&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As opposed to frequentist, which gives no value to prior beliefs, Bayesians hold prior beliefs at the center of their model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Bayesian works on conditional probability, or Bayes Theorem, that tells the probability of event A happening given that B has occurs &lt;code&gt;P(A|B)&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;During the training phase, the model takes the training data to build a list of conditional probabilities. During testing, given certain features, the model will use the conditional probabilities to perform predictions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Naive Bayes algorithm is one that assumes that all probabilities are independent of each other. Although it is not a valid assumption in the real world, it still performs quite well.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Analogizers&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Master Algorithm: &lt;strong&gt;Support Vector Machines&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Loss Function: &lt;strong&gt;Margin between Support Vectors&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Optimization Function: &lt;strong&gt;Constrained Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This tribe uses similarities among various data points to categorize them to distinct classes. Based on the similarity between data points, we can relate them together.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Models in this tribe are K-Nearest-Neighbor and Support Vector Machines.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Summary&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":325,"align":"center","width":487,"height":487} --&gt;&lt;/p&gt;
&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/puzzle_thumb.png){.wp-image-325 width="487" height="487"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The book tries to amalgamate ideas together to form the Master Equation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We could use posterior probability as the evaluation function, and genetic search coupled with gradient descent as the optimizer&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>GAN?</title><link href="/gan.html" rel="alternate"></link><published>2019-05-26T13:13:00+00:00</published><updated>2019-05-26T13:13:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-26:/gan.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Generative Adversarial Network (GAN) is a collection of two neural network models: A Discriminator, and a Generator. The goals of the two models are opposing to each other&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Discriminator: Given a set of features, we try to predict the label&lt;/li&gt;
&lt;li&gt;Generator: Given a label, we try to predict the …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Generative Adversarial Network (GAN) is a collection of two neural network models: A Discriminator, and a Generator. The goals of the two models are opposing to each other&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Discriminator: Given a set of features, we try to predict the label&lt;/li&gt;
&lt;li&gt;Generator: Given a label, we try to predict the features that lead to the label&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, a Discriminator in a spam email detector identifies if an email is spam, given certain keywords. A Generator on the other hand, given a spam label, tries to come up with keywords that results in the label spam.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The goal of a GAN is to train a generative model that can produce outputs that are believable enough for the discriminator to classify it as a positive label. At the end, the generative model will be able to produce outputs that are close to what the true distribution produces. Examples of this are image generations, text generation and&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How It Works&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Generator:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;The generator takes in a random numbers from a noise generator, and produces a random output&lt;/li&gt;
&lt;li&gt;The outputs of the generator are mixed together with a collection from the actual training data set&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Discriminator:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;The Discriminator takes in data from both the actual data set and the output of the Generator&lt;/li&gt;
&lt;li&gt;The Discriminator makes a prediction of each data and predicts the probability of the label&lt;/li&gt;
&lt;li&gt;It tries to predict if the data is from the training set, or generated from the Generator model (Real vs Fake data)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Discriminator and Generator goes back and forth, Generating new data points, and predicting the data points. This goes on until convergence: When the Generator produces data points that are classified as Real by the Discriminator.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Discriminator gets the feedback for optimization from the ground truth, and the Generator gets feedback from the Discriminator.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":314,"align":"center","width":503,"height":218} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/gans.png){.wp-image-314 width="503" height="218"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Visualizing the Generator&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;We can visualize how the Generator learns to generate outputs that goes closer to the distribution of the real distribution&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":315} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/02/iterations-1.gif){.wp-image-315}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can see that initially, the distribution by the Generator was random and scattered all over. Over several iterations, the Generator starts producing outputs that have a distribution getting closer to the actual distribution.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Math for GAN&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;We have a joint loss function, with the two models (Generative &lt;code&gt;G&lt;/code&gt; and Discriminative &lt;code&gt;D&lt;/code&gt;) optimizing for different things.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Discriminator tries to identify if the data is from the true distribution &lt;code&gt;x&lt;/code&gt;, and outputs a value &lt;code&gt;D(x)&lt;/code&gt;. The Discriminator also tries to recognize if the data comes from the Generator &lt;code&gt;G&lt;/code&gt;, which outputs a value &lt;code&gt;D(G(z))&lt;/code&gt;. (or &lt;code&gt;1 - D(G(z))&lt;/code&gt;, because the inverse of the Generated data is the data from the true distribution) Putting these two together, we get the loss function:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":316,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/02/1-4xahmaugxeoqnnjhzjq-4q.jpeg){.wp-image-316}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Discriminator &lt;code&gt;D&lt;/code&gt; wants to maximize this, as it wants to correctly identify true data &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;1 - D(G(z))&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;On the other hand, the Generator &lt;code&gt;G&lt;/code&gt; tries to generates data to fool the Discriminator, and it wants to minimize the second half of the loss function:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":317,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/02/1-n235xeigxkl3ktl08d-cza.jpeg){.wp-image-317}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By maximizing &lt;code&gt;D&lt;/code&gt; and minimizing &lt;code&gt;G&lt;/code&gt;, we get the function:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":318} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/02/1-ihk3whuaz_0uek4sjicyfw.png){.wp-image-318}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We then use alternating gradient descent, one step to Maximize the function by Discriminator &lt;code&gt;D&lt;/code&gt;, and the other step to Minimize the function by Generator &lt;code&gt;G&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We fix the Generator's parameters, and perform one iteration of Gradient Descent on the Discriminator. Then we switch and fix the Discriminator's parameters, and perform one iteration of Gradient Descent on the Generator. We keep alternating these steps of Gradient Descent of both models until convergence.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Discriminator usually wins early on against the Generator, as initially, it is very easy for the Discriminator to identify Generated data because the Generator has not learnt anything yet. As such, the Generator will get diminished gradient, and learning will be very slow. GAN therefore modifies the loss function slightly to backpropagate the gradient to the Generator&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":319} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/02/1-6so6q3dwurg8qrmwk1y3jw.jpeg){.wp-image-319}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As the gradient backpropagated to the Generator approaches 0, the GAN changes the function to another one to ensure the gradient to the Generator does not vanish.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Tips for training a GAN&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When training the Generator, hold the values of the Discriminator constant.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When training the Discriminator, hold the values of the Generator constant.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You may train one network that is stronger than the other, giving adverse results: If the Generator is too strong, it will always successfully deceive the Discriminator, leading to a lot of false negatives. If the Discriminator is too strong, it will give outputs that are close to 0 or 1, and the Generator will struggle during learning from gradient descent.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>Visualizing Neural Networks</title><link href="/visualizing-neural-networks.html" rel="alternate"></link><published>2019-05-19T09:31:00+00:00</published><updated>2019-05-19T09:31:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-19:/visualizing-neural-networks.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Neural Networks have always been sort of a black box when it comes to it's implementation, and how it produces good results. I came across some material that shows visually, how the neural networks morph the problem space so that they are separable.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Simple Data&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Here's a sample graph that …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Neural Networks have always been sort of a black box when it comes to it's implementation, and how it produces good results. I came across some material that shows visually, how the neural networks morph the problem space so that they are separable.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Simple Data&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Here's a sample graph that is not linearly separable:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":302,"align":"center","width":284,"height":277} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/simple2_data.png){.wp-image-302 width="284" height="277"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When we try to use a linear model to discriminate the two data, we get a poorly separated model:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":303,"align":"center","width":278,"height":271} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/simple2_linear.png){.wp-image-303 width="278" height="271"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Neural Networks, with the interactions of their hidden layers and nodes, are able to learn more complex information about the graph to plot a non-linear separation:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":304,"align":"center","width":270,"height":263} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/simple2_0.png){.wp-image-304 width="270" height="263"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;What a Neural Networks does is that it warps the space of the problem so that it becomes more separable. The hidden layers in the network transforms the problem space by representing it in a different way&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":305,"align":"center","width":281,"height":274} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/simple2_1.png){.wp-image-305 width="281" height="274"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By warping the problem space with the hidden layers, we see that it's able to linearly separate the two distributions. That's pretty cool! So what the neural network is doing is finding the most optimal way to represent the problem that is discriminative.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;So what happens if the data distribution is too complex, or your neural network model is too simple (too shallow) that it can't properly represent the data?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Spiral Data&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Given a complex data set that resembles a spiral shape, and a neural network model that is too simple, we can see it struggling to find a representation that is separable. This means that there is not enough hidden layers and hidden nodes to transform the data. We need to go deeper!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":308,"align":"center","width":364,"height":355} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/spiral.2.2-2-2-2-2-2-2.gif){.wp-image-308 width="364" height="355"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Here's the same spiral graph, but with enough hidden layers and nodes to transform the spiral data to a separable space. We can see the model separating the data very clearly&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":307,"align":"center","width":344,"height":336} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/spiral.1-2.2-2-2-2-2-2-1.gif){.wp-image-307 width="344" height="336"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;More Complex Data&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In the last example, we see a more complex example, and see how a neural network can separate the data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":309,"align":"center","width":376,"height":283} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/topology_base.png){.wp-image-309 width="376" height="283"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Given a circular topology data, a shallow neural network will have difficulties trying to separate the data from the inside and outer ring. We see it trying to pull apart the data like how it did with the spiral data, but it fails to do so&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":310,"align":"center","width":351,"height":343} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/02/topology_2d-2d_train.gif){.wp-image-310 width="351" height="343"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By introducing more hidden layers and nodes and going deeper, we see that the data is able to be extracted out into another dimension, making it separable!  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":311} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/02/topology_3d.png){.wp-image-311}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In this post, I wanted to show how neural networks warp the space of the data make them separable, and how a shallow network might fail to perform well.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By adding more hidden layers and nodes, we are able to morph and warp the space into different dimensions, representing them differently and making them discriminative&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>The Power of Agency</title><link href="/the-power-of-agency.html" rel="alternate"></link><published>2019-05-14T21:19:00+00:00</published><updated>2019-05-14T21:19:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-14:/the-power-of-agency.html</id><summary type="html">&lt;p&gt;Agency is having the feeling that you're in control of the situation at hand, and of yourself.&lt;/p&gt;
&lt;p&gt;This post is a review of the book "The Power of Agency", and they offer 7 steps for you to regain this sense of control&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keep a clear head and control the amount …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Agency is having the feeling that you're in control of the situation at hand, and of yourself.&lt;/p&gt;
&lt;p&gt;This post is a review of the book "The Power of Agency", and they offer 7 steps for you to regain this sense of control&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keep a clear head and control the amount of stimuli you get&lt;/li&gt;
&lt;li&gt;Associate selectively with people&lt;/li&gt;
&lt;li&gt;Exercise and move&lt;/li&gt;
&lt;li&gt;Always position yourself as a learner no matter where you are&lt;/li&gt;
&lt;li&gt;Keep your emotions in check&lt;/li&gt;
&lt;li&gt;Learn how to read your intuition&lt;/li&gt;
&lt;li&gt;Deliberate before acting&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Keeping a clear head&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Practice meditation&lt;/p&gt;
&lt;p&gt;Dont multitask&lt;/p&gt;
&lt;p&gt;Filter your sources of information&lt;/p&gt;
&lt;p&gt;Reduce junk information (social media)&lt;/p&gt;
&lt;p&gt;Put away your phone. Far far away.&lt;/p&gt;
&lt;p&gt;A traditional pen and paper brings more clarity as opposed to typing&lt;/p&gt;
&lt;p&gt;Embrace boredom, and use it as a moment for self reflection&lt;/p&gt;
&lt;h2&gt;Associate Selectively&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;You have Mirror neurons. Mix around with positive people, and you will mirror them&lt;/p&gt;
&lt;p&gt;Other people have Mirror neurons. Act positively and others will follow suit&lt;/p&gt;
&lt;p&gt;Dont fall into the herd mentality, and disassociate yourself from negative emotions&lt;/p&gt;
&lt;p&gt;Learn to say No&lt;/p&gt;
&lt;p&gt;Being unpopular is okay&lt;/p&gt;
&lt;p&gt;Make or break unhealthy relationships&lt;/p&gt;
&lt;h2&gt;Exercise and Move&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Walk more&lt;/p&gt;
&lt;p&gt;Stand more&lt;/p&gt;
&lt;p&gt;Learn to understand the signals your body is giving you (Hungry? Tired?)&lt;/p&gt;
&lt;p&gt;Go and experience new places and cultures&lt;/p&gt;
&lt;p&gt;Make sleep a priority&lt;/p&gt;
&lt;h2&gt;Always be Learning&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Pursue new knowledge not within your domain&lt;/p&gt;
&lt;p&gt;Learn to embrace failure in learning&lt;/p&gt;
&lt;p&gt;Find out what kind if learner are you&lt;/p&gt;
&lt;p&gt;Get feedback from others&lt;/p&gt;
&lt;p&gt;Bounce and voice out your thought chains and get validation&lt;/p&gt;
&lt;p&gt;Look from other peoples perspective&lt;/p&gt;
&lt;h2&gt;Keep Your Emotions In Check&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Values are not Beliefs. Values are more general. Beliefs are more specific&lt;/p&gt;
&lt;p&gt;Tear down misconstructed beliefs from the past. They may not be valid&lt;/p&gt;
&lt;p&gt;Identify emotions with names and words&lt;/p&gt;
&lt;p&gt;Look at the grander scheme of things&lt;/p&gt;
&lt;p&gt;Channel your emotions somewhere&lt;/p&gt;
&lt;h2&gt;Intuition&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;I personally didn't like this chapter, because I find the lessons quite gray and not very concrete.&lt;/p&gt;
&lt;p&gt;It seems to just say, trust your heart, which is, to me, one of the worse advice to give anyone.&lt;/p&gt;
&lt;h2&gt;Deliberation&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Dont be seduced by shortcuts&lt;/p&gt;
&lt;p&gt;Name your mental steps to your conclusion&lt;/p&gt;
&lt;p&gt;Question the decision you made&lt;/p&gt;
&lt;p&gt;Stay open to alternatives&lt;/p&gt;
&lt;p&gt;Ask yourself 3 questions for each decision&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How did I arrive to that decision&lt;/li&gt;
&lt;li&gt;What other alternatives are there&lt;/li&gt;
&lt;li&gt;How am I feeling during the decision making process&lt;/li&gt;
&lt;/ol&gt;</content></entry><entry><title>The Cyber Kill Chain</title><link href="/the-cyber-kill-chain.html" rel="alternate"></link><published>2019-05-13T16:52:00+00:00</published><updated>2019-05-13T16:52:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-13:/the-cyber-kill-chain.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Cyber Kill Chain (CKC) is a sequential set of steps that takes place when an attack happens. There are many variations of the CKC by different companies such as , but the "trusted" and most convincing variant is by Lockheed Martin.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":447} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/05/the-cyber-kill-chain-body.png.pc-adaptive.1920.medium …&lt;/figure&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The Cyber Kill Chain (CKC) is a sequential set of steps that takes place when an attack happens. There are many variations of the CKC by different companies such as , but the "trusted" and most convincing variant is by Lockheed Martin.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":447} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/05/the-cyber-kill-chain-body.png.pc-adaptive.1920.medium.png){.wp-image-447}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This CKC is pretty straightforward, and by disrupting any part of the kill chain, you can stop the final attack, which is "Actions On Objectives"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;At each step, there are examples of what an Adversary could do, and what Defenders can do to detect or disrupt it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Reconnaissance&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Before carrying out the attack, the adversary will scope out and survey the target. This phase is extremely broad, and can cover technical and non-technical aspects.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, they can find out the working hours of your system administrator to plan the right time to attack, or find out what version of OS and email application the company is using. They can harvest emails or contact information through OSINT channels, or social media. They can find scan for open services in the company network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Because of such a broad scope of activities, it's almost impossible to be aware that someone is performing reconnaissance on your company. What you can do however lies on the technical side, such as:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Enabling logging for your webservers to detect any sort of scraping or probing.&lt;/li&gt;
&lt;li&gt;Disabling all unneeded services&lt;/li&gt;
&lt;li&gt;Disabling ICMP responses&lt;/li&gt;
&lt;li&gt;Properly configuring your Firewall to log and prevent network traffic&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection&lt;/strong&gt;:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;-&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention&lt;/strong&gt;:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The goal here is to prevent information leakage, as well as detecting information probing attempts. Knowing that an attack is going to happen is the first step to protecting yourself.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Weaponization&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In this stage, the adversary starts to prepare the payload for attack.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Given the information he got from reconnaissance, he can build tools specific for OS versions, application versions or Firewall versions. Since this phase of the attack happens outside the victims circle of control, there is no way of detecting when Weaponization happens.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;-&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One possible way of neutralizing this phase is to do regular security assessments of your infrastructure, and detect if any applications or versions are vulnerable, and perform patching to secure those assets.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By doing so, you are preventing, or making it very hard for adversaries to perform Weaponization.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Delivery&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In the delivery stage, the attacker sends the Weaponized tools to the victim, either via software (Email, links, direct to the webserver) or physical means (USB insertion)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This is the most crucial stage for defenders. Knowing what are all the possible vectors of attacks, and either mitigating it, or eliminating it if possible.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You must know which are your most important infrastructures that are connected to the most important assets, and make sure that they are well secured with various layers of security.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Logging must also be enabled to detect any point of entry, such as email logs, web logs and endpoint logs.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Airgapped machines, web proxies and proper staff security education all limit the vectors of delivery.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Exploitation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;If you failed to prevent Delivery, the adversaries would be able to enter the machine. Once inside, the next step for them is to perform exploitation to either gain privilege escalation, or to gain unauthorized information. This can either be a software or hardware vulnerability that the adversary leverages on.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Preventing exploitation is a huge monster of a topic on it's own, but basically it revolves around patching your systems, making sure appropriate security controls are in place, and properly educating your staff on security issues like phishing emails and malicious links.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, regular security assessments should be done to lock down all possible edge cases.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Endpoint security and application logging&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By hardening your systems and educating your users, you're limiting the amount of damage that can be done if the adversary is within your network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Installation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Once the adversary gets into your system and performs exploitation, it is highly likely that he would have escalated privileges, and can install other tools he wants to allow him to perform other actions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These tools includes keyloggers, rootkits, backdoors, webshells or scripts.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Detection at this phase involves behavioral analysis. HIPS, endpoint detection tools, and log analysis can be used to detect anomalous activities on both the endpoint and network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;At this phase, since the adversary already has exploited the system and has escalated privilege. There is little you can do to prevention, but only detection and performing remediation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Command &amp;amp; Control&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;After installing rootkits and backdoors, the malware needs to receive commands remotely from their server. This is done by establishing a C2 connection out from the victim machine to the adversary.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;C2 communication is hard to detect, and it can take place under commonly used ports and services such as HTTP, DNS or SMTP.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Network based detection can be used to find anomalous activities on the network. Web proxies to log all traffic for analysis.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Blocking and preventing unauthorized network traffic. Disabling unneeded services that connect out to the internet. Close unused ports. Honey pots to study the C2 traffic.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Actions On Objectives&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In the CKC, it shows this as the final step after performing all previous actions. Actions On Objects could mean acquiring user credentials, collecting and exfiltrating data or lateral movement. But these actions need not be the final step of the CKC, after establishing a C2 or performing Exploitation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Depending on the objective the adversary wants to perform, Actions On Objectives could actually happen after the Exploitation phase onward.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This phase is an accumulation of steps, thus there is no single point of detection or prevention. To disrupt this part of the kill chain, you have to target all preceding parts of the CKC.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Detection:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Logging on network and endpoint to perform anomaly detection.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Preventing Delivery and Exploitation would prevent the adversaries to perform any Actions, thus preventing this final step of the CKC.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Installation cannot be prevented, since it assumes that the adversary has escalated privileges, and a C2 connection may not be required to perform an Action On Objectives.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Cyber kill chain"></category></entry><entry><title>Tips for Kaggling</title><link href="/tips-for-kaggling.html" rel="alternate"></link><published>2019-05-12T11:31:00+00:00</published><updated>2019-05-12T11:31:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-12:/tips-for-kaggling.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've been doing Kaggle competitions for awhile (although with not much success), and I've learning quite a few things along the way. One of which is how to properly approach the problem, and iterate through it to climb the LB (leader board).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Setting the baseline&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The first thing I would …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've been doing Kaggle competitions for awhile (although with not much success), and I've learning quite a few things along the way. One of which is how to properly approach the problem, and iterate through it to climb the LB (leader board).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Setting the baseline&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The first thing I would do is to use some very simple features, and build a quick model that has a relatively low bias.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I'll then use cross validation to ensure that I have low variance between train-test splits. This ensures that i'm not overfitting to any segment of the training data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After getting a satisfactory bias and variance value, we cross our fingers, and submit our prediction to see how well it does on the LB!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are now 3 things you need to take note of:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Cross Validation Score (CV Score)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Leader board Score (LB Score)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Difference between CV and LB Score (Your variance on the testing set)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the difference between your CV and LB is high, you're overfitting the training data. Try to tune your model so that the difference isn't too high.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Feature Generation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Now that you got your baseline, &lt;strong&gt;Do Not Modify Your Model's Parameters!&lt;/strong&gt;..... yet&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Using parameters for the baseline model, you want to generate more features to increase your CV score. Then you make submissions to the LB to checkout your LB score. If your CV score increases, but your LB score stays the same or decreases, you're overfitting.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Here's a snippet of my comments I used to keep track of my CV/LB climb:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;xgb_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; {
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;max_depth&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;4&lt;/span&gt;,  # &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;maximum&lt;/span&gt; &lt;span class="nv"&gt;depth&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;each&lt;/span&gt; &lt;span class="nv"&gt;tree&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;eta&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;,  # &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;training&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;each&lt;/span&gt; &lt;span class="nv"&gt;iteration&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;silent&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;1&lt;/span&gt;,  # &lt;span class="nv"&gt;logging&lt;/span&gt; &lt;span class="nv"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;quiet&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;objective&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;multi:softprob&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;,  # &lt;span class="nv"&gt;error&lt;/span&gt; &lt;span class="nv"&gt;evaluation&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;multiclass&lt;/span&gt; &lt;span class="nv"&gt;training&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;gamma&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;9&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;alpha&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;3&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;colsample_bytree&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;09&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;subsample&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;09&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;num_class&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;9&lt;/span&gt;}  # &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;number&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;classes&lt;/span&gt; &lt;span class="nv"&gt;that&lt;/span&gt; &lt;span class="nv"&gt;exist&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;this&lt;/span&gt; &lt;span class="nv"&gt;datset&lt;/span&gt;

## &lt;span class="nv"&gt;Original&lt;/span&gt;
&lt;span class="nv"&gt;nfolds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nv"&gt;CV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7299&lt;/span&gt;
&lt;span class="nv"&gt;std&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;0112&lt;/span&gt;
&lt;span class="nv"&gt;LB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;67291&lt;/span&gt;

&lt;span class="nv"&gt;Difference&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;05699&lt;/span&gt;

## &lt;span class="nv"&gt;changed&lt;/span&gt; &lt;span class="nv"&gt;rolling&lt;/span&gt; &lt;span class="nv"&gt;window&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;
&lt;span class="nv"&gt;nfolds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nv"&gt;CV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7458&lt;/span&gt;
&lt;span class="nv"&gt;std&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;0207&lt;/span&gt;
&lt;span class="nv"&gt;LB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;67995&lt;/span&gt;

&lt;span class="nv"&gt;Difference&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;06585&lt;/span&gt;

## &lt;span class="nv"&gt;added&lt;/span&gt; &lt;span class="nv"&gt;quantile&lt;/span&gt; &lt;span class="nv"&gt;features&lt;/span&gt;
&lt;span class="nv"&gt;nfolds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nv"&gt;CV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7564&lt;/span&gt;
&lt;span class="nv"&gt;std&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;0167&lt;/span&gt;
&lt;span class="nv"&gt;LB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;68347&lt;/span&gt;

&lt;span class="nv"&gt;Difference&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;07293&lt;/span&gt;

## &lt;span class="nv"&gt;dropping&lt;/span&gt; &lt;span class="nv"&gt;mean&lt;/span&gt;
&lt;span class="nv"&gt;using&lt;/span&gt; &lt;span class="nv"&gt;smaller&lt;/span&gt; &lt;span class="nv"&gt;feature&lt;/span&gt; &lt;span class="nv"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;nfolds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nv"&gt;CV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7670&lt;/span&gt;
&lt;span class="nv"&gt;std&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;0243&lt;/span&gt;
&lt;span class="nv"&gt;LB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;69284&lt;/span&gt;

&lt;span class="nv"&gt;Difference&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;07416&lt;/span&gt;

## &lt;span class="nv"&gt;adding&lt;/span&gt; &lt;span class="nv"&gt;iqr&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;trimming&lt;/span&gt; &lt;span class="nv"&gt;mean&lt;/span&gt;
&lt;span class="nv"&gt;using&lt;/span&gt; &lt;span class="nv"&gt;smaller&lt;/span&gt; &lt;span class="nv"&gt;feature&lt;/span&gt; &lt;span class="nv"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;70&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;nfolds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="nv"&gt;CV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7740&lt;/span&gt;
&lt;span class="nv"&gt;std&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;0257&lt;/span&gt;
&lt;span class="nv"&gt;LB&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;69988&lt;/span&gt;

&lt;span class="nv"&gt;Difference&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;07412&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As you can see, my parameters are the same, and I'm only adding or removing features to push up my CV and LB&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Feature Selection&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Feature generation was the process of adding in new features, but using all the features (if you have a lot of them), is usually too noisy.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Most models like XGBoost and LightGBM have functions to tell you which features have the most impact on your prediction. You would want to trim your selected features to only include those high impact ones.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By doing this, I was able to push my score up just a little bit more!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Parameter Tuning&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Once you're done with Feature Generation and Feature Selection, then we come to parameter tuning phase.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this phase, we want to tune the parameters to reduce bias, variance, and CV-LB difference. You can use functions like GridSearch to efficiently search across a range of parameters&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Baseline -&amp;gt; Feature Generation -&amp;gt; Feature Selection -&amp;gt; Parameter Tuning!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This isn't a silver bullet to all competitions, but its the strategy that I use regularly.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In data science and Kaggle, there are plenty of moving parts, and it's easy to get lost in the myriad of factors affecting your prediction. It's always good to have a system to isolate and tackle the problem!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Kaggle"></category></entry><entry><title>Side Channel Data Exfiltration</title><link href="/side-channel-data-exfiltration.html" rel="alternate"></link><published>2019-05-10T14:39:00+00:00</published><updated>2019-05-10T14:39:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-10:/side-channel-data-exfiltration.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A typical data exfiltration attack can be quite easy to spot. By monitoring the usage of common protocols such as HTTP, HTTPS, FTP or even DNS, we can deduce if a data exfiltration is taking place.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Most modern DLP (Data Leak Prevention) solutions today that incorporate network analysis can perform …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A typical data exfiltration attack can be quite easy to spot. By monitoring the usage of common protocols such as HTTP, HTTPS, FTP or even DNS, we can deduce if a data exfiltration is taking place.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Most modern DLP (Data Leak Prevention) solutions today that incorporate network analysis can perform such detection across multiple protocols. In fact, a simple data analysis by SIEMs and a competent analyst can point out anomalies in traffic behavior and protocol usage.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The bad guys are well aware of this, and thus are looking for many innovative ways to exfiltrate data that does not leverage on typical protocols, of even the network at all. I came across a few that I found were extremely interesting:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Data Transfer over Ultrasonic Frequency&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jamesonrader/CUE-Ultrasonic-Transmissions-Protocol"&gt;https://github.com/jamesonrader/CUE-Ultrasonic-Transmissions-Protocol&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;On the write up, it has &lt;strong&gt;&lt;em&gt;"No reliance on a data connection, including Wi-Fi, Bluetooth, or cellular service."&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As of now, the advertised usage is targeted at various marketing activities during events at a stadium. One example usage was &lt;strong&gt;&lt;em&gt;"Triggering commands on the smartphone through a television broadcast, online video, radio commercial, film and movies."&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If you can send commands, you can send data. If you can send data, it's data exfiltration.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Data Transfer over Screen Interfaces&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/pentestpartners/PTP-RAT"&gt;https://github.com/pentestpartners/PTP-RAT&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;a href="https://www.pentestpartners.com/security-blog/exfiltration-by-encoding-data-in-pixel-colour-values/"&gt;https://www.pentestpartners.com/security-blog/exfiltration-by-encoding-data-in-pixel-colour-values/&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This package is more straightforward as malicious tool.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You have a sender (Victim) and a receiver (C2). The victim has his machine compromised, and has established an RDP connection back to the C2. To get the RDP connection in the first place can be done by tunneling through SSH: &lt;a href="https://serverfault.com/questions/200249/how-to-tunnel-windows-remote-desktop-through-ssh-using-a-linux-box"&gt;https://serverfault.com/questions/200249/how-to-tunnel-windows-remote-desktop-through-ssh-using-a-linux-box&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once the RDP connection is established, this tool shows that data exfiltration can be performed by encoding data into pixels, which on the receiver end, can read the screen decode them.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:core-embed/youtube {"url":"https://www.youtube.com/watch?time_continue=1\u0026v=hpw8Lz5Fg9I","type":"rich","providerNameSlug":"","className":"wp-embed-aspect-16-9 wp-has-aspect-ratio"} --&gt;

&lt;figure class="wp-block-embed-youtube wp-block-embed is-type-rich wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;
&lt;div class="wp-block-embed__wrapper"&gt;

https://www.youtube.com/watch?time\_continue=1&amp;v=hpw8Lz5Fg9I

&lt;/div&gt;

&lt;/figure&gt;

&lt;!-- /wp:core-embed/youtube --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Data Transfer over Hardware Manipulation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Perhaps the most interesting of all is hijacking and manipulating the physical machine itself. In the event of an air-gapped machine where no network connection is present, getting data out can be very challenging. (Getting into an air-gapped machine is even more challenging, and can involve really complex scenarios such as supply-chain attacks)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This paper explain how it's possible to control the blinking of LED lights and, using a recording device, capture the blinking sequences to reconstruct data: &lt;a href="https://arxiv.org/abs/1706.01140"&gt;https://arxiv.org/abs/1706.01140&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Even more innovative ones take control of the PC fans, and control the RPM to produce sound based data encoding: &lt;a href="https://www.technologyreview.com/s/601816/how-fansmitter-malware-steals-data-from-air-gapped-computers/"&gt;https://www.technologyreview.com/s/601816/how-fansmitter-malware-steals-data-from-air-gapped-computers/&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;End Notes&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The techniques are endless, and as attackers continue to get more innovative, the list will continue to grow. That being said, all these attacks are considerably hard to pull off, and what we as defenders can do is the bare minimum of preventing easy ways of data exfiltration over the network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once we raise the difficulty threshold of data exfiltration to a certain level, then should we start worrying about such innovative and out of the box methods. Get the basics right first!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="data exfiltration"></category></entry><entry><title>Say NO to Overfitting!</title><link href="/say-no-to-overfitting.html" rel="alternate"></link><published>2019-05-05T13:58:00+00:00</published><updated>2019-05-05T13:58:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-05:/say-no-to-overfitting.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just some experience I've encountered while working on a very small data set of 1703 training samples, and 1705 testing samples.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One way to combat overfitting is to use cross validation. While doing so, it's important for you not to just look at the final validation score, but also observe …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just some experience I've encountered while working on a very small data set of 1703 training samples, and 1705 testing samples.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One way to combat overfitting is to use cross validation. While doing so, it's important for you not to just look at the final validation score, but also observe the training process itself.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If we just look at the final CV result, we see an astounding &lt;code&gt;~92%&lt;/code&gt; accuracy. This should raise some alarms that shout "Overfitting!". And this is an accurate observation, because when submitted to the Kaggle leader board, it got a measly &lt;code&gt;0.64&lt;/code&gt;, which was below the baseline! And more horribly, the difference between CV and LB score is &lt;code&gt;~30%&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":294} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/xgb2.png){.wp-image-294}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can also observe the huge disparity between the training error and validation error. A training error of &lt;code&gt;0%&lt;/code&gt;? And validation error of &lt;code&gt;~8%&lt;/code&gt;? Something is really wrong.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Preventing overfitting in XGB&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Since I've used XGBoost, there are several techniques available to combat overfitting, such as regularization, maximum depth of tree and bagging fractions. After applying all of those, I get a final CV score of &lt;code&gt;~74%&lt;/code&gt;, but if we observe the disparity between the training error and validation error, the difference is only &lt;code&gt;~2%&lt;/code&gt;!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":293} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/xgb1.png){.wp-image-293}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After uploading that to the leader board, I see my score rise up to &lt;code&gt;0.69&lt;/code&gt;. The difference between my CV score and the LB is drop drastically from &lt;code&gt;~30%&lt;/code&gt; to &lt;code&gt;~3%&lt;/code&gt;! Classic example of overfitting.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Aside from feature engineering, a lot of effort should also go into ensuring your model is not too complex for very simple data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Overfitting"></category></entry><entry><title>Hit Refresh</title><link href="/hit-refresh.html" rel="alternate"></link><published>2019-05-05T12:51:00+00:00</published><updated>2019-05-05T12:51:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-05:/hit-refresh.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A book by Satya Nadella, CEO of Microsoft&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This book seems to start off as a biography, but it's intent becomes clear by the second chapter, that it's about the changes Satya brings about in Microsoft, and the anticipation of the future innovations such as Mixed Reality, Artificial Intelligence, and …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A book by Satya Nadella, CEO of Microsoft&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This book seems to start off as a biography, but it's intent becomes clear by the second chapter, that it's about the changes Satya brings about in Microsoft, and the anticipation of the future innovations such as Mixed Reality, Artificial Intelligence, and Quantum Computing.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I'll like to highlight the 2 important lessons I took away from this book&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Culture being at the heart of everything&lt;/li&gt;
&lt;li&gt;Collaboration brings about greater benefits&lt;/li&gt;
&lt;li&gt;Trust that the consumers places in you&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Culture&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":439} --&gt;&lt;/p&gt;
&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/05/picture1.png){.wp-image-439}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;To me, this diagram was the biggest take away of the book.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I'll like to emphasize that Culture sit inside BOTH Capabilities and Concepts, meaning to say it affects both circles.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We start off with Concepts, which are innovative ideas that we have and we want to implement. This is the result of Culture that support and promotes creative thinking. A Culture that allows and embraces new ideas, and is welcoming to change. A dead culture is one that is not open to change, and resistant to any new ideas.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Next, we have Capabilities. To realize the ideas derived produced in Concepts, we need to have the right Capabilities. The right people, right infrastructure, right processes. If there isn't the right Capabilities , it can always be built by hiring the right people, setting up the needed infrastructure, and defining proper processes. All these Capability building cannot happen with the right Culture.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;At the heart of it all, Culture reigns supreme. There are many definitions of Culture, but my very own short and simple definition is&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:quote --&gt;

&lt;blockquote&gt;
&lt;p&gt;The Guiding Principles to Solutions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- /wp:quote --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When coming up with a solution to any problem, what are the principles that guide you?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;If you face an issue of sexual harassment at the work place, what principles do the company policies have to dealing with it: Two strikes, or one strike?&lt;/li&gt;
&lt;li&gt;If someone writes spaghetti code, what principles do the engineers have to dealing with it: Teach, or reprimand?&lt;/li&gt;
&lt;li&gt;If engineers feel stagnant, what principles do the managers have: neglect, or constant training?&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Culture is not related to just one issue, but to many issues within the company.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Collaboration&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In the Information age, it is no longer a Zero-Sum game, where information shared would not lead to a loss of information.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Nadella talks about the various collaborative efforts that Microsoft engaged in, many initially questionable, but paid off in the end. Some of them are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Collaborating with their long standing rival Apple, to develop Microsoft Office applications for MacOS&lt;/li&gt;
&lt;li&gt;Collaborating with Linux to integrate Linux environment into Windows, and to provide first class support to Linux machines in Azure Cloud&lt;/li&gt;
&lt;li&gt;Others such as Yahoo and Samsung&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Collaboration almost always leads to greater results, but I personally feel we should be wary of who we collaborate with. Collaborating with companies or people who have no value to you ends up being a dead weight. Selective Collaborate should be done, with clear objectives on both sides, and obvious rationales for collaboration.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As mentioned, it is no longer a Zero-Sum game, and we should not be afraid of intermingling of knowledge.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>Looking out for C2 Traffic</title><link href="/looking-out-for-c2-traffic.html" rel="alternate"></link><published>2019-05-02T16:14:00+00:00</published><updated>2019-05-02T16:14:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-05-02:/looking-out-for-c2-traffic.html</id><summary type="html">&lt;!-- wp:heading --&gt;

&lt;h2&gt;Types of C2 Communication&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When a host gets infected with a malware, sometimes it will attempt to call back to it's Command and Control (C2) to get, or send information. There are 4 types of C2 communication traffic&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Beacon&lt;ul&gt;
&lt;li&gt;After a host has been compromised, the malware will send a …&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;!-- wp:heading --&gt;

&lt;h2&gt;Types of C2 Communication&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When a host gets infected with a malware, sometimes it will attempt to call back to it's Command and Control (C2) to get, or send information. There are 4 types of C2 communication traffic&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Beacon&lt;ul&gt;
&lt;li&gt;After a host has been compromised, the malware will send a message heartbeat to the C2 to inform them of it's status. This traffic is just to tell the C2 that it's alive.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Command&lt;ul&gt;
&lt;li&gt;The command is sent from the C2 to the malware residing on the compromised host. It can either be real-time, or non-real-time. Non-real-time commands means that the command is stored and queued somewhere which the malware can retrieve to execute.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Exfiltration&lt;ul&gt;
&lt;li&gt;This command is sent from the compromised host to the C2. Exfiltration means sending a payload, and this payload can either be a reply from the malware, or stolen data from the host or network. Exfiltration can be done either immediately on request, or at regular (or deliberately irregular) intervals&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Connectivity Check&lt;ul&gt;
&lt;li&gt;This check is done by the malware to check if it has internet connectivity out. This connection may not talk directly to the C2, but may try to connect to something as benign as Google. If it doesn't have any internet connection, it can either defer talking to the C2, or remove itself entirely from the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Capturing C2 traffic&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;There are some strategies to capture C2 traffic, such as leveraging on CTI to learn about IOCs, patterns and log entries that may indicate a compromise.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Because C2 traffic is a networking phenomenon, most approaches towards network analysis, such as:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Netflow Analysis for inflow and outflow&lt;/li&gt;
&lt;li&gt;IRC and P2P traffic&lt;/li&gt;
&lt;li&gt;DNS query logs (to look out for DNS tunneling or DGA)&lt;/li&gt;
&lt;li&gt;Unusual port numbers and services&lt;/li&gt;
&lt;li&gt;Unusual timing of connections&lt;/li&gt;
&lt;li&gt;Requests to Social Media at unusual hours&lt;/li&gt;
&lt;li&gt;Packet size&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below shows an image of the packet sizes versus time, and we can see the start difference between a normal Google search and a Malware&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":435,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/05/eta-blake-fig-2.png){.wp-image-435}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Machine Learning to capture C2 traffic&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Machine learning techniques can be employed to detect C2 traffic. In an extremely noisy environment like network traffic, ML perform anomaly detection by sieving out traffic that stands out.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I did a small sample project which can be seen here:&lt;a href="https://github.com/jinhaochan/BotnetDetection"&gt;https://github.com/jinhaochan/BotnetDetection&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The model trained took features only from network behavior, and had quite a good performance. Although I must say that more advanced malwares these days come up with creative techniques, and in this case, machine learning might fail to detect them due to the lack to training data. Furthermore, the malware can cleverly disguise themselves to look like normal traffic, and the model we train miss those entries&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Analyzing C2 traffic&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Assuming that you know a malware has infected a host and is talking to a C2 server, you can either setup a honeypot, or try to reverse engineer the malware sample on the host.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Setting up the honeypot is essentially performing an MITM between the malware and the C2 server. We allow the malware to connect to the C2 and internet, while isolating it from other machines on the network to prevent it from spreading. This way, we can capture all the traffic that's flowing to and from the C2, and we can find out what the motive of the malware is.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The second method is getting the sample of the malware on the infected host, and perform reverse engineering to find out what functions and capabilities it has.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;MITRE ATT&amp;amp;CK TTP for C2&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;There is a branch Tactics in the MITRE ATT&amp;amp;CK Framework dedicated to C2, and there is a collection of Techniques they use to identify C2 communication.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If you are coming up with a system or model to detect C2 traffic, the matrix can be highly beneficial. But take caution to not fit a round peg into a square hole, the list is not comprehensive. Attackers are aware of MITRE and their TTPs, and will actively build ways around them.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Software to use for detection C2&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Bro (now renamed to Zeek) &lt;a href="https://www.zeek.org/"&gt;https://www.zeek.org/&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are many write ups out there on how to use Zeek to capture and analyze traffic. Zeek is not specific to capturing just C2, but a wide array of network activities&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="C2"></category><category term="Command and Control"></category></entry><entry><title>What is UPnP? (And how it can be malicious)</title><link href="/what-is-upnp-and-how-it-can-be-malicious.html" rel="alternate"></link><published>2019-04-29T20:09:00+00:00</published><updated>2019-04-29T20:09:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-29:/what-is-upnp-and-how-it-can-be-malicious.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;UPnP, which stands for Universal Plug n Play, is a set of networking protocols used to facilitate adding of new devices to the network. It comes enabled default on most new routers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, when you connect a new printer to the network, it automatically becomes discoverable by all other …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;UPnP, which stands for Universal Plug n Play, is a set of networking protocols used to facilitate adding of new devices to the network. It comes enabled default on most new routers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, when you connect a new printer to the network, it automatically becomes discoverable by all other devices without you having to configure the IP address, or opening ports on the firewall. It does so through the concept of zero-configuration networking, which at it's core consists of&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Automatic assignment of network address&lt;/li&gt;
&lt;li&gt;Automatic distribution and resolution of hostnames&lt;/li&gt;
&lt;li&gt;Automatic location of network services such as printers (through Service Discovery Protocol)&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Device search and advertising is done over HTTP over UDP on port 1900&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This means that any UPnP compatible device can join the network and automatically get an IP address, broadcast it's name, advertise it's capabilities /services on request, and learn about capabilities / services on the network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;UPnP Setup Steps&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;Addressing&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The device implements a DHCP client, and must search for a DHCP server on the network. If no DHCP server exists on the network, it then assigns itself an IP through AutoIP&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Discovery&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The device then uses Simple Service Discovery Protocol (SSDP) to advertise it's own service to Control Points (CP) on the network by sending SSDP Alive Messages, which provides very basic information about the device&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Description&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;To learn more about the device, the Control Point must retrieve the device description from the URL provided from the SSDP. The Device Description comes in an XML format, and has information such as model number, serial number and manufacturer name.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Control&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After getting the description, the Control Point can send actions to the device via Simple Object Access Protocol (SOAP)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Notifications&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The UPnP device can send events or notifications to the Control Points on any changes that happen to it. This uses the General Event Notification Architecture (GENA)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Presentation&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the device has any pages for presentation, the Control Point can receive it and load it on the web browser&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How It Is Abused&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;UPnP does not perform any sort of authentication, and assumes that any devices that is connected is trusted.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, UPnP can automatically configure port forwarding on the router without having any user intervention, or authentication.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Flash UPnP attack was one of the attack that abused the UPnP protocol, and how it works was by sending a UPnP request to the router to forward ports, thus exposing it to the internet. The attack could also change your primary DNS server with a UPnP request.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The best defense therefore is to &lt;strong&gt;disable UPnP on your routers&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="UPnP"></category></entry><entry><title>What is Maximum Likelihood Estimation?</title><link href="/what-is-maximum-likelihood-estimation.html" rel="alternate"></link><published>2019-04-28T09:44:00+00:00</published><updated>2019-04-28T09:44:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-28:/what-is-maximum-likelihood-estimation.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In machine learning, we often perform what we call &lt;strong&gt;parameter estimation&lt;/strong&gt;, which are the weights that are assigned to each feature of the input data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, in a simple linear model, we use the equation &lt;code&gt;y=mx + c&lt;/code&gt; , and &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; are your parameters to be estimated. For …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In machine learning, we often perform what we call &lt;strong&gt;parameter estimation&lt;/strong&gt;, which are the weights that are assigned to each feature of the input data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, in a simple linear model, we use the equation &lt;code&gt;y=mx + c&lt;/code&gt; , and &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; are your parameters to be estimated. For different values of the parameters, we build different models that produce different estimations of the data&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":286} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/parameters.png){.wp-image-286}

&lt;figcaption&gt;
Given different parameter values, we get different models. In the case of a linear model, each model is a different line on the graph.

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Maximum likelihood is a technique for parameter value estimation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;MLE Parameter Estimation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Whenever we create a model with certain parameters, the outputs of the model (or the prediction) can be plotted as a probability distribution as well.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;What MLE does it to try to make the distribution of the model close to the distribution of the observed data. Intuitively, this makes the model more accurate, as it becomes more representative of the actual data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, given the following training data distribution points:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":287} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/1-z3jjgvetojmplfvmwiur3q.png){.wp-image-287}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We want to find out which of the graphs below has the highest probability of plotting those points. Each graph has different parameter values, and so they are plotted in different spaces on the graph.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":288} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/1-ulkl0nz1vfg6bmfiqpckzq.png){.wp-image-288}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just by visual inspection, we can see that the blue line is the graph with the correct parameters that produces those data points. But of course in a machine, there is no visual inspection, only &lt;strong&gt;maths&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Calculating the MLE&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;We want to calculate what is the total probability of observing all the generated data, or the joint probability of all the data points.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For a single data point for an assume Gaussian distribution, we have the following equation&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":289} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/1-t4zrihvhtlzjzsvcx3jrjg.png){.wp-image-289}

&lt;figcaption&gt;
Probability for observing 1 point

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For 3 data points, we have the following joint probability:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":290} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/1-rfzbq614ir4zewbm3k1v0q.png){.wp-image-290}

&lt;figcaption&gt;
Joint probability for observing 3 points

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This can be extended to &lt;code&gt;n&lt;/code&gt; number of points&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;To calculate the MLE of the parameters, we need to find the values of the parameters in the equation that gives us the maximum value of the probability. To find the maximum, we get the differential of the equation and set it to 0, and solve for the parameters.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Extending the MLE to the least squares method&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When the distribution is Gaussian, the process of finding the MLE is similar to the least squared method.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For least squares estimation we want to find the line that minimizes the total squared distance between the data points and the regression line.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When the data distribution is assumed to be Gaussian, the maximum probability is found when the data points get closer to the mean value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Since the Gaussian distribution is symmetric, this is equivalent to minimizing the distance between the data points and the mean value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>MITRE on Threat Detection</title><link href="/mitre-on-threat-detection.html" rel="alternate"></link><published>2019-04-25T17:37:00+00:00</published><updated>2019-04-25T17:37:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-25:/mitre-on-threat-detection.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I just sat through a webinar by the folks at Red Canary, and they covered some questions regarding threat detection using the MITRE ATT&amp;amp;CK framework.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The webinar sat down with the researchers who created MITRE, and it was quite insightful. Here are some of the notes I took that …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I just sat through a webinar by the folks at Red Canary, and they covered some questions regarding threat detection using the MITRE ATT&amp;amp;CK framework.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The webinar sat down with the researchers who created MITRE, and it was quite insightful. Here are some of the notes I took that may be useful for present and future work:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Top 10 MITRE ATT&amp;amp;CK Techniques&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list {"ordered":true} --&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Powershell&lt;/li&gt;
&lt;li&gt;Scripting&lt;/li&gt;
&lt;li&gt;Regsvr32&lt;/li&gt;
&lt;li&gt;Connection proxy&lt;/li&gt;
&lt;li&gt;Spearphising&lt;/li&gt;
&lt;li&gt;Masquerading&lt;/li&gt;
&lt;li&gt;Credential Dumping&lt;/li&gt;
&lt;li&gt;Registry run keys&lt;/li&gt;
&lt;li&gt;Rundll32&lt;/li&gt;
&lt;li&gt;Service Execution&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can observe that a bulk of the these techniques are actually native operating system utilities, and that adversaries are leveraging on these preinstalled utilities to carry out their attacks. Things like Powershell, Regsvr32 and Rundll32 are very common things that are executed in benign settings.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The implications of this is that we simply can't just "turn off" these services in an attempt to disrupt their Cyber Kill Chain. What has to be done is proper logging and auditing of these services.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, we need to turn on logging for Powershell command line, or cmd.exe command line parameters to observe what command is being ran. Also, we need to turn on process tracking to identify which process spawns what other processes. If Microsoft Word spawns cmd.exe or Powershell, we know that something is highly suspicious.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;That being said, there needs to be a fine balance to ensure we don't get too much log by enabling everything. Most activities are normally benign, and having too much logging will induced noise, which may invariably hide the malicious activities!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Top Data Sources for leveraging on MITRE ATT&amp;amp;CK&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list {"ordered":true} --&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Process Monitoring&lt;/li&gt;
&lt;li&gt;File Monitoring&lt;/li&gt;
&lt;li&gt;Process Command-line Parameters&lt;/li&gt;
&lt;li&gt;API monitoring&lt;/li&gt;
&lt;li&gt;Process use of network&lt;/li&gt;
&lt;li&gt;Windows Registry&lt;/li&gt;
&lt;li&gt;Packet capture&lt;/li&gt;
&lt;li&gt;Authentication Logs&lt;/li&gt;
&lt;li&gt;Netflow&lt;/li&gt;
&lt;li&gt;Windows Event Logs&lt;/li&gt;
&lt;li&gt;Network Protocol Analysis&lt;/li&gt;
&lt;li&gt;Binary file metadata&lt;/li&gt;
&lt;li&gt;DLL monitoring&lt;/li&gt;
&lt;li&gt;Loaded DLL&lt;/li&gt;
&lt;li&gt;System Calls&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If that list is too much, or you find that it's too noisy (or your sysadmin policy says you can't enable such logging), then there is a bare minimum data source is required for threat hunting:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Windows Registry&lt;/li&gt;
&lt;li&gt;File Monitoring&lt;/li&gt;
&lt;li&gt;Process Command-line Parameters&lt;/li&gt;
&lt;li&gt;Process Monitoring&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These 4 telemetry provides a comprehensive enough picture to perform threat hunting. These 4 data sources will cover most crucial end-point activities. There isn't any network components in this, but that can be incorporated if needed.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;&lt;strong&gt;How do you build up threat hunting plan based on MITRE ATT&amp;amp;CK?&lt;/strong&gt;&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Know the questions you want to answer, and construct hypotheses around them. Evaluate these hypothesis using various data sources.&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Don't in go blindly. Threat hunting has to be done in a directed manner, and you need to know what you're hunting.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Tools to assist in Threat Hunting&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DetectionLab by Chris Long&lt;/li&gt;
&lt;li&gt;ThreatHuting splunk app by Olaf Hartong&lt;/li&gt;
&lt;li&gt;PoSh_ATTCK by ENRW&lt;/li&gt;
&lt;li&gt;ATT&amp;amp;CK Navigator&lt;/li&gt;
&lt;li&gt;Atomic Red Team&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've not used the DetectionLab, but I've used the rest quite extensively.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The data resource by Olaf Hartong is really comprehensive, as it covers most TTPs. However, most of the queries are Sysmon oriented, so if your environment does not support Sysmon, you have to find way to tweak the Sysmon queries to match your environment.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;PoSh_ATTCK seems to be a Powershell replica of MITRE, and I did not really find much value add in it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;ATT&amp;amp;CK Navigator is the standard way of browsing the TTPs. Standard, but very useful. They even link the TTPs to suspected APT groups, which can assist in attribution.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Atomic Red Team is a really useful resource in providing atomic tests to execute. This allows you to replay attacks, and get first hand data in your environment. However, it does not cover all the attacks, and there are some TTPs that are still missing in their atomic test list. Still, a very good resource.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="MITRE"></category></entry><entry><title>CSRF Tokens</title><link href="/csrf-tokens.html" rel="alternate"></link><published>2019-04-24T16:13:00+00:00</published><updated>2019-04-24T16:13:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-24:/csrf-tokens.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If we look at source codes of HTML forms, we typically can spot this field being rendered on the webpage&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":420} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/token.png){.wp-image-420}

&lt;figcaption&gt;


&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Sometimes it doesn't have the name called CSRF Token, and it just appears as a random gibberish value being loaded.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This post breaks …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If we look at source codes of HTML forms, we typically can spot this field being rendered on the webpage&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":420} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/token.png){.wp-image-420}

&lt;figcaption&gt;


&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Sometimes it doesn't have the name called CSRF Token, and it just appears as a random gibberish value being loaded.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This post breaks down the purpose of the token, and what happens behind the scenes with the token&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Understanding CSRF&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;CSRF stands for Cross-Site Request Forgery, and understanding how it works is a prerequisite to understanding CSRF tokens. Below shows a picture of what a CSRF attack looks like&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":421} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/csrf-cross-site-request-forgery.png){.wp-image-421}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;The attacker crafts a GET requests that triggers a fund transfer to his account&lt;ul&gt;
&lt;li&gt;&lt;code&gt;GET http://bank.com/transfer.php?account=Attacker&amp;amp;amount=100&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The attacker embeds this request as a hyperlink&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;a href="http://bank.com transfer.php?account=Attacker&amp;amp;amount=100"&amp;gt; READ MORE... &amp;lt;/a&amp;gt;&lt;/code&gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When the user clicks on the link, it triggers the &lt;code&gt;GET&lt;/code&gt; request on behalf of the victim&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;GET&lt;/code&gt; request is triggered by the victim, and funds are transferred to the Attacker&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This attack hinges on the fact that the Victim must be logged in to the service, and is already authenticated with an open session with the service.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the Victim is not logged in, when he clicks on the malicious link, instead of triggering the bad &lt;code&gt;GET&lt;/code&gt; request, it will redirect him to the login page instead, thus rendering the attack useless.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;CSRF Tokens&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;CSRF token is a simple concept where include one more argument of a token, that is sort of like a secret password.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;http://bank.com/transfer.php?account=User&amp;amp;amount=100&amp;amp;token=32Sa2dsa10gB88vcx9cz08f331j=Da&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This token value is a high-entropy value which is hard to guess by the attacker. If on the server side, it receives a wrong or missing CSRF token value, the &lt;code&gt;GET&lt;/code&gt; request is rejected and does not execute&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The CSRF token works this way:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Client requests for a HTML page that contains a form&lt;/li&gt;
&lt;li&gt;Server generates two distinct tokens, and sends one as a cookie to the client, and embeds the other as a hidden field in the form&lt;/li&gt;
&lt;li&gt;When the client submits the form, both CSRF tokens must be sent back to the server. The one embedded in the form, and the one in the cookie.&lt;/li&gt;
&lt;li&gt;If the request does not contain both tokens, it's rejected&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The CSRF token value should be regularly invalidated at a time interval, per request, or when the user logs out.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;CSRF Token Vulnerabilities&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;If traffic carrying the token is not encrypted over HTTPS, the Attacker can sniff the traffic and obtain the CSRF token value and the Cookie, and perform a CSRF token replay attack.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The solution to this is obvious: Always use encryption for communication. Aside from that, per-request-tokens can also be implemented.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="CSRF"></category></entry><entry><title>Reinventing Capitalism in the Age of Big Data: Summary</title><link href="/reinventing-capitalism-in-the-age-of-big-data-summary.html" rel="alternate"></link><published>2019-04-21T20:28:00+00:00</published><updated>2019-04-21T20:28:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-21:/reinventing-capitalism-in-the-age-of-big-data-summary.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've finished this book a few months ago, and realized it'll be useful for me to recap the points I've learnt from the book.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This book talks about how data is the new currency in this era, and how the capitalism landscape will change. The book also proposes some steps …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've finished this book a few months ago, and realized it'll be useful for me to recap the points I've learnt from the book.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This book talks about how data is the new currency in this era, and how the capitalism landscape will change. The book also proposes some steps to manage this change, and how to make it a fairer market for all&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 1: Reinventing Capitalism&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Difference between conventional markets and data-rich markets is the role of information flowing through them, and how the information gets translated into decisions&lt;/li&gt;
&lt;li&gt;In data-rich markets, we no longer have to condense all our preferences to a single dollar sum value, which can be an oversimplification of our preference&lt;/li&gt;
&lt;li&gt;There are short-comings in data rich markets, which are over reliance on the data, and lack of diversity of the data and algorithms. This could lead to a data-monopoly, where the company with the most data dominates the industry&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 2: Communicative Coordination&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Human successes so far is predicated mainly on our ability to communicate and coordinate with each other. Coordination relies on our ability to communicate.&lt;/li&gt;
&lt;li&gt;Technology, more specifically volume of information, is increasing our ability to communicate with each other, hence increasing our coordination tremendously.&lt;/li&gt;
&lt;li&gt;Markets and firms help humans coordinate more efficiently through economies of scale, where managing the pay and decisions of several workers is easier than managing each individual.&lt;/li&gt;
&lt;li&gt;In the Market, decisions are decentralized, producing the "Invisible hand". In the firm, decisions are centralized, and top-down.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 3: Markets and Money&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;How the structure of the market is linked to information, and how the information flows and are translated to decisions.&lt;/li&gt;
&lt;li&gt;Information, and the cost of transmitting them, is integral to the success of a Market.&lt;/li&gt;
&lt;li&gt;Markets are decentralized, and so is the flow of information. There is no single point of failure in the market.&lt;/li&gt;
&lt;li&gt;Cascades of bad information in the market will lead to a market crash (housing market bubble, stock market crashes)&lt;/li&gt;
&lt;li&gt;A huge volume of information however, will cause our cognitive abilities to fail. Hence, we use money as a denomination to be a summary of our preferences.&lt;/li&gt;
&lt;li&gt;Money encapsulates our preferences and priorities into a single unit of information: Price&lt;/li&gt;
&lt;li&gt;Priced-based markets have been dominating for many years, but it might not be the best to represent the market in the information age.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 4: Data-Rich Markets&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;The solution is to replace or complement price with rich and comprehensive streams of data. Rather than relying solely on price as an information, we have other sources of data to provide information as well.&lt;/li&gt;
&lt;li&gt;The difference between conventional Markets and Data-Rich Markets is the volume and variety of data flowing through it.&lt;/li&gt;
&lt;li&gt;Three technologies are required to reconfigure the market&lt;ul&gt;
&lt;li&gt;Use a standard language when comparing our preferences&lt;/li&gt;
&lt;li&gt;Better match preferences along multiple dimensions&lt;/li&gt;
&lt;li&gt;Devise effective way to comprehensively capture all our preferences&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Those 3 technologies translate rich data into effective transaction decisions&lt;/li&gt;
&lt;li&gt;One of the challenges of a Data-Rich Market is getting the labels correct for each data&lt;/li&gt;
&lt;li&gt;Transformation from a conventional Market to a Data-Rich Marker:&lt;ul&gt;
&lt;li&gt;Improvements in data ontology to extract data from multiple streams&lt;/li&gt;
&lt;li&gt;Advances in preference matching algorithms&lt;/li&gt;
&lt;li&gt;Machine Learning to identify preferences from user activity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 5: Companies and Control&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Firms aim to offer human coordination at a lower cost via economies of scale.&lt;/li&gt;
&lt;li&gt;Information flow in firms were transform from accounting for the past, to a strategic tool for future planning. Scientific Management is the term for collection and processing multiple sources of information in the firm for planning.&lt;/li&gt;
&lt;li&gt;Information and decision making in firms are centralized at the top, with a few instances of delegation.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 6: Firm Futures&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Firms persist when they operate more efficiently at organizing human effort.&lt;/li&gt;
&lt;li&gt;A focus on improving efficiency relies on two factors:&lt;ul&gt;
&lt;li&gt;Are there inefficiencies to be eliminated?&lt;/li&gt;
&lt;li&gt;What is the time period to implement the improvements? (Over a longer time, the gains get marginally smaller)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Firms can either Automate decision making, or rearrange their internal organization, which indirectly changes their decision-making structure.&lt;/li&gt;
&lt;li&gt;Restructuring of the organization is a human construct, while automation of decisions removes the decision making process away from the manager to a machine learning system.&lt;/li&gt;
&lt;li&gt;Restructuring still leaves humans in place, while automating decisions completely removes the need for humans.&lt;/li&gt;
&lt;li&gt;In future, firms may end up as one of the two forms&lt;ul&gt;
&lt;li&gt;A firm that owns most of the resources needed for operations and employs some humans, but is manged and run by machines&lt;/li&gt;
&lt;li&gt;A firm that relies on market mechanisms, but sheds away most of their organizational functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 7: Capital Decline&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;In Data-Rich Markets, consumers no longer use price as an indicator of information. Money thus loses one of it's functions, though it won't lose it's usefulness entirely.&lt;/li&gt;
&lt;li&gt;As market participants look for and consider richer data, fewer of them will rely on money, and wont be willing to pay as much for it's informational function. This is detrimental to banks.&lt;/li&gt;
&lt;li&gt;Money thus cannot convey multiple sources of information to the consumer, and the consumers must rely on other means to obtain the information&lt;/li&gt;
&lt;li&gt;As the economy shifts to being Data-Rich, most information flows will not come from the banks. Banks will still handle transactions, but it will not be the source of information as it used to be.&lt;/li&gt;
&lt;li&gt;The demise of money as the primary conveyor of information means there will be a decline in the role of Capital as well&lt;/li&gt;
&lt;li&gt;Capital conveys information. It signals that a company has assets for disposal that it can exchange for other factors of production.&lt;/li&gt;
&lt;li&gt;As markets embrace information, the two functions of capital - information and value - will be separated. It will only hold value, but not information.&lt;/li&gt;
&lt;li&gt;As capital is abundant, and fewer companies are looking for capital, this means supply of capital outstrips demand, and thus the returns on investments for capital is falling.&lt;/li&gt;
&lt;li&gt;Banks thus try to cut cost, and reinvent themselves as information intermediaries&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 8: Feedback Effects&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;There are three distinct effects at play when markets become concentrated&lt;ul&gt;
&lt;li&gt;Scale Effect - Economies of scale&lt;/li&gt;
&lt;li&gt;Network Effect - Value of service increases when more people engage in it&lt;/li&gt;
&lt;li&gt;Feedback Effect - Systems gain feedback to learn&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scale decreases cost, Network expands utility, and Feedback improves the product.&lt;/li&gt;
&lt;li&gt;Volume of data greatly increases the Feedback effect, and companies that hold monopoly over data have an advantage over smaller companies with little and poor data.&lt;/li&gt;
&lt;li&gt;Machine learning systems thus undermine competition, and data hoarding can be anti-competitive.&lt;/li&gt;
&lt;li&gt;Open algorithms are not as helpful as open data to combat anti-competitive behavior.&lt;/li&gt;
&lt;li&gt;Large companies wont lose anything when they share a small portion of their data. Their products will still improve, but you would help other smaller companies improve their products as well.&lt;/li&gt;
&lt;li&gt;Relying solely on one decision making machine learning model is also fatal, as it is a bottleneck for mistakes. There should thus also have competition for decision making systems&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 9: Unbundling Work&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Data-Rich Markets and data-driven machine learning systems are changing the way humans work. There is a decrease in the percentage of people participating in the labor force.&lt;/li&gt;
&lt;li&gt;Automation will slowly replace humans in the workforce. There are two ways to respond to this shift:&lt;ul&gt;
&lt;li&gt;Distributive&lt;/li&gt;
&lt;li&gt;Participatory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distributive: As income shifts from labor to capital, the automation income can be taxed. Example, taxing machine and computers running the machine learning models - Robotax&lt;/li&gt;
&lt;li&gt;Participatory: Retraining workers who have been made redundant.&lt;/li&gt;
&lt;li&gt;Proposal of Universal Basic Income: Just enough money for basic necessities like food, shelter and education.&lt;/li&gt;
&lt;li&gt;Not all automation replaces work, but some can help relief work and make it easier. - labor augmenting&lt;/li&gt;
&lt;li&gt;Companies that hold dominance in the market, with strong feedback, and monopoly on data lead to significant market concentration: Google, Facebook, Amazon.&lt;/li&gt;
&lt;li&gt;We need to define elements of work, and make them flexible enough to be recombined. UBI provides flexibility in the human choice when choosing work, because some tension in income requirements is alleviated.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Chapter 10: Human Choice&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Key Ideas:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;In a world of automation and machine performing decision making, what would humans do?&lt;/li&gt;
&lt;li&gt;Task of humans, is not to be efficient, like robots, but to be creative and adventurous and feel alive, unlike robots&lt;/li&gt;
&lt;li&gt;By freeing our minds very several mundane and routine decisions, we can focus on things that really matter&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;</content><category term="Big Data"></category></entry><entry><title>OS Inference through Ping TTL</title><link href="/os-inference-through-ping-ttl.html" rel="alternate"></link><published>2019-04-18T14:00:00+00:00</published><updated>2019-04-18T14:00:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-18:/os-inference-through-ping-ttl.html</id><summary type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Terminologies&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ping: An command to discover the availability of a target machine. It sends an ICMP Echo Request, and waits for an Echo Reply&lt;/li&gt;
&lt;li&gt;TTL: Time-To-Live, which tells the network routers how long the packet should live. For each router that passes the packet on, the TTL reduces by 1 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Terminologies&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ping: An command to discover the availability of a target machine. It sends an ICMP Echo Request, and waits for an Echo Reply&lt;/li&gt;
&lt;li&gt;TTL: Time-To-Live, which tells the network routers how long the packet should live. For each router that passes the packet on, the TTL reduces by 1. Once TTL reaches 0, the packet is discarded, and an ICMP message is sent to the original sender to resend the packet.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Infering OSes From TTLs&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Each OS has a different TTL for their Echo Reply packet, and based on that, we can infer what OS is sending us the reply.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lets look at what happens when we ping &lt;code&gt;google.com&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":415} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/untitled.png){.wp-image-415}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The TTL that is show there is the Echo Reply that Google has sent us, and when it has reached our machine, it was "left" with 42 TTL. So how do we find out how long the Echo Reply travelled? &lt;code&gt;tracert&lt;/code&gt;!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":416} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/untitled-1.png){.wp-image-416}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;How &lt;code&gt;tracert&lt;/code&gt; works is that it first sends out a packet with TTL 1 and incrementally bumps up that amount so that at each router, it collect the IP address information about it. When a packet reaches a router with TTL=0, it is sent back to the originating machine, along with it's (the router) IP address.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Request time out happens when the network router has specifically blocked ICMP ping request, so when a packet reaches there with TTL=0, nothing is sent back.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can see that for traffic that travel from &lt;code&gt;google.com&lt;/code&gt; to our machine takes 23 hops, and when it reached out machine, it was left with 42 TTL. With that, we can conclude that when it was sent out, it had an initial TTL of &lt;code&gt;23+42=65&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can look at the table below to find out that Linux servers using ICMP protocol has a TTL of 64, which has the closest value to ours.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Table of TTLs for each OS&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:table --&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Device /\        Version                 Protocol       TTL
  OS                                                      &lt;/p&gt;
&lt;p&gt;AIX              -                       TCP            60&lt;/p&gt;
&lt;p&gt;AIX              -                       UDP            30&lt;/p&gt;
&lt;p&gt;AIX              3.2, 4.1                ICMP           255&lt;/p&gt;
&lt;p&gt;BSDI             BSD/OS 3.1 and 4.0      ICMP           255&lt;/p&gt;
&lt;p&gt;Compa            Tru64 v5.0              ICMP           64&lt;/p&gt;
&lt;p&gt;Cisco            -                       ICMP           254&lt;/p&gt;
&lt;p&gt;DEC\             V5                      TCP and UDP    30
  Pathworks                                               &lt;/p&gt;
&lt;p&gt;Foundry          -                       ICMP           64&lt;/p&gt;
&lt;p&gt;FreeBSD          2.1R                    TCP and UDP    64&lt;/p&gt;
&lt;p&gt;FreeBSD          3.4, 4.0                ICMP           255&lt;/p&gt;
&lt;p&gt;FreeBSD          5                       ICMP           64&lt;/p&gt;
&lt;p&gt;HP-UX            9.0x                    TCP and UDP    30&lt;/p&gt;
&lt;p&gt;HP-UX            10.01                   TCP and UDP    64&lt;/p&gt;
&lt;p&gt;HP-UX            10.2                    ICMP           255&lt;/p&gt;
&lt;p&gt;HP-UX            11                      ICMP           255&lt;/p&gt;
&lt;p&gt;HP-UX            11                      TCP            64&lt;/p&gt;
&lt;p&gt;Irix             5.3                     TCP and UDP    60&lt;/p&gt;
&lt;p&gt;Irix             6.x                     TCP and UDP    60&lt;/p&gt;
&lt;p&gt;Irix             6.5.3, 6.5.8            ICMP           255&lt;/p&gt;
&lt;p&gt;juniper          -                       ICMP           64&lt;/p&gt;
&lt;p&gt;MPE/IX\          -                       ICMP           200
  (HP)                                                    &lt;/p&gt;
&lt;p&gt;Linux            2.0.x kernel            ICMP           64&lt;/p&gt;
&lt;p&gt;Linux            2.2.14 kernel           ICMP           255&lt;/p&gt;
&lt;p&gt;Linux            2.4 kernel              ICMP           255&lt;/p&gt;
&lt;p&gt;Linux            Red Hat 9               ICMP and TCP   64&lt;/p&gt;
&lt;p&gt;MacOS/MacTCP     2.0.x                   TCP and UDP    60&lt;/p&gt;
&lt;p&gt;MacOS/MacTCP     X (10.5.6)              ICMP/TCP/UDP   64&lt;/p&gt;
&lt;p&gt;NetBSD           -                       ICMP           255&lt;/p&gt;
&lt;p&gt;Netgear\         -                       ICMP and UDP   64
  FVG318                                                  &lt;/p&gt;
&lt;p&gt;OpenBSD          2.6 &amp;amp; 2.7               ICMP           255&lt;/p&gt;
&lt;p&gt;OpenVMS          07.01.2002              ICMP           255&lt;/p&gt;
&lt;p&gt;OS/2             TCP/IP 3.0              -              64&lt;/p&gt;
&lt;p&gt;OSF/1            V3.2A                   TCP            60&lt;/p&gt;
&lt;p&gt;OSF/1            V3.2A                   UDP            30&lt;/p&gt;
&lt;p&gt;Solaris          2.5.1, 2.6, 2.7, 2.8    ICMP           255&lt;/p&gt;
&lt;p&gt;Solaris          2.8                     TCP            64&lt;/p&gt;
&lt;p&gt;Stratus          TCP_OS                 ICMP           255&lt;/p&gt;
&lt;p&gt;Stratus          TCP_OS (14.2-)         TCP and UDP    30&lt;/p&gt;
&lt;p&gt;Stratus          TCP_OS (14.3+)         TCP and UDP    64&lt;/p&gt;
&lt;p&gt;Stratus          STCP                    ICMP/TCP/UDP   60&lt;/p&gt;
&lt;p&gt;SunOS            4.1.3/4.1.4             TCP and UDP    60&lt;/p&gt;
&lt;p&gt;SunOS            5.7                     ICMP and TCP   255&lt;/p&gt;
&lt;p&gt;Ultrix           V4.1/V4.2A              TCP            60&lt;/p&gt;
&lt;p&gt;Ultrix           V4.1/V4.2A              UDP            30&lt;/p&gt;
&lt;p&gt;Ultrix           V4.2 – 4.5              ICMP           255&lt;/p&gt;
&lt;p&gt;VMS/Multinet     -                       TCP and UDP    64&lt;/p&gt;
&lt;p&gt;VMS/TCPware      -                       TCP            60&lt;/p&gt;
&lt;p&gt;VMS/TCPware      -                       UDP            64&lt;/p&gt;
&lt;p&gt;VMS/Wollongong   1.1.1.1                 TCP            128&lt;/p&gt;
&lt;p&gt;VMS/Wollongong   1.1.1.1                 UDP            30&lt;/p&gt;
&lt;p&gt;VMS/UCX          -                       TCP and UDP    128&lt;/p&gt;
&lt;p&gt;Windows          for Workgroups          TCP and UDP    32&lt;/p&gt;
&lt;p&gt;Windows          95                      TCP and UDP    32&lt;/p&gt;
&lt;p&gt;Windows          98                      ICMP           32&lt;/p&gt;
&lt;p&gt;Windows          98, 98 SE               ICMP           128&lt;/p&gt;
&lt;p&gt;Windows          98                      TCP            128&lt;/p&gt;
&lt;p&gt;Windows          NT 3.51                 TCP and UDP    32&lt;/p&gt;
&lt;p&gt;Windows          NT 4.0                  TCP and UDP    128&lt;/p&gt;
&lt;p&gt;Windows          NT 4.0 SP5-             -              32&lt;/p&gt;
&lt;p&gt;Windows          NT 4.0 SP6+             -              128&lt;/p&gt;
&lt;p&gt;Windows          NT 4 WRKS SP 3, SP 6a   ICMP           128&lt;/p&gt;
&lt;p&gt;Windows          NT 4 Server SP4         ICMP           128&lt;/p&gt;
&lt;p&gt;Windows          ME                      ICMP           128&lt;/p&gt;
&lt;p&gt;Windows          2000 pro                ICMP/TCP/UDP   128&lt;/p&gt;
&lt;p&gt;Windows          2000 family             ICMP           128&lt;/p&gt;
&lt;p&gt;Windows          Server 2003             -              128&lt;/p&gt;
&lt;p&gt;Windows          XP                      ICMP/TCP/UDP   128&lt;/p&gt;
&lt;p&gt;Windows          Vista                   ICMP/TCP/UDP   128&lt;/p&gt;
&lt;p&gt;Windows          7                       ICMP/TCP/UDP   128&lt;/p&gt;
&lt;p&gt;Windows          Server 2008             ICMP/TCP/UDP   128&lt;/p&gt;
&lt;p&gt;Windows          10                      ICMP/TCP/UDP   128&lt;/p&gt;
&lt;hr&gt;
&lt;!-- /wp:table --&gt;</content></entry><entry><title>How to harden a Linux Kernel</title><link href="/how-to-harden-a-linux-kernel.html" rel="alternate"></link><published>2019-04-17T11:21:00+00:00</published><updated>2019-04-17T11:21:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-17:/how-to-harden-a-linux-kernel.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Hardening means to make the something more secure and resilient to attacks. When people talk about hardening, they usually talk about server hardening, which includes things like&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;IP / MAC address white listing&lt;/li&gt;
&lt;li&gt;Closing unused ports&lt;/li&gt;
&lt;li&gt;Uninstalling unused systems&lt;/li&gt;
&lt;li&gt;Disabling &lt;code&gt;root&lt;/code&gt; login (no one can login as root, only a normal …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Hardening means to make the something more secure and resilient to attacks. When people talk about hardening, they usually talk about server hardening, which includes things like&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;IP / MAC address white listing&lt;/li&gt;
&lt;li&gt;Closing unused ports&lt;/li&gt;
&lt;li&gt;Uninstalling unused systems&lt;/li&gt;
&lt;li&gt;Disabling &lt;code&gt;root&lt;/code&gt; login (no one can login as root, only a normal user who can &lt;code&gt;sudo&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These are legitimate areas of hardening, but another area of hardening involves securing the kernel itself at compile time. This deals with much lower level of security such as Address Space Layout Randomization (ASLR) or Read/Write permissions at different memory regions (SMEP/SMAP). In this post, I'll be writing about these 2 technologies.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Kernel Level Hardening&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;Kernel Address Space Layout Randomization (KASLR)&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;ASLR is a memory protection technique that randomizes the address layout of the executables that are loaded in memory. How this prevent an attack is to disallow memory space predictability.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;An attacker, if he knows your target OS (example Ubuntu 14.04), he can spin up the exact same OS in his testing environment. If there is no ASLR, the executables such as &lt;code&gt;glibc&lt;/code&gt; will be loaded in the same address space every time, allowing him to make an exploit targeting predictable addresses.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;With ASLR, the executable will always be in a different address space, and it will cause the kernel to crash (Memory access violation) if an exploit runs.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;ASLR can be configured at &lt;code&gt;/proc/sys/kernel/randomize_va_space&lt;/code&gt; with the following values:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;0 - No Randomization: All addresses are static&lt;/li&gt;
&lt;li&gt;1 - Conserved Randomization:&lt;ul&gt;
&lt;li&gt;Stack ASLR: Each execution of a program results in different stack memory layout&lt;/li&gt;
&lt;li&gt;LIBS/MMAP ASLR: Each execution of a program results in different &lt;code&gt;mmap&lt;/code&gt; memory space layout&lt;/li&gt;
&lt;li&gt;EXEC ASLR: Each program that was complied with &lt;code&gt;-fPIE -pie&lt;/code&gt;, which stands for Position Independent Executables, will get loaded into different memory locations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2 - Full Randomization: &lt;code&gt;brk&lt;/code&gt; ASLR&lt;ul&gt;
&lt;li&gt;All of the above, including &lt;code&gt;brk&lt;/code&gt; ASLR&lt;/li&gt;
&lt;li&gt;Previously, &lt;code&gt;brk&lt;/code&gt; memory areas were always allocated after the EXEC memory area&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brk&lt;/code&gt; ASLR randomizes the &lt;code&gt;brk&lt;/code&gt; memory area relative to the EXEC memory area&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Possible Exploits: One of the weakness of ASLR is that even though the libraries and executables are randomly located within the memory space, within the library, the functions are still at a fixed offset. This means that if the attack want to leverage on a &lt;code&gt;glibc&lt;/code&gt; function, all he has to do is find the starting point of &lt;code&gt;glibc&lt;/code&gt;, and the function will always be at the same offset&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;SMEP/SMAP&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Supervisor Mode Execution Protection (SMEP) and Supervisor Mode Access Prevention (SMAP) are techniques to prevent unauthorized memory access.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SMAP prevents supervisor mode from accessing (rw) user-space memory space.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SMEP prevents user mode from executing (x) in kernel memory space&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SMAP is important because while you're in kernel space, you have full privileges to perform any actions. If we allow this privilege to "escape" and return to user-space memory, he can perform even more unauthorized actions and get user data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SMEP is important for similar reasons, where the user cannot execute in kernel space to perform unprivileged actions affecting the kernel.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Possible Exploits: Linux kernel has a function &lt;code&gt;native_write_cr4&lt;/code&gt; which can overwrite bits in the CR4 control register. One of the bit controls if SMEP/SMAP is on or off. If the attack can call the function to overwrite the bits in the control register, he can turn of SMEP/SMAP&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;</content><category term="ASLR"></category><category term="SMAP"></category><category term="SMEP"></category></entry><entry><title>Activation Functions</title><link href="/activation-functions.html" rel="alternate"></link><published>2019-04-14T18:07:00+00:00</published><updated>2019-04-14T18:07:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-14:/activation-functions.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The structure of a deep learning model consists mainly of nodes, and connections between them. Most of the time, every single node is connected to every other node in the next layer, which we call a Dense layer.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":260,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/01/2.png){.wp-image-260}  
&lt;figcaption&gt;
Nodes in a fully connected …&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The structure of a deep learning model consists mainly of nodes, and connections between them. Most of the time, every single node is connected to every other node in the next layer, which we call a Dense layer.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":260,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/01/2.png){.wp-image-260}  
&lt;figcaption&gt;
Nodes in a fully connected neural network
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Within each node is a mathematical equation, decides, based on the input values and their weights, what values to output to the next layer. These mathematical equations are called Activation Functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":261,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/01/3.png){.wp-image-261}  
&lt;figcaption&gt;
The activation function is in the middle box, which performs an operation on the inputs, z, based on their weights and bias value.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Different Activation Functions&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;There are several kinds of Activation Functions, or in other words, different kinds of mathematical operations that a node can take. They are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Sigmoid Function&lt;/li&gt;
&lt;li&gt;Tanh Function&lt;/li&gt;
&lt;li&gt;ReLU Function&lt;/li&gt;
&lt;li&gt;Leaky ReLU Function&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:image {"id":262,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/01/4.png){.wp-image-262}  
&lt;figcaption&gt;
Different Activation Functions and their mathematical equations
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These activation functions take in the inputs &lt;code&gt;z&lt;/code&gt; from the previous layer, and feed it into their equations to produce an output &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Sigmoid vs TanH&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The TanH function is almost strictly superior to the Sigmoid function, because the TanH function has it's mean centered at &lt;code&gt;0&lt;/code&gt;. This feature will result in a higher value of derivative, and a faster learning rate. Also, having a &lt;code&gt;0&lt;/code&gt; value mean will avoid having bias in the gradients.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;ReLU vs (Sigmoid + TanH)&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The drawback of both Sigmoid and TanH, given that they have a curved graph, is that if the value of &lt;code&gt;z&lt;/code&gt; is either extremely large or small, the gradient on the curve will be extremely small as well. This small gradient will have an adverse effect on the learning rate when performing Gradient Descent.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The solution to this is ReLU (Rectified Linear Unit), which has a constant gradient regardless of the value of &lt;code&gt;z&lt;/code&gt;. But for ReLU, having a negative value of &lt;code&gt;z&lt;/code&gt; will result in a &lt;code&gt;0&lt;/code&gt; value activation. The solution for that is a Leaky ReLU, which allows for a small value of &lt;code&gt;a&lt;/code&gt; for negative values of &lt;code&gt;z&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Must they Always be Non-Linear?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Yes, Activation Function must always be non-linear. Having multiple linear activation functions can be condensed together, effectively negating the need for any hidden layers or hidden nodes.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In this post, we talked very briefly about the different kinds of Activation Functions, and compared their pro and cons.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A recommendation for building a neural network model is to have the hidden nodes all be either TanH or ReLU, and never having Sigmoid.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The only time you can have a Sigmoid is at your output layer, if your problem is a binary classification problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Activation Functions"></category></entry><entry><title>The Interpretation of ROC and AUC</title><link href="/the-interpretation-of-roc-and-auc.html" rel="alternate"></link><published>2019-04-14T12:52:00+00:00</published><updated>2019-04-14T12:52:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-14:/the-interpretation-of-roc-and-auc.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The ROC curve and it's AUC is a common metric for evaluation the performance of a model. In this post, we dig deeper to find out how to interpret the results, and what corrective actions to take to improve it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is it?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The ROC curve, or Receiver Operating Characteristic …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The ROC curve and it's AUC is a common metric for evaluation the performance of a model. In this post, we dig deeper to find out how to interpret the results, and what corrective actions to take to improve it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is it?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The ROC curve, or Receiver Operating Characteristic curve works on binary classification problems (True or False). It plots the following values against each other:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;True Positive Rate (TPR): Of those sample that are true, how many did I predict are true? This is also known as Recall (&lt;code&gt;TP/P&lt;/code&gt;, where &lt;code&gt;TP&lt;/code&gt; is how many True samples predicted True, and &lt;code&gt;P&lt;/code&gt; is the total number of True samples)&lt;/li&gt;
&lt;li&gt;False Positive Rate (FPR): Of those samples that are false, how many did I predict are true? This is also known as False Alarms (&lt;code&gt;FP/N&lt;/code&gt;, where &lt;code&gt;FP&lt;/code&gt; is how many False samples predicted True, and &lt;code&gt;N&lt;/code&gt; is the total number of False samples)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;So... What is it?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Now that we got the formal definitions out of the way, lets talk about the intuition behind the ROC and AUC.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The TPR is also called &lt;strong&gt;sensitivity&lt;/strong&gt;, which means how many in the &lt;strong&gt;true positives&lt;/strong&gt; have I identified to be &lt;strong&gt;True&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;TNR (True Negative Rate) is also called &lt;strong&gt;specificity&lt;/strong&gt;, which means how many in the &lt;strong&gt;true negatives&lt;/strong&gt; have I identified to be &lt;strong&gt;False&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;FPR is (&lt;code&gt;1 - TNR&lt;/code&gt;), which means how many in the &lt;strong&gt;true negatives&lt;/strong&gt; have I identified to be &lt;strong&gt;True&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The ROC curve plots TPR against FPR.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":257,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/01/roc-curves.png){.wp-image-257}  
&lt;figcaption&gt;
Plotting the TPR against the FPR. There are 4 scenarios here
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The top left graph shows the perfect scenario, where the Area Under Curve (AUC) is 1. This means that the model has 100% TPR, regardless of my FPR rate, and correctly classifies all True samples as True.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The bottom right graph shows a random classifier, which is randomly separated.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The question to ask is: what is the lowest possible FPR, that can give me the highest FPR?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If we look at the perfect scenario, the highest possible TPR corresponds to an almost 0 FPR. That's perfect! It means the model made no classification errors (Excellent Precision and Recall)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Looking at the random separation, the highest TPR corresponds to the highest FPR, which is horrible. It means that for my model to get a good Recall, I must predict all my False samples to be True as well.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;A good model will thus have a lower FPR that will give a reasonable TPR (Reasonable here depends on the scenario and use case).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Another way to look at it is, to get a good Recall, what is the amount of Precision I have to sacrifice.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the model has to sacrifice a lot of Precision to get a good Recall, then it is a bad model. If the model does not have to sacrifice any Precision (In the case of the perfect scenario), then it is a good model.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>Hosting your own DNS (and how to setup DNS tunneling)</title><link href="/hosting-your-own-dns-and-how-to-setup-dns-tunneling.html" rel="alternate"></link><published>2019-04-11T11:23:00+00:00</published><updated>2019-04-11T11:23:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-11:/hosting-your-own-dns-and-how-to-setup-dns-tunneling.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Earlier this week, I wrote a post on DNS tunneling, and how to pass information over the web through the DNS protocol by stuffing information in the DNS Name Resolution process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to look at how to setup and host your own DNS server. And because …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Earlier this week, I wrote a post on DNS tunneling, and how to pass information over the web through the DNS protocol by stuffing information in the DNS Name Resolution process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to look at how to setup and host your own DNS server. And because you're hosting it, you can essentially choose to reply whatever you want to the subject querying you.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Components&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list {"ordered":true} --&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;VM with a static IP address, and allowed ingress/egress connections for port 53.&lt;ul&gt;
&lt;li&gt;For this, I spun up a VM on GCP with minimal settings to reduce the cost&lt;/li&gt;
&lt;li&gt;I used a Linux based image because I planned to use bind9 for my DNS (https://wiki.debian.org/Bind9)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A Domain name&lt;ul&gt;
&lt;li&gt;Head over to &lt;code&gt;my.freenom.com&lt;/code&gt; for a free domain name with a &lt;code&gt;.tk&lt;/code&gt; TLD&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Concepts&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNS Resolution&lt;ul&gt;
&lt;li&gt;When you send a query for a domain name, it queries your DNS for the corresponding IP address tied to the domain name&lt;/li&gt;
&lt;li&gt;Your DNS server then queries the Root Servers, which are DNS servers who hold information about the TLDs such as &lt;code&gt;.com&lt;/code&gt; or &lt;code&gt;.tk&lt;/code&gt;, and redirects your query to the TLD Server&lt;/li&gt;
&lt;li&gt;The TLD Server stores information about your second level domains. The &lt;code&gt;.com&lt;/code&gt; server will store information such as &lt;code&gt;facebook.com&lt;/code&gt; or &lt;code&gt;google.com&lt;/code&gt;. In our case, we're using the &lt;code&gt;.tk&lt;/code&gt; domain, so the &lt;code&gt;.tk&lt;/code&gt; server will hold our website information &lt;code&gt;dnsserver.tk&lt;/code&gt;. The TLD server defers the query to &lt;code&gt;dnsserver.tk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dnsserver.tk&lt;/code&gt; is known as the Authoritative Server, which gives the authoritative response of the IP address&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DNS Glue Record&lt;ul&gt;
&lt;li&gt;A DNS glue record is used for preventing circular dependencies&lt;/li&gt;
&lt;li&gt;This is important when your DNS server is a subdomain of your domain name itself. e.g. &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt; is a subdomain of &lt;code&gt;dnsserver.tk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The circular dependency happens when we ask for the IP address of &lt;code&gt;dnsserver.tk&lt;/code&gt;, and it tells you to ask it's DNS server &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;. But in order to query &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;, you need the IP address of &lt;code&gt;dnsserver.tk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To solve this issue, we "glue" the IP address of &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Now, instead of asking you to query &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;, it'll give you the IP address of &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt; directly, breaking the circular dependency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Execution&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;GCP&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We will need to spin up the VM, get it's static IP, and host a DNS server on it. this VM will be our &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You can follow this guide on how to setup bind9 on your VM https://www.digitalocean.com/community/tutorials/how-to-configure-bind-as-an-authoritative-only-dns-server-on-ubuntu-14-04&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;On your GCP console, you have to do 2 things&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Open ports 53 to allow DNS traffic to flow through&lt;/li&gt;
&lt;li&gt;Set your IP address to static, instead of ephemeral&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Domain name console&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When you register for a new domain name, you can usually configure it. The free domain name we got from &lt;code&gt;my.freenom.com&lt;/code&gt; allows your to specify your own Nameserver and glue records.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've attached screen grabs on how to point the Nameservers to your &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt;, and how to glue your IP address to &lt;code&gt;ns1.dnsserver.tk&lt;/code&gt; for breaking circular dependency&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":405} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/2.png){.wp-image-405}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When setting up your glue records for the Nameservers, you can use the same IP address for both records. You need 2 records because when you specify new Nameserver, you need to input minimally 2 records&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":406} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/1.png){.wp-image-406}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Instead of letting Freenom Nameservers to be the authoritative Nameserver, point it to your Nameservers your are hosting.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When you set a new Nameserver, you need to wait a few hours for it to propagate the information over to other DNS servers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In your DNS server, you can choose to return whatever you want when a DNS request comes to your server. In this way, it can be possible to craft it as a C2 communication server. I won't go into details on how to set that up, but this is one of the steps.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="DNS"></category></entry><entry><title>UEFI and Secure Boot</title><link href="/uefi-and-secure-boot.html" rel="alternate"></link><published>2019-04-09T16:12:00+00:00</published><updated>2019-04-09T16:12:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-09:/uefi-and-secure-boot.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Secure Boot is a verification mechanism to ensure that code launched by the firmware is trusted. It ensures that all system level drivers are signed and trusted.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before we talk about secure boot and how it works, we need to have some understand of UEFI (Unified Extensible Firmware Interface)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Overview …&lt;/h3&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Secure Boot is a verification mechanism to ensure that code launched by the firmware is trusted. It ensures that all system level drivers are signed and trusted.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before we talk about secure boot and how it works, we need to have some understand of UEFI (Unified Extensible Firmware Interface)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Overview of BIOS and UEFI&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Both UEFI and BIOS are firmwares, and are programs that run upon booting your system.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;UEFI provides faster boot time, more security features (such as Secure Boot), and a more usable graphical interface. Below shows the visual difference between BIOS and UEFI:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":398} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/04/ximg_5913814ed5e9f.png.pagespeed.gpjpjwpjwsjsrjrprwricpmd.ic_.9qc4wyodnr.png){.wp-image-398}

&lt;figcaption&gt;
Side by side visual comparison of BIOS and UEFI

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The typical sequence for the BIOS when booting up is:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Perform POST (Power-On Self Test), which checks that the hardware configuration is proper&lt;/li&gt;
&lt;li&gt;Look for the MBR (Master Boot Record) on the boot device to launch the boot loader&lt;/li&gt;
&lt;li&gt;Boot loader then launches the Operating System&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;On the other hand, UEFI boots the system by launching EFI's (Extensible Firmware Interfaces) executables, as opposed to running the MBR.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Drawbacks of BIOS&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Some major drawbacks of BIOS booting are it can only boot from an MBR-partitioned disk, and the MBR-partitioned disk can only support up to 2TB of partitions. What this means is that if you use a disk bigger than 2TB as your boot loader, it will only show that it has 2TB of space.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;GPT partitioning can support partitions more than 2TB, but BIOS cannot boot from GPT-partitioned disk, only MBR-partitioned disk&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, BIOS runs in 16-bit processor mode, and only has 1MB of memory space to execute in. As such due to its limited space, it cannot initialize multiple hardware at once, which leads to a slower boot time.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These drawbacks are solved by UEFI&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;UEFI&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;One of the biggest change is that the UEFI can run in 32-bit or 64-bit mode, which has way more address space, and is able to boot a lot faster. It also has other features such as&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Being able to boot from a GPT-partitioned disk, hence being able to support disks more than 2TB&lt;/li&gt;
&lt;li&gt;Giving a nice GUI&lt;/li&gt;
&lt;li&gt;Secure Boot feature (more on this later)&lt;/li&gt;
&lt;li&gt;Network boot&lt;/li&gt;
&lt;li&gt;Firmware specification&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Just like the BIOS which targets the MBR to boot up the OS, UEFI marks one of the GPT-partition with a boot flag, and that partition becomes an EFI partition with its own EFI filesystem in FAT32 format.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The layout of the EFI filesystem is such that every OS has its own directory, which stores all the necessary files for loading the OS&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EFI&lt;/span&gt;
    &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Boot&lt;/span&gt;
    &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Microsoft&lt;/span&gt;
    &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Ubuntu&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;UEFI Legacy Mode&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Operating Systems that are installed in BIOS mode cannot be booted using UEFI, vice-versa. To boot a BIOS install OS in UEFI mode, you have to reinstall the entire system. To get around this hassle, UEFI supports legacy mode&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;UEFI Legacy will make the UEFI act just like a BIOS, and this throws away many of the features such as Fast Boot and Secure Boot. UEFI Legacy allows the system to boot from MBR-partitioned disks, and allows booting to be not from EFI partitions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Secure Boot&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Advanced malwares target the bootloader as a vector of attack, which launches their malicious process before the OS is launched.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Secure Boot is a feature in UEFI which aims to make the booting process more secure by disallowing unsigned code to run in the pre-boot phase. Secure Boot only allows signed bootloaders and drivers that are trusted by the Original Equipment Manufacturer (OEM) to run.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When the PC first runs, it checks the signature of each piece of booting software. If the signatures are valid, then the firmware passes control to the OS.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The OEMs creates Secure Boot keys and store them on the firmware, which are used for the verification process of Secure Boot.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Secure Boot is also customizable, and you can control which signing certificates are present for checking. You can install or remove certificates that Secure Boot uses for checking. For example, if an organization uses Linux, they can remove all of Microsoft's certificates, and install their own organization's certificate in place. Secure Boot then uses those certificates for verification.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This customization is also available to any individual user, where you can sign your own bootloader and device drivers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Secure Boot and Linux&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The whole concept of Secure Boot was built around Microsoft systems, and Linux distros were not made in mind for this. As such, there were a few hurdles to overcome when applying Secure Boot to Linux distros.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The first money grabbing move by Microsoft was to let Linux distros pay a one-time fee of \$99 on Microsoft Sysdev Portal to apply for their bootloaders to be signed and recognized by Secure Boot. This way, these Linux distros work with Secure Boot out-of-the-box in the machines.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In Linux, it's common for developers to develop their own third party modules, which are all unsigned, and will be rejected by the system when trying to &lt;code&gt;insmod&lt;/code&gt; them. Linux therefore provides a way to sign their custom binaries or modules using the command &lt;code&gt;sbsign&lt;/code&gt; and &lt;code&gt;kmodsign&lt;/code&gt; respectively.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;</content><category term="Secure Boot"></category><category term="UEFI"></category></entry><entry><title>What is a CGI?</title><link href="/what-is-a-cgi.html" rel="alternate"></link><published>2019-04-08T17:11:00+00:00</published><updated>2019-04-08T17:11:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-08:/what-is-a-cgi.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Not Computer Generated Imagery, but &lt;code&gt;cgi&lt;/code&gt; pages you see when you visit webpages.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CGI stands for Common Gateway Interface, and it acts as the Controller in the MVC framework. To give a complete picture, in a web application, the Model is the database, the View is the front-end HTML/CSS …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Not Computer Generated Imagery, but &lt;code&gt;cgi&lt;/code&gt; pages you see when you visit webpages.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CGI stands for Common Gateway Interface, and it acts as the Controller in the MVC framework. To give a complete picture, in a web application, the Model is the database, the View is the front-end HTML/CSS, and the Controller is the logic that processes user interaction&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The CGI program takes in input from the user via the webpage, does the processing, and outputs information back to the front-end.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":392,"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![]({attach}media/2019/04/cgi.gif){.wp-image-392}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CGI is a generic name for any program, or script that runs at the back end to process the user input. This program can be written in languages such as Python, C or C++. An example of a Python CGI is:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;http://www.test.com/cgi-bin/hello.py?key1=value1&amp;amp;key2=value2&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Programming vs CGI Programming&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Most of us are familiar and have experience with the languages mentioned above, but there is a difference between conventional programming with those languages, and programming to conform to CGI standard.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below shows a code snippet of CGI programming in Python:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/python&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Content-type:text/html&lt;/span&gt;&lt;span class="se"&gt;\r\n\r\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;html&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;head&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;title&amp;gt;Hello Word - First CGI Program&amp;lt;/title&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;/head&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;body&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;h2&amp;gt;Hello Word! This is my first CGI program&amp;lt;/h2&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;/body&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;/html&amp;gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are two main differences here:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;The CGI program must start with a MIME-type header.&lt;ul&gt;
&lt;li&gt;MIME, which stands for &lt;strong&gt;Multipurpose Internet Mail Extensions&lt;/strong&gt; is a HTTP header which tells the client what sort of content it's receiving.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;print "Content-type:text/html\r\n\r\n"&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The content of the output must be in HTML format, or other formats that the browser is able to display&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;CGI Environment Variables&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When programming a CGI program, there are some environment variables that are standard across all CGI, regardless of languages used.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Some examples of these are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:table --&gt;

&lt;hr&gt;
&lt;p&gt;HTTP_COOKIE        The visitor's cookie, if one is set
  HTTP_HOST          The hostname of the page being attempted
  HTTP_REFERER       The URL of the page that called your program
  HTTP_USER_AGENT   The browser type of the visitor&lt;/p&gt;
&lt;hr&gt;
&lt;!-- /wp:table --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You can see the full list of CGI environment variables by searching it online.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;CGI Vulnerabilities&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Most CGI vulnerabilities lie in the fast that the inputs from the users are not properly checked and parsed. As a result, the user can perform unintended actions on your server such as directory traversal or RCE.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="cgi"></category></entry><entry><title>Domain Generating Algorithm (Used by C2 Communication)</title><link href="/domain-generating-algorithm-used-by-c2-communication.html" rel="alternate"></link><published>2019-04-07T16:46:00+00:00</published><updated>2019-04-07T16:46:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-07:/domain-generating-algorithm-used-by-c2-communication.html</id><summary type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;C2 Communication and Disruption&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When a machine gets infected by a malware, it can start receiving command from it's C2 server to perform unwanted activities. Examples of this are a machines infected with botnets or ransomware, where the C2 server will send commands down to the victim machine, and the …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;C2 Communication and Disruption&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When a machine gets infected by a malware, it can start receiving command from it's C2 server to perform unwanted activities. Examples of this are a machines infected with botnets or ransomware, where the C2 server will send commands down to the victim machine, and the machines can send replies back.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The easiest way to tackle this problem is to disrupt the communication between the C2 and the victim machine, and one of this is to either take down the C2 server, or block all traffic that is going to that specific IP address.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How Malwares Overcome Communication Disruption&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Bad actors are well aware of this problem of having a single static IP or server for their C2, and they know that if this single IP is block or the server is taken down, their infected machines have no where to receive commands from.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;How they overcome this is by having their malware communicate with different domains instead of a single static one. This act is called &lt;strong&gt;"Domain Fluxing&lt;/strong&gt;", or &lt;strong&gt;"Fast Fluxing"&lt;/strong&gt;, where the malware communicates with different C2 servers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The process of generating multiple domains for their malware to connect to is called &lt;strong&gt;"Domain Generation Algorithm" (DGA)&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;DGA in Action&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;DGAs automatically generate multiple domains that the malware can communicate to. These DGA's have to be random enough, so that defenders cannot predict what list of domains to block. For example, if a malware is dumb enough to change their list of domains to "badserver1", "badserver2" ... Defenders just have to block "badserver*", and that will cover all the list of C2 servers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Dumb DGAs will also generate jibberish domains, which can be spotted easily by analyst, or smart NLP models. Domains such as "dsawkkl.com" generated randomly is obviously a malicious domain.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Smarter DGAs will pluck and piece together words that make sense, such as "Birds.com", "Elephant.com" or "Tiger.com". But this also has a downside, as its obvious that their seed for generating the names are animals. Really advanced DGAs will use and NLP text generator model, and a random seed generator to produce really legitimate looking domains that can fool both the analyst, and models.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below is an example code to generate random domains&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;generate_domain&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;year&lt;/span&gt;, &lt;span class="nv"&gt;month&lt;/span&gt;, &lt;span class="nv"&gt;day&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Generates a domain name for the given date.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="nv"&gt;domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
        &lt;span class="nv"&gt;year&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;year&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;year&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;year&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nv"&gt;xFFFFFFF0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;month&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;month&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;month&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;month&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nv"&gt;xFFFFFFF8&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;day&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;day&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;day&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;day&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nv"&gt;xFFFFFFFE&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;domain&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nv"&gt;chr&lt;/span&gt;&lt;span class="ss"&gt;(((&lt;/span&gt;&lt;span class="nv"&gt;year&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="nv"&gt;month&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="nv"&gt;day&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;97&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Malwares need to communicate with C2's for commands. It's easy to block a single domain, or list of correlated domains.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Malwares therefore need sophisticated DGAs to come up with unpredictable domains for their C2 server.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Domain Generation Algorithm"></category></entry><entry><title>Regularization</title><link href="/regularization.html" rel="alternate"></link><published>2019-04-07T09:49:00+00:00</published><updated>2019-04-07T09:49:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-07:/regularization.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One of the major problems in training a model in machine learning is overfitting. Especially when your model gets more and more complex, it starts to memorize the patterns in the training data. This makes it perform poorly on unseen data, which has new patterns.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Overfitting is the result of …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One of the major problems in training a model in machine learning is overfitting. Especially when your model gets more and more complex, it starts to memorize the patterns in the training data. This makes it perform poorly on unseen data, which has new patterns.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Overfitting is the result of low-bias and high-variance, where it performs well for a single data set, but given new data, the error fluctuates. That means that the model is learning too much for each data set.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One of the ways to overcome overfitting is Regularization&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is Regularization&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The mathematical definition of Regularization is the process of adding information in order to solve ill-posed problems, or to prevent overfitting. Ill-posed meaning that the solution is highly sensitive to the changes in the data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":248,"align":"center","width":238,"height":228} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2019/01/1280px-regularization.png){.wp-image-248 width="238" height="228"}  
&lt;figcaption&gt;
The blue line shows the model before regularization, while the green line shows the model after regularization.  

Regularization makes the model less complex.  
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By introducing regularization, we reduce the complexity of the learned model. This means that we're reducing the accuracy of the model for a given data set, but in doing so we're making it generalize across data sets. This action reduces variance, while not changing your bias too much, and bring us to the idea situation of low-bias low-variance.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Regularization in Machine Learning&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To put this into a machine learning context, for each model we use, we have a loss function we wish to minimize. We'll use the RSS (Residual Sum Squares) loss function in this example.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":249} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/rss.png){.wp-image-249}

&lt;figcaption&gt;
RSS loss function we want to minimize

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This will calculate how much to adjust your parameters based on your training data. But if your training data has noise, then your parameters will be adjusted to pick up the noise, and your model will be optimized towards the noise in the data. That's overfitting.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;To combat this, we add in a regularization factor, which will shrink the estimated value to adjust your parameters. This way, your parameters won't move too much towards learning the noise in the data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Ridge Regression (L2)&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":250} --&gt;&lt;/p&gt;
&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/ridge.png){.wp-image-250}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Ridge Regression adds a shrinkage quantity to the original loss function RSS. This works by preventing the change in parameters from being too high in value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When &lt;em&gt;λ = 0&lt;/em&gt; , the penalty term is essentially taken out. Your estimated value to modify the parameters will then simply be RSS&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When &lt;strong&gt;&lt;em&gt;λ→∞&lt;/em&gt;&lt;/strong&gt;, the penalty term, the penalty term grows large, and your estimated value to modify the parameters will approach 0. (But never being 0). Because it never reaches 0, the impact of those noisy features will only be minimized, but never removed.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Lasso Regression (L1)&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:image {"id":251} --&gt;&lt;/p&gt;
&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/lasso.png){.wp-image-251}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lasso Regression also adds a shrinkage quantity, but the difference is that it only penalizes high valued coefficients.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The penalty term uses &lt;strong&gt;&lt;em&gt;|β1|&lt;/em&gt;&lt;/strong&gt; instead of &lt;strong&gt;&lt;em&gt;β1²&lt;/em&gt;&lt;/strong&gt; , hence it is named L1, while&lt;br&gt;
Ridge regularization is named L2.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lasso also differs from from Ridge in that it can set coefficients to 0, making them not relevant at all. In the end, because the coefficients are 0, you may end up with lesser features, which is an advantage!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Regularization in Deep Learning - Drop Out&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Regularization in deep learning is slightly different from shallow learning.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In deep learning, we have neurons that are for the most times fully connected. That's to say, every single neuron is connected to every other neuron in the next layer.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This may cause some problems like overfitting again, because the neurons may develop false co-dependencies among each other (which may be due to noise).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Regularization in deep learning works by occasionally ignoring a fraction of the neurons during the training phase.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":252} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/dropout.png){.wp-image-252}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;By using dropout, you're forcing the model to learn more robust features, as opposed to random combinations of neurons. Also, it roughly doubles the number of iterations required to converge.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To conclude, we've talked about methods in shallow learning and deep learning to combat overfitting by regularization.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Regularization is the process of adding new information to reduce the value to modify the parameters. This prevents it from learning any noise that is specific to the data set, and reduce the chances of overfitting&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="drop out"></category><category term="regularization"></category></entry><entry><title>Process Injection</title><link href="/process-injection.html" rel="alternate"></link><published>2019-04-05T14:44:00+00:00</published><updated>2019-04-05T14:44:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-04-05:/process-injection.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I decided to revisit some fundamental security concepts again, and one of which I used in my previous employment was Process Injection.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Process Injection is a technique of running your own code within the address space of another process. The hard part is getting your code in that address space …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I decided to revisit some fundamental security concepts again, and one of which I used in my previous employment was Process Injection.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Process Injection is a technique of running your own code within the address space of another process. The hard part is getting your code in that address space, but there are numerous ways to achieve this&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;DLL Injection&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The malware write the address pointing to its own DLL into the virtual address space of another process. The DLL is then executed by creating a remote thread within the process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The steps performed to achieve this are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Finding a process to hijack using &lt;code&gt;Process32First&lt;/code&gt; and &lt;code&gt;Process32Next&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Getting a handle of the target process with &lt;code&gt;OpenProcess&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Allocating memory and writing the path to malicious DLL using &lt;code&gt;VirtualAllocEx&lt;/code&gt; and &lt;code&gt;WriteProcessMemory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Code execution in the process by calling &lt;code&gt;CreateRemoteThread&lt;/code&gt;, &lt;code&gt;NtCreateThreadEx&lt;/code&gt; or &lt;code&gt;RtlCreateUserThread&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;PE Injection&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Instead of passing the address of the DLL, the malware can directly copy malicious the code into the process. The code is then executed via &lt;code&gt;CreateRemoteThread&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The steps performed to achieve this are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Finding a process to hijack using &lt;code&gt;Process32First&lt;/code&gt; and &lt;code&gt;Process32Next&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Getting a handle of the target process with &lt;code&gt;OpenProcess&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Allocating memory and writing the malicious code using &lt;code&gt;VirtualAllocEx&lt;/code&gt; and &lt;code&gt;WriteProcessMemory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Code execution in the process by calling &lt;code&gt;CreateRemoteThread&lt;/code&gt;, &lt;code&gt;NtCreateThreadEx&lt;/code&gt; or &lt;code&gt;RtlCreateUserThread&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The difference here is in step 3, where the code is copied, instead of the reference to the code. This method does not require dropping a DLL onto the machine.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Process Hollowing&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Instead of injecting the address of the DLL, or copying the malicious code into the target process, malware can also overwrite the original code in the memory space of the process. This is called Process Hollowing.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The steps performed to achieve this are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Create a new process in suspended mode to host the malicious code&lt;/li&gt;
&lt;li&gt;Done by calling &lt;code&gt;CreateProcess&lt;/code&gt; with the flag &lt;code&gt;CREATE_SUSPEND&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Unmap memory of target process by calling &lt;code&gt;ZwUnmapViewOfSection&lt;/code&gt; or &lt;code&gt;NtUnmapViewOfSection&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Allocate new memory for malware using &lt;code&gt;VirtualAllocEx&lt;/code&gt; and write the code using &lt;code&gt;WriteProcessMemory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Point the entry point of the suspended process to the code in the target process using &lt;code&gt;SetThreadContext&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Resume suspended process by calling &lt;code&gt;ResumeThread&lt;/code&gt; which executes the code in the target process&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Thread Execution Hijacking (Suspend, Inject, Resume)&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Instead of creating a new process that is suspended like Process Hollowing, Thread Execution Hijacking avoids creating a new process.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The steps performed to achieve this are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Get a handle to the target process&lt;/li&gt;
&lt;li&gt;Suspend the target process by calling &lt;code&gt;SuspendThread&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Write malicious code in the target process by calling &lt;code&gt;VirtualAllocEx&lt;/code&gt; and &lt;code&gt;WriteProcessMemory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Resume the running of the process by calling &lt;code&gt;ResumeThread&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;SIR are problematic because suspending a process mid-execution may cause the system to crash.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Hook Injection via &lt;code&gt;SetWindowsHookEx&lt;/code&gt;&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Hooking is a technique to intercept function calls, and load their malicious DLL upon a certain event getting triggered within a specific thread.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;SetWindowsHookEx&lt;/code&gt; is called to install a hook routine into the hook chain. One of the arguments that &lt;code&gt;SetWindowsHookEx&lt;/code&gt; takes is a &lt;code&gt;threadID&lt;/code&gt; with which this hook procedure is associated with. If this value is set to &lt;code&gt;0&lt;/code&gt;, all threads within the process perform the action when the event is triggered. To generate less noise, 1 thread is usually targeted.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once the DLL is injected, the malware executes the malicious code on behalf of the process of the &lt;code&gt;threadID&lt;/code&gt; that was passed into the &lt;code&gt;SetWindowsHookEx&lt;/code&gt; function.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Injection and Persistence via Registry Modification&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Malwares can insert their malicious libraries under &lt;code&gt;Appinit_Dlls&lt;/code&gt; to have other processes load their libraries. Every library under this registry key is loaded into any process that calls &lt;code&gt;User32.dll&lt;/code&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Malwares can also put their libraries under &lt;code&gt;AppCertDlls&lt;/code&gt;, which affects any process that calls Win32 API functions such as &lt;code&gt;CreateProcess&lt;/code&gt;, &lt;code&gt;CreateProcessAsUser&lt;/code&gt; and &lt;code&gt;WinExec&lt;/code&gt;  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Image File Execution Options (IFEO) is usually used for debugging purposes. The &lt;code&gt;Debugger Value&lt;/code&gt; under this registry key can be set to attach a program to another executable for debugging, and whenever that executable is launched, the attached program is also launched. Malwares can make use of this to attach themselves to a target executable.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Asynchronous Procedure Calls (APC)&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Malwares can leverage on APC to force another thread to execute their malicious code by intercepting the APC queue of the target thread.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Each thread has a queue of APC which are waiting for execution upon the thread entering an alterable state.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The steps performed to achieve this are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Finding a thread that is in an alterable state&lt;/li&gt;
&lt;li&gt;Call &lt;code&gt;OpenThread&lt;/code&gt; and &lt;code&gt;QueueUserAPC&lt;/code&gt; to queue an APC to the thread&lt;/li&gt;
&lt;li&gt;&lt;code&gt;QueueUserAPC&lt;/code&gt; takes in 3 arguments&lt;ul&gt;
&lt;li&gt;Handle to a target thread&lt;/li&gt;
&lt;li&gt;Pointer to the function that the malware wants to run&lt;/li&gt;
&lt;li&gt;Parameters to the function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Injection using Shims&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Shims are provided by Microsoft to provide backward compatibility by allowing developers to apply fixes to their program without rewriting code. Malwares can leverage on Shims to target an executable for persistence and injection.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When Windows runs the Shim engine, it loads a binary to check shimming databases to check for appropriate fixes. Malwares can create and install their own shimming database (sdb). They can do so by calling &lt;code&gt;sdbinst.exe&lt;/code&gt; (shim database installer), and install their own malicious sdb file.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Import Address Table (IAT) and Inline Hooking&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;IAT hooking involves modifying the Import Address Table to redirect the address of the functions there to their own malicious functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Inline hooking modified the API function itself, by rewriting the first few bytes of code in the function to jump to their malicious function.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In the past, I've only worked in the Linux space when doing process injection. One of the techniques I used was modifying the IAT, and here I've learnt a lot more other techniques that are related to the Windows OS.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Process Injection"></category></entry><entry><title>Microsoft Kaggle Competition</title><link href="/microsoft-kaggle-competition.html" rel="alternate"></link><published>2019-03-31T09:38:00+00:00</published><updated>2019-03-31T09:38:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-31:/microsoft-kaggle-competition.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This is the write up for my solution for the Microsoft Malware Prediction&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;a href="https://www.kaggle.com/c/microsoft-malware-prediction"&gt;https://www.kaggle.com/c/microsoft-malware-prediction&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I got pretty high up the leader board, but it was nothing that I was proud of, because:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;I grossly overfitted my model&lt;/li&gt;
&lt;li&gt;The final result was a blend of another …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This is the write up for my solution for the Microsoft Malware Prediction&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;a href="https://www.kaggle.com/c/microsoft-malware-prediction"&gt;https://www.kaggle.com/c/microsoft-malware-prediction&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I got pretty high up the leader board, but it was nothing that I was proud of, because:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;I grossly overfitted my model&lt;/li&gt;
&lt;li&gt;The final result was a blend of another kernel&lt;/li&gt;
&lt;li&gt;All my attempts at feature engineering failed&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;And I'm now officially ceasing efforts to improve my score, because:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;I'm not learning anything new, just mindlessly tweaking hyperparameters and hoping one of them works&lt;/li&gt;
&lt;li&gt;I don't think I've got the basics down yet, and this challenge was way over my head. I feel I should start with something simpler&lt;/li&gt;
&lt;li&gt;And most importantly, I'm no longer having fun&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;But wait! Doing such a hard competition really taught me many concepts, such as:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Adversarial Cross Validation&lt;/li&gt;
&lt;li&gt;How to properly use LightGBM&lt;/li&gt;
&lt;li&gt;The real problem of overfitting, which LightGBM does really fast&lt;/li&gt;
&lt;li&gt;Blending and Ensembling is a powerful method for getting good results&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below shows one of the code variants I've used. They were all mostly the same, with a few hyperparameters being different, and some failed attempts at feature engineering.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The most important features were Version numbers, and there's probably some way to exploit that.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;My single model (which I believe grossly overfitted, because I set &lt;code&gt;num_leaves=8000&lt;/code&gt; got me a score of 0.684. I blended with another blended kernel of 0.688, and my final score was 0.692.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I think this got me off at the wrong start because I was working and tweaking with those overfitted hyperparameters, when they were wrong in the first place.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Anyway, on to the next competition!  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This Python 3 environment comes with many helpful analytics libraries installed&lt;/span&gt;
&lt;span class="c1"&gt;# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python&lt;/span&gt;
&lt;span class="c1"&gt;# For example, here&amp;#39;s several helpful packages to load in &lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;gc&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mpl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;warnings&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;lightgbm&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;lgb&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StratifiedKFold&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;preprocessing&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;preprocessing&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;category_encoders&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ce&lt;/span&gt;

&lt;span class="n"&gt;le&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LabelEncoder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="c1"&gt;# Any results you write to the current directory are saved as output.&lt;/span&gt;

&lt;span class="n"&gt;dtypes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;#&amp;#39;MachineIdentifier&amp;#39;:                                    &amp;#39;category&amp;#39;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;ProductName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                          &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;EngineVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                        &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AppVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                           &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AvSigVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                         &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IsBeta&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                               &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;RtpStateBitfield&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                     &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IsSxsPassiveMode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                     &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;DefaultBrowsersIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                            &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AVProductStatesIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                            &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AVProductsInstalled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                  &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AVProductsEnabled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                    &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;HasTpm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                               &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;CountryIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                    &lt;span class="s1"&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;CityIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                       &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OrganizationIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                               &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;GeoNameIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                    &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;LocaleEnglishNameIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                          &lt;span class="s1"&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Platform&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                             &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Processor&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                            &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OsVer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                                &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OsBuild&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                              &lt;span class="s1"&gt;&amp;#39;int16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OsSuite&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                              &lt;span class="s1"&gt;&amp;#39;int16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OsPlatformSubRelease&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                 &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;OsBuildLab&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                           &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;SkuEdition&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                           &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IsProtected&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                          &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AutoSampleOptIn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                      &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;PuaMode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                              &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;SMode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                                &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IeVerIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                      &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;SmartScreen&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                          &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Firewall&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                             &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;UacLuaenable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                         &lt;span class="s1"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_MDC2FormFactor&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_DeviceFamily&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                  &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OEMNameIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                             &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OEMModelIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                            &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ProcessorCoreCount&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                            &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ProcessorManufacturerIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;               &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ProcessorModelIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                      &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ProcessorClass&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_PrimaryDiskTotalCapacity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                      &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_PrimaryDiskTypeName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                           &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_SystemVolumeTotalCapacity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                     &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_HasOpticalDiskDrive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                           &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_TotalPhysicalRAM&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                              &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ChassisTypeName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                               &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_InternalPrimaryDiagonalDisplaySizeInInches&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_InternalPrimaryDisplayResolutionHorizontal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_InternalPrimaryDisplayResolutionVertical&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;      &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_PowerPlatformRoleName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                         &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_InternalBatteryType&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                           &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_InternalBatteryNumberOfCharges&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                     &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSArchitecture&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSBranch&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                      &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSBuildNumber&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                 &lt;span class="s1"&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSBuildRevision&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                               &lt;span class="s1"&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSEdition&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                     &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSSkuName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                     &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSInstallTypeName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                             &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSInstallLanguageIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                   &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSUILocaleIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                          &lt;span class="s1"&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_OSWUAutoUpdateOptionsName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                     &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsPortableOperatingSystem&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                     &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_GenuineStateName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                              &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ActivationChannel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                             &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsFlightingInternal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                           &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsFlightsDisabled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                             &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_FlightRing&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                    &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_ThresholdOptIn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_FirmwareManufacturerIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_FirmwareVersionIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                     &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsSecureBootEnabled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                           &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsWIMBootEnabled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                              &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsVirtualDevice&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                               &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsTouchEnabled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsPenCapable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                  &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Census_IsAlwaysOnAlwaysConnectedCapable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;              &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Wdft_IsGamer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                         &lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;Wdft_RegionIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                &lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;HasDetections&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;                                        &lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="c1"&gt;# read data&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Reading Data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sorted.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MachineIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MachineIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Reading&lt;/span&gt; &lt;span class="k"&gt;Data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df_train&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;df_train&lt;/span&gt;.&lt;span class="nv"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;HasDetections&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;]

#&lt;span class="nv"&gt;assign&lt;/span&gt; &lt;span class="nv"&gt;target&lt;/span&gt; &lt;span class="nv"&gt;variable&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;y_train&lt;/span&gt;
&lt;span class="nv"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df_train&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;HasDetections&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;]
&lt;span class="nv"&gt;Train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df_train&lt;/span&gt;[&lt;span class="nv"&gt;features&lt;/span&gt;]
&lt;span class="nv"&gt;Test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df_test&lt;/span&gt;[&lt;span class="nv"&gt;features&lt;/span&gt;]
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Feature Engineering&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:code --&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;add_noise&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;series&lt;/span&gt;, &lt;span class="nv"&gt;noise_level&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;series&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;noise_level&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="k"&gt;random&lt;/span&gt;.&lt;span class="nv"&gt;randn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;series&lt;/span&gt;&lt;span class="ss"&gt;)))&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;target_encode&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;None&lt;/span&gt;, 
                  &lt;span class="nv"&gt;tst_series&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;None&lt;/span&gt;, 
                  &lt;span class="nv"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;None&lt;/span&gt;, 
                  &lt;span class="nv"&gt;min_samples_leaf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;, 
                  &lt;span class="nv"&gt;smoothing&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;,
                  &lt;span class="nv"&gt;noise_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="nv"&gt;Smoothing&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;computed&lt;/span&gt; &lt;span class="nv"&gt;like&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;following&lt;/span&gt; &lt;span class="nv"&gt;paper&lt;/span&gt; &lt;span class="nv"&gt;by&lt;/span&gt; &lt;span class="nv"&gt;Daniele&lt;/span&gt; &lt;span class="nv"&gt;Micci&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;Barreca&lt;/span&gt;
    &lt;span class="nv"&gt;https&lt;/span&gt;:&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="nv"&gt;kaggle2&lt;/span&gt;.&lt;span class="nv"&gt;blob&lt;/span&gt;.&lt;span class="nv"&gt;core&lt;/span&gt;.&lt;span class="nv"&gt;windows&lt;/span&gt;.&lt;span class="nv"&gt;net&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;forum&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;message&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;attachments&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;225952&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;7441&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;high&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="nv"&gt;cardinality&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="nv"&gt;categoricals&lt;/span&gt;.&lt;span class="nv"&gt;pdf&lt;/span&gt;
    &lt;span class="nv"&gt;trn_series&lt;/span&gt; : &lt;span class="nv"&gt;training&lt;/span&gt; &lt;span class="nv"&gt;categorical&lt;/span&gt; &lt;span class="nv"&gt;feature&lt;/span&gt; &lt;span class="nv"&gt;as&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Series&lt;/span&gt;
    &lt;span class="nv"&gt;tst_series&lt;/span&gt; : &lt;span class="nv"&gt;test&lt;/span&gt; &lt;span class="nv"&gt;categorical&lt;/span&gt; &lt;span class="nv"&gt;feature&lt;/span&gt; &lt;span class="nv"&gt;as&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Series&lt;/span&gt;
    &lt;span class="nv"&gt;target&lt;/span&gt; : &lt;span class="nv"&gt;target&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt; &lt;span class="nv"&gt;as&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Series&lt;/span&gt;
    &lt;span class="nv"&gt;min_samples_leaf&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; : &lt;span class="nv"&gt;minimum&lt;/span&gt; &lt;span class="nv"&gt;samples&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;take&lt;/span&gt; &lt;span class="nv"&gt;category&lt;/span&gt; &lt;span class="nv"&gt;average&lt;/span&gt; &lt;span class="nv"&gt;into&lt;/span&gt; &lt;span class="nv"&gt;account&lt;/span&gt;
    &lt;span class="nv"&gt;smoothing&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; : &lt;span class="nv"&gt;smoothing&lt;/span&gt; &lt;span class="nv"&gt;effect&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;balance&lt;/span&gt; &lt;span class="nv"&gt;categorical&lt;/span&gt; &lt;span class="nv"&gt;average&lt;/span&gt; &lt;span class="nv"&gt;vs&lt;/span&gt; &lt;span class="nv"&gt;prior&lt;/span&gt;  
    &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;
    &lt;span class="nv"&gt;assert&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;target&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;assert&lt;/span&gt; &lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nv"&gt;tst_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;
    &lt;span class="nv"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;concat&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;[&lt;span class="nv"&gt;trn_series&lt;/span&gt;, &lt;span class="nv"&gt;target&lt;/span&gt;], &lt;span class="nv"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;Compute&lt;/span&gt; &lt;span class="nv"&gt;target&lt;/span&gt; &lt;span class="nv"&gt;mean&lt;/span&gt; 
    &lt;span class="nv"&gt;averages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;temp&lt;/span&gt;.&lt;span class="nv"&gt;groupby&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;[&lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;].&lt;span class="nv"&gt;agg&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;[&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;mean&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;count&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;Compute&lt;/span&gt; &lt;span class="nv"&gt;smoothing&lt;/span&gt;
    &lt;span class="nv"&gt;smoothing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;exp&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;averages&lt;/span&gt;[&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;count&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;] &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;min_samples_leaf&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nv"&gt;smoothing&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    # &lt;span class="nv"&gt;Apply&lt;/span&gt; &lt;span class="nv"&gt;average&lt;/span&gt; &lt;span class="nv"&gt;function&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;all&lt;/span&gt; &lt;span class="nv"&gt;target&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;prior&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;mean&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
    # &lt;span class="nv"&gt;The&lt;/span&gt; &lt;span class="nv"&gt;bigger&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;less&lt;/span&gt; &lt;span class="nv"&gt;full_avg&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;taken&lt;/span&gt; &lt;span class="nv"&gt;into&lt;/span&gt; &lt;span class="nv"&gt;account&lt;/span&gt;
    &lt;span class="nv"&gt;averages&lt;/span&gt;[&lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;prior&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;smoothing&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;averages&lt;/span&gt;[&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;mean&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;] &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;smoothing&lt;/span&gt;
    &lt;span class="nv"&gt;averages&lt;/span&gt;.&lt;span class="nv"&gt;drop&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;[&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;mean&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;count&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;], &lt;span class="nv"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;Apply&lt;/span&gt; &lt;span class="nv"&gt;averages&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;trn&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;tst&lt;/span&gt; &lt;span class="nv"&gt;series&lt;/span&gt;
    &lt;span class="nv"&gt;ft_trn_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;merge&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;
        &lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;to_frame&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,
        &lt;span class="nv"&gt;averages&lt;/span&gt;.&lt;span class="nv"&gt;reset_index&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;.&lt;span class="nv"&gt;rename&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;{&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;index&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;, &lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;: &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;average&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;}&lt;span class="ss"&gt;)&lt;/span&gt;,
        &lt;span class="nv"&gt;on&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;,
        &lt;span class="nv"&gt;how&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;left&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;average&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;].&lt;span class="nv"&gt;rename&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;_mean&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.&lt;span class="nv"&gt;fillna&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;prior&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;merge&lt;/span&gt; &lt;span class="nv"&gt;does&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;keep&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;index&lt;/span&gt; &lt;span class="nv"&gt;so&lt;/span&gt; &lt;span class="nv"&gt;restore&lt;/span&gt; &lt;span class="nv"&gt;it&lt;/span&gt;
    &lt;span class="nv"&gt;ft_trn_series&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt; 
    &lt;span class="nv"&gt;ft_tst_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;merge&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;
        &lt;span class="nv"&gt;tst_series&lt;/span&gt;.&lt;span class="nv"&gt;to_frame&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;tst_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,
        &lt;span class="nv"&gt;averages&lt;/span&gt;.&lt;span class="nv"&gt;reset_index&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;.&lt;span class="nv"&gt;rename&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;{&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;index&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;, &lt;span class="nv"&gt;target&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;: &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;average&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;}&lt;span class="ss"&gt;)&lt;/span&gt;,
        &lt;span class="nv"&gt;on&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;tst_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt;,
        &lt;span class="nv"&gt;how&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;left&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;average&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;].&lt;span class="nv"&gt;rename&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;trn_series&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;_mean&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.&lt;span class="nv"&gt;fillna&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;prior&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;merge&lt;/span&gt; &lt;span class="nv"&gt;does&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;keep&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;index&lt;/span&gt; &lt;span class="nv"&gt;so&lt;/span&gt; &lt;span class="nv"&gt;restore&lt;/span&gt; &lt;span class="nv"&gt;it&lt;/span&gt;
    &lt;span class="nv"&gt;ft_tst_series&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;tst_series&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;add_noise&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ft_trn_series&lt;/span&gt;, &lt;span class="nv"&gt;noise_level&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;add_noise&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ft_tst_series&lt;/span&gt;, &lt;span class="nv"&gt;noise_level&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# &lt;span class="nv"&gt;combine&lt;/span&gt; &lt;span class="nv"&gt;dtrain&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;dtest&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;preprocessing&lt;/span&gt;
&lt;span class="nv"&gt;alldata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;concat&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;[&lt;span class="nv"&gt;Train&lt;/span&gt;,&lt;span class="nv"&gt;Test&lt;/span&gt;], &lt;span class="nv"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;trainlen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Train&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

# &lt;span class="nv"&gt;convert&lt;/span&gt; &lt;span class="nv"&gt;character&lt;/span&gt; &lt;span class="nv"&gt;columns&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;integer&lt;/span&gt;
&lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Label Encoding&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;numeric&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;Train&lt;/span&gt;.&lt;span class="nv"&gt;select_dtypes&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="k"&gt;include&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;number&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.&lt;span class="nv"&gt;columns&lt;/span&gt;.&lt;span class="nv"&gt;tolist&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
&lt;span class="nv"&gt;categorical&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [&lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;Train&lt;/span&gt;.&lt;span class="nv"&gt;columns&lt;/span&gt;.&lt;span class="nv"&gt;tolist&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;f&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;numeric&lt;/span&gt;]
&lt;span class="nv"&gt;categorical&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;cat&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;categorical&lt;/span&gt;:
    &lt;span class="nv"&gt;alldata&lt;/span&gt;[&lt;span class="nv"&gt;cat&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;le&lt;/span&gt;.&lt;span class="nv"&gt;fit_transform&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;alldata&lt;/span&gt;[&lt;span class="nv"&gt;cat&lt;/span&gt;].&lt;span class="nv"&gt;fillna&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;alldata&lt;/span&gt;[&lt;span class="nv"&gt;cat&lt;/span&gt;].&lt;span class="nv"&gt;mode&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;.&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="ss"&gt;))&lt;/span&gt;

# &lt;span class="nv"&gt;split&lt;/span&gt; &lt;span class="nv"&gt;back&lt;/span&gt; &lt;span class="nv"&gt;into&lt;/span&gt; &lt;span class="nv"&gt;dtrain&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;dtest&lt;/span&gt;
&lt;span class="nv"&gt;Train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;alldata&lt;/span&gt;[:&lt;span class="nv"&gt;trainlen&lt;/span&gt;]
&lt;span class="nv"&gt;Test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;alldata&lt;/span&gt;[&lt;span class="nv"&gt;trainlen&lt;/span&gt;:]
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Training&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:code --&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; {
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;boosting_type&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;gbdt&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;objective&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;binary&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;metric&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;binary_logloss&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;nthread&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;16&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;learning_rate&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;02&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;max_depth&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;12&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;num_leaves&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;100&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;sub_feature&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;sub_row&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;7&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;bagging_freq&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;1&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;bagging_fraction&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;8&lt;/span&gt;,
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;lambda_l1&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;1&lt;/span&gt;, 
    &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;lambda_l2&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; : &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;2&lt;/span&gt;
}

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;modeling_cross_validation&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;params&lt;/span&gt;, &lt;span class="nv"&gt;X&lt;/span&gt;, &lt;span class="nv"&gt;y&lt;/span&gt;, &lt;span class="nv"&gt;folds&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;clfs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; []
    &lt;span class="nv"&gt;allPreds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X&lt;/span&gt;.&lt;span class="nv"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;evals_result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; {}

    &lt;span class="nv"&gt;X_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt;[&lt;span class="nv"&gt;X_len&lt;/span&gt;:]
    &lt;span class="nv"&gt;X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt;[:&lt;span class="nv"&gt;X_len&lt;/span&gt;]
    &lt;span class="nv"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;y&lt;/span&gt;[&lt;span class="nv"&gt;X_len&lt;/span&gt;:]
    &lt;span class="nv"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;y&lt;/span&gt;[:&lt;span class="nv"&gt;X_len&lt;/span&gt;] 

    &lt;span class="nv"&gt;lgb_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;lgb&lt;/span&gt;.&lt;span class="nv"&gt;Dataset&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X_train&lt;/span&gt;, &lt;span class="nv"&gt;y_train&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;lgb_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;lgb&lt;/span&gt;.&lt;span class="nv"&gt;Dataset&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X_valid&lt;/span&gt;, &lt;span class="nv"&gt;y_valid&lt;/span&gt;, &lt;span class="nv"&gt;reference&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;lgb_train&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;lgb&lt;/span&gt;.&lt;span class="nv"&gt;train&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;params&lt;/span&gt;,
                &lt;span class="nv"&gt;lgb_train&lt;/span&gt;,
                &lt;span class="nv"&gt;num_boost_round&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;,
                &lt;span class="nv"&gt;valid_sets&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;[&lt;span class="nv"&gt;lgb_train&lt;/span&gt;, &lt;span class="nv"&gt;lgb_valid&lt;/span&gt;],
                &lt;span class="nv"&gt;evals_result&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;evals_result&lt;/span&gt;,
                &lt;span class="nv"&gt;verbose_eval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;,
                &lt;span class="nv"&gt;early_stopping_rounds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Plot metrics during training...&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;lgb&lt;/span&gt;.&lt;span class="nv"&gt;plot_metric&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;evals_result&lt;/span&gt;, &lt;span class="nv"&gt;metric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;binary_logloss&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="k"&gt;show&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;

    &lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Plot feature importances...&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;lgb&lt;/span&gt;.&lt;span class="nv"&gt;plot_importance&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;model&lt;/span&gt;, &lt;span class="nv"&gt;max_num_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="k"&gt;show&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;

    &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="nv"&gt;allPreds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;.&lt;span class="nv"&gt;predict&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X_test&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;roc_auc_score&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;y_test&lt;/span&gt;, &lt;span class="nv"&gt;allPreds&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="nv"&gt;clfs&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;model&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;clfs&lt;/span&gt;


&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;predict_cross_validation&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;test&lt;/span&gt;, &lt;span class="nv"&gt;clfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:

    &lt;span class="nv"&gt;sub_preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;test&lt;/span&gt;.&lt;span class="nv"&gt;shape&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;, &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;enumerate&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;clfs&lt;/span&gt;, &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:    
        &lt;span class="nv"&gt;test_preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;.&lt;span class="nv"&gt;predict_proba&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;test&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;sub_preds&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nv"&gt;test_preds&lt;/span&gt;[:,&lt;span class="mi"&gt;1&lt;/span&gt;]

    # &lt;span class="nv"&gt;Averaging&lt;/span&gt; &lt;span class="nv"&gt;across&lt;/span&gt; &lt;span class="nv"&gt;all&lt;/span&gt; &lt;span class="nv"&gt;models&lt;/span&gt;
    &lt;span class="nv"&gt;sub_preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sub_preds&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;clfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    # &lt;span class="nv"&gt;Creating&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;series&lt;/span&gt; &lt;span class="nv"&gt;from&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;predictions&lt;/span&gt;
    &lt;span class="nv"&gt;ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Series&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sub_preds&lt;/span&gt;, &lt;span class="nv"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;test&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ret&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;test&lt;/span&gt;.&lt;span class="nv"&gt;index&lt;/span&gt;.&lt;span class="nv"&gt;name&lt;/span&gt; 

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;ret&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;predict_test_chunk&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;clfs&lt;/span&gt;, &lt;span class="nv"&gt;Test&lt;/span&gt;, &lt;span class="nv"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;tmp.csv&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;chunks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:

    &lt;span class="nv"&gt;preds_sub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;DataFrame&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;

    &lt;span class="nv"&gt;num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7853253&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;groups&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;Test&lt;/span&gt;.&lt;span class="nv"&gt;groupby&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Test&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="nv"&gt;chunks&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;idx&lt;/span&gt;, &lt;span class="nv"&gt;df&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;groups&lt;/span&gt;:

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;:
            &lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Running on idx {} of {}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;idx&lt;/span&gt;, &lt;span class="nv"&gt;num&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
            &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="nv"&gt;preds_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;predict_cross_validation&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;, &lt;span class="nv"&gt;clfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;preds_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;preds_df&lt;/span&gt;.&lt;span class="nv"&gt;to_frame&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;HasDetections&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

        &lt;span class="nv"&gt;preds_sub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;concat&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;[&lt;span class="nv"&gt;preds_sub&lt;/span&gt;, &lt;span class="nv"&gt;preds_df&lt;/span&gt;], &lt;span class="nv"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

        &lt;span class="nv"&gt;del&lt;/span&gt; &lt;span class="nv"&gt;preds_df&lt;/span&gt;
        &lt;span class="nv"&gt;gc&lt;/span&gt;.&lt;span class="nv"&gt;collect&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;preds_sub&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Start Training&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clfs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;modeling_cross_validation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Start&lt;/span&gt; &lt;span class="nv"&gt;Training&lt;/span&gt;
&lt;span class="nv"&gt;Training&lt;/span&gt; &lt;span class="k"&gt;until&lt;/span&gt; &lt;span class="nv"&gt;validation&lt;/span&gt; &lt;span class="nv"&gt;scores&lt;/span&gt; &lt;span class="nv"&gt;don&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;t improve for 50 rounds.&lt;/span&gt;
[&lt;span class="mi"&gt;100&lt;/span&gt;]    &lt;span class="nv"&gt;training&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;s binary_logloss: 0.626603 valid_1&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="nv"&gt;binary_logloss&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;632894&lt;/span&gt;
[&lt;span class="mi"&gt;200&lt;/span&gt;]    &lt;span class="nv"&gt;training&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;s binary_logloss: 0.614641 valid_1&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="nv"&gt;binary_logloss&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;624013&lt;/span&gt;
&lt;span class="nv"&gt;Did&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;meet&lt;/span&gt; &lt;span class="nv"&gt;early&lt;/span&gt; &lt;span class="nv"&gt;stopping&lt;/span&gt;. &lt;span class="nv"&gt;Best&lt;/span&gt; &lt;span class="nv"&gt;iteration&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt;:
[&lt;span class="mi"&gt;200&lt;/span&gt;]    &lt;span class="nv"&gt;training&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;s binary_logloss: 0.614641 valid_1&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="nv"&gt;binary_logloss&lt;/span&gt;: &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;624013&lt;/span&gt;
&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;metrics&lt;/span&gt; &lt;span class="nv"&gt;during&lt;/span&gt; &lt;span class="nv"&gt;training&lt;/span&gt;...
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Plot&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt; &lt;span class="n"&gt;importances&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:image {"id":241} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/output_9_1.png){.wp-image-241}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:image {"id":242} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2019/01/output_9_3.png){.wp-image-242}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Start Predicting&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;predict_test_chunk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clfs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;chunks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Start Submission&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_sub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sample_submission.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_sub&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HasDetections&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HasDetections&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="k"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;df_sub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mySubmission.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Done!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;</content><category term="Kaggle"></category></entry><entry><title>Model Capacity</title><link href="/model-capacity.html" rel="alternate"></link><published>2019-03-24T20:19:00+00:00</published><updated>2019-03-24T20:19:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-24:/model-capacity.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;While studying the book Deep Learning by Ian Goodfellow, I came across this concept of model capacity, and it was really intuitive in helping me understand the models representation of a given problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This ties to the concept of overfitting and underfitting&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Capacity&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Put simply, the capacity of the model …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;While studying the book Deep Learning by Ian Goodfellow, I came across this concept of model capacity, and it was really intuitive in helping me understand the models representation of a given problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This ties to the concept of overfitting and underfitting&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Capacity&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Put simply, the capacity of the model is the complexity of the model, or the ability to represent complex relationships.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A model with high capacity can represent very complex relationships, while a model with low capacity can represent not so complex relationships&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How it ties to Overfitting and Underfitting&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Models perform best when their capacity approximately captures the complexity of the task they need to perform.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the task or data set has a very low complexity, but the model has a very high capacity, the model will overfit, as it will memorize and represent all the features in the training set that may not be in the testing set.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Conversely, if the task or data set is highly complex, but the capacity of the model is low, the model will underfit, as it cannot sufficiently represent the complex relationships and features in the training data&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Vapnik–Chervonenkis (&lt;strong&gt;VC&lt;/strong&gt;) &lt;strong&gt;dimension&lt;/strong&gt;&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The VC dimension is a measurement of a model's capacity, given that the task at hand is a binary classification problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The numerical value of a VC dimension tells us the largest set of data point the model can perfectly classify (or shatter). Thus, the larger the VC dimension, the more data points the model is able to perfectly classify, which also means that the model is inherently more complex.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The usage of a VC dimension usually just tells us how complex an algorithm is. A model with a higher VC dimension requires more data to properly train due to the higher complexity.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The take away here is that, overly complicated models are not always better as they can overfit. A simple decision tree or random forest can be perfect for data with low complexity.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A VC dimension is simply a quantification of how complex a model is. Higher VC = Able to separate more data points = more complex = requires more training data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Capacity"></category><category term="VC Dimension"></category></entry><entry><title>Counts Based Featurization</title><link href="/counts-based-featurization.html" rel="alternate"></link><published>2019-03-24T17:48:00+00:00</published><updated>2019-03-24T17:48:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-24:/counts-based-featurization.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;While doing the Microsoft Malware Classification challenge, I encountered a way of Feature representation called Count Based Features (CBF).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CBF is good to use with very high cardinality features, and it transforms the high number of categories in the data to the number of it's occurrences. This representation is helpful …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;While doing the Microsoft Malware Classification challenge, I encountered a way of Feature representation called Count Based Features (CBF).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CBF is good to use with very high cardinality features, and it transforms the high number of categories in the data to the number of it's occurrences. This representation is helpful because it extracts out a simple inherent feature of the data: count&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below shows a simple example of how we get the CBF of a given feature&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:table --&gt;

&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Label&lt;/strong&gt;   &lt;strong&gt;Feature1&lt;/strong&gt;
  0           A
  0           A
  1           A
  0           B
  1           B
  1           B
  1           B&lt;/p&gt;
&lt;hr&gt;
&lt;!-- /wp:table --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CBF can be done in pandas in a single line&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;Train.groupby([' Feature1 '])[' Feature1 '].transform('count')&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The output of this will give you&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:table --&gt;

&lt;p&gt;Label   &lt;strong&gt;Feature1&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;0       3
  0       3
  1       3
  0       4
  1       4
  1       4
  1       4&lt;/p&gt;
&lt;!-- /wp:table --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As you can see, the categorical values are all converted their count values!  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Count Feature"></category></entry><entry><title>LightGBM</title><link href="/lightgbm.html" rel="alternate"></link><published>2019-03-24T12:33:00+00:00</published><updated>2019-03-24T12:33:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-24:/lightgbm.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For some time, XGBoost was considered the Kaggle-Killer, being the winning model for most prediction problems. Recently Microsoft released their own gradient boosting framework called LightGBM, and it is way faster than XGB. In this post, I'm going to touch on the interesting portions of LightGBM.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is LightGBM?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Similar …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For some time, XGBoost was considered the Kaggle-Killer, being the winning model for most prediction problems. Recently Microsoft released their own gradient boosting framework called LightGBM, and it is way faster than XGB. In this post, I'm going to touch on the interesting portions of LightGBM.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is LightGBM?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Similar to XGBoost, LightGBM is a gradient boosted tree based algorithm. Unlike other gradient boosted trees which grows hroizontally, LightGBM grows vertically. LightGBM grows Leaf-wise, while others grow Level-wise.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":227} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/12/1-AZsSoXb8lc5N6mnhqX5JCg-1.png){.wp-image-227}

&lt;figcaption&gt;
LightGBM leaf-wise growth. This allows for deeper vertical growth

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:image {"id":228} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/12/1-whSa8rY4sgFQj1rEcWr8Ag-1.png){.wp-image-228}

&lt;figcaption&gt;
Other gradient boosted algortihms grow level wise, which results in longer horizontal growth

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Dealing with Non-Numeric Data&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The nice thing about LightGBM is that it can take in data as a whole, and it does not require inputs to be converted into numerical format! This means that if your data has a mix of numbers and strings, you can simply throw everything into the model to learn.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The one thing you have to do however, is to specify the string columns as &lt;code&gt;category&lt;/code&gt;. Below is a example of how we do it with Pandas Dataframe&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dtypes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;MachineIdentifier&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;ProductName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;EngineVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AppVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;AvSigVersion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IsBeta&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;RtpStateBitfield&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;IsSxsPassiveMode&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int8&amp;#39;&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;train.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2000000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Or if you're creating new features, you have to recast the datatype of the new column to categories&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;feature&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;newFeatures&lt;/span&gt;:
    &lt;span class="nv"&gt;Train&lt;/span&gt;[&lt;span class="nv"&gt;feature&lt;/span&gt; ] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;Train&lt;/span&gt;[&lt;span class="nv"&gt;feature&lt;/span&gt; ].&lt;span class="nv"&gt;astype&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;category&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Important Parameters to Tune&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;LightGBM has a huge array of parameters to tune, and I wont be listing them here. I will however be highlighting those I think are important, and has helped me increase my model predictions&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;max_depth&lt;/code&gt;: Defines how deep the tree grows&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_leaves&lt;/code&gt;: Defines the maximum number of leaves in a node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_bin&lt;/code&gt;: Defines the maximum number of bins your feature will be bucketed in&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For a more comprehensive read, &lt;a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"&gt;click here!&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In this short post, we've very briefly covered about LightGBM, how it is different from other gradient boosted machines, and how to define categories for training.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;An important thing to know is that LightGBM is very sensitive to overfitting, and should not be used for small data sets &amp;lt;10,000 rows.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>Feature Engineering</title><link href="/feature-engineering.html" rel="alternate"></link><published>2019-03-17T09:41:00+00:00</published><updated>2019-03-17T09:41:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-17:/feature-engineering.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Feature Engineering is one of the neglected portion of machine learning. Most topics revolve around Model Training (parameter tuning, cross validation). While that might be really important, feature engineering is equally important as well, but I can't seem to find good resources that talk about this. I suspect this is …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Feature Engineering is one of the neglected portion of machine learning. Most topics revolve around Model Training (parameter tuning, cross validation). While that might be really important, feature engineering is equally important as well, but I can't seem to find good resources that talk about this. I suspect this is because to perform feature engineering, you need expert knowledge of the data, and what it represents.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A typical workflow would look something like this&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Project Scoping / Data Collection&lt;/li&gt;
&lt;li&gt;Exploratory Analysis (EDA)&lt;/li&gt;
&lt;li&gt;Data Cleaning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Model Training&lt;/li&gt;
&lt;li&gt;Project Delivery / Insights&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is not Feature Engineering&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:list --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data cleaning (Outlier detection, Missing values)&lt;/li&gt;
&lt;li&gt;Scaling and Normalization&lt;/li&gt;
&lt;li&gt;Feature Selection&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I would classify these as data massaging, as you're just changing the data (except for Feature Selection). Feature Engineering is the creation of new data.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;What is Feature Engineering&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;There are a few ways to create new features from existing ones&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Indicator Variables&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Indicator variables are new variables that help you isolate data. This new feature is discriminative and can help separate the data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Examples:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Threshold: If you're studying data on alcohol consumption, you could create a new binary feature if the person is &lt;code&gt;&amp;gt;=21&lt;/code&gt; years old. The expert knowledge in this is knowing where your data came from, and what is the minimum age of drinking in that country/state&lt;/li&gt;
&lt;li&gt;Special Events: If you're studying sales, there could be seasons that have higher sales, such as &lt;code&gt;isChristmas&lt;/code&gt;, &lt;code&gt;isSinglesDay&lt;/code&gt; or &lt;code&gt;isBlackFriday&lt;/code&gt;. Expert knowledge is knowing what special events there are&lt;/li&gt;
&lt;li&gt;Groupings: You can create artificial groups for the data, for example in network traffic, you can group the, according to protocols or source. Expert knowledge is knowing how to interpret the data, and what grouping makes sense&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Interaction of Features&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Features can interact with each other to create new variables. Interaction here means some mathematical operation between them.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Examples:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Sum of Features: If you're looking at sales of individual items, a new feature might be &lt;code&gt;overallSales&lt;/code&gt;, where you add the sales of each item together&lt;/li&gt;
&lt;li&gt;Product of Features: If you're looking at wages, and you have features like &lt;code&gt;hourlyRate&lt;/code&gt;, and &lt;code&gt;workingHours&lt;/code&gt;, you can create a new feature called &lt;code&gt;totalPay&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The expert knowledge in these areas are knowing how the features interact with each other to produce new features. However, from unfortunate experience, I've seen some feature interactions that makes absolutely no sense, but the model seems to think otherwise. An example I saw was a new feature created from the multiplication of &lt;code&gt;screenHorizontalSize&lt;/code&gt; and &lt;code&gt;totalRAM&lt;/code&gt; which makes absolutely no sense, but it gave a boost in prediction accuracy. Machine Learning really is still a black box.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Feature Representation&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For some features, you can better represent them in other formats that give more information.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Examples:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Date to integer: When give a &lt;code&gt;datetime&lt;/code&gt; format string, it almost always makes sense to decompose it to it's integer components such as &lt;code&gt;day&lt;/code&gt;, &lt;code&gt;month&lt;/code&gt; and &lt;code&gt;year&lt;/code&gt;. More than that, you can create features such as &lt;code&gt;isWeekday&lt;/code&gt; or &lt;code&gt;isPeakHour&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Sparse classes to Other: In a categorical class, if some classes are hugely under-represented, they can be grouped together, and classified as &lt;code&gt;Others&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;External Data Augmentation&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Another way to create new features is to bring in new data such as Geolocation information. These external data can be used to add in new features, which in turn can interact, represent or isolate current features.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Indicator Features, Feature Interactions, Feature Representation, External Data Augmentation are all several way to engineer new features. This is different from data massaging.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Feature Engineering is extremely important in your Machine Learning workflow.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Feature Engineering"></category></entry><entry><title>Microsoft Kaggle Challenge: Adversarial Validation</title><link href="/microsoft-kaggle-challenge-adversarial-validation.html" rel="alternate"></link><published>2019-03-10T19:45:00+00:00</published><updated>2019-03-10T19:45:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-10:/microsoft-kaggle-challenge-adversarial-validation.html</id><summary type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Overview&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;This was a concept I came across while doing a Kaggle challenge issued by Microsoft to predict if a computer would get hit by a malware or not.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This challenge was different from their previous one, where they wanted you to predict if the malware class of a given …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Overview&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;This was a concept I came across while doing a Kaggle challenge issued by Microsoft to predict if a computer would get hit by a malware or not.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This challenge was different from their previous one, where they wanted you to predict if the malware class of a given binary.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This challenge was really interesting, because we had a lot of given information about the target machine, the list of them are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;MachineIdentifier, ProductName, EngineVersion, AppVersion, AvSigVersion, IsBeta, RtpStateBitfield, IsSxsPassiveMode, DefaultBrowsersIdentifier, AVProductStatesIdentifier, AVProductsInstalled, AVProductsEnabled, HasTpm, CountryIdentifier, CityIdentifier', OrganizationIdentifier', GeoNameIdentifier', LocaleEnglishNameIdentifier', Platform', Processor', OsVer', OsBuild', OsSuite', OsPlatformSubRelease', OsBuildLab', SkuEdition', IsProtected', AutoSampleOptIn', PuaMode', SMode', IeVerIdentifier', SmartScreen', Firewall', UacLuaenable', Census_MDC2FormFactor', Census_DeviceFamily', Census_OEMNameIdentifier', Census_OEMModelIdentifier', Census_ProcessorCoreCount', Census_ProcessorManufacturerIdentifier', Census_ProcessorModelIdentifier', Census_ProcessorClass', Census_PrimaryDiskTotalCapacity', Census_PrimaryDiskTypeName', Census_SystemVolumeTotalCapacity', Census_HasOpticalDiskDrive', Census_TotalPhysicalRAM', Census_ChassisTypeName', Census_InternalPrimaryDiagonalDisplaySizeInInches', Census_InternalPrimaryDisplayResolutionHorizontal', Census_InternalPrimaryDisplayResolutionVertical', Census_PowerPlatformRoleName', Census_InternalBatteryType', Census_InternalBatteryNumberOfCharges', Census_OSVersion', Census_OSArchitecture', Census_OSBranch', Census_OSBuildNumber', Census_OSBuildRevision', Census_OSEdition', Census_OSSkuName', Census_OSInstallTypeName', Census_OSInstallLanguageIdentifier', Census_OSUILocaleIdentifier', Census_OSWUAutoUpdateOptionsName', Census_IsPortableOperatingSystem', Census_GenuineStateName', Census_ActivationChannel', Census_IsFlightingInternal', Census_IsFlightsDisabled', Census_FlightRing', Census_ThresholdOptIn', Census_FirmwareManufacturerIdentifier', Census_FirmwareVersionIdentifier', Census_IsSecureBootEnabled', Census_IsWIMBootEnabled', Census_IsVirtualDevice', Census_IsTouchEnabled', Census_IsPenCapable, Census_IsAlwaysOnAlwaysConnectedCapable, Wdft_IsGamer, Wdft_RegionIdentifier&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Now that's pretty crazy, with things like Screen size, is the PC build a gaming PC or not, and is touch screen enabled. With such complex features, it'll be really challenging to pick out patterns to predict if the machine will get hit or not.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;But one important thing that stood out was how different the test set was compared to the training set. This can be shown in the following way:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Random sample 10k rows from the training data set and the testing data set&lt;/li&gt;
&lt;li&gt;Drop the initial label (in this case, &lt;code&gt;HasDetected&lt;/code&gt;), and put in your own label &lt;code&gt;IsTrain&lt;/code&gt; , and give the training data 1, and the test data 0&lt;/li&gt;
&lt;li&gt;Build a classifier to predict if a given row came from the training data set, or the testing data set&lt;/li&gt;
&lt;li&gt;If the model gives a high accuracy, it means that the training and testing data are really different.&lt;/li&gt;
&lt;li&gt;If the model gives an accuracy of about 50%, it means that the training and testing data are almost the same&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The model I built was LightGBM, and it gave me an incredible score of 93%! That means that the training and testing data set are incredibly different.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This gives us some problems if we use the standard solution of cross validation of the training data, since at the end, the testing data is so disparate.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Adversarial Validation&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In comes adversarial validation. The idea of this actually really simple.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Based on the model we built earlier to classify is a row belongs to training or testing, we use the same model to run the classification only on the training data set.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We then pick out the rows that the model identified wrongly as testing data. This means that those rows inside the training data set have features that are similar to the testing data set!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;And so, instead of the conventional validation methods, we use these rows classified falsely as testing to be our validation data. This way, our model validates itself to data that is close the testing data, and there would not have a huge difference in performance when training the model, and testing it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Downside&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;One of the downsides of doing this is that, once the testing data set changes again to something that is dissimilar to the current data, we the adversarial validation technique would perform poorly again.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This might mean that we need to retrain the adversarial data selection model, and pick out falsely classified rows, and retrain the prediction model all over again. And that sounds like a lot of work.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Adversarial Validation"></category></entry><entry><title>Web Beacon for Trip wiring documents</title><link href="/web-beacon-for-trip-wiring-documents.html" rel="alternate"></link><published>2019-03-03T14:25:00+00:00</published><updated>2019-03-03T14:25:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-03-03:/web-beacon-for-trip-wiring-documents.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;During my course of security research work, I came across this concept of web beacons, which is a clever way of knowing who has opened up a document.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Web Beacon is an element inside the document, that is not a saved resource. Rather, the element sends a request out …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;During my course of security research work, I came across this concept of web beacons, which is a clever way of knowing who has opened up a document.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Web Beacon is an element inside the document, that is not a saved resource. Rather, the element sends a request out to a server to retrieve the resource. An example of this would be an image tag, that requests the image resource from a server.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, writing this piece of code fetches the image resource from www.w3schools.com server:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;img src="https://www.w3schools.com/images/w3schools_green.jpg" alt="W3Schools.com" style="width:104px;height:142px;"&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"align":"center"} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter"&gt;
![W3Schools.com](https://www.w3schools.com/images/w3schools_green.jpg)  
&lt;figcaption&gt;
Image retrieved from w3 schools
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;It's a very simple concept, and we can make use of this functionality and twist it to be a defensive tool&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Web Server Request Tracking&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;If we can setup our own server that hosts resources, we can secretly embed invisible images, or elements that makes requests to our servers to retrieve those resources.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This way, when the document is opened, the tries to render itself by making a request to our server for the resource. It acts as a tripwire that immediately triggers the moment the document is opened. And as the image is is not obvious to the threat actor, he would not be aware of this callback.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Improvements?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The obvious drawback to this is that, once the document is taken to an offline premise, the image can no longer make a request to our server. This means that we will not be notified when the tripwire is activated.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The second drawback is: So what?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;So what if I know if the document has been opened by some unauthorized person, or in another location? What can I do to prevent him from opening it? Some simple solutions that I came up with are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;If the requesting IP address is not in the whitelist, we return an extremely huge image, hopefully to make the document hang and not be usable.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Another improvement is, aside from image resources, what other resources can be requested, and hopefully such resources can be "executed". Of course, such a solution is considered intrusive, because then it can be used in malicious ways for remote code execution.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Web Beacons"></category></entry><entry><title>Convolutional Neural Networks</title><link href="/convolutional-neural-networks.html" rel="alternate"></link><published>2019-02-17T16:11:00+00:00</published><updated>2019-02-17T16:11:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-02-17:/convolutional-neural-networks.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Convolutional Neural Networks (CNN) are neural networks that are mainly used for image recognition and image classification.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we'll break down how a CNN works under the hoods.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Backgroud&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;If we used a traditional neural network without any of the prior convolution steps, the network would not scale …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Convolutional Neural Networks (CNN) are neural networks that are mainly used for image recognition and image classification.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we'll break down how a CNN works under the hoods.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Backgroud&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;If we used a traditional neural network without any of the prior convolution steps, the network would not scale well at all.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;28 x 28 pixel of MNIST in a fully connected model gives use 784 input weights. Obviously, most pictures are a lot larger than 28 x 28. A 200 x 200 pixel picture would result in 120,000 input weights.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;To minimize the number of input parameters, we need produce lower representations of the image that captures the most amount of information.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CNN was inspired the visual cortex, where in the human brain, parts of the visual cortex fired when detecting edges. Furthermore, studies have shown that the visual cortex works in layers; a given layer works on the features detected in the previous layer, from lines, to contours, to shapes, to entire objects.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Vector Representation of Images&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;As we know, all models only take in numerical inputs to perform their actions. Non-numerical data such as text, and in this case images, must first be converted to numerical vectors.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:media-text {"mediaId":190,"mediaType":"image"} --&gt;

&lt;div class="wp-block-media-text alignwide"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/1_zy1qfb9affzz66yxxoi2aw1.gif){.wp-image-190}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph --&gt;
&lt;/p&gt;
An image with multiple colors can be converted into a grayscale image, and each pixel is represented by its intensity from a range of 0-255.

&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

This gives us a resulting numerical vector representation of an image

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Convolution?&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Before we talk about convolutional neural networks, we need to understand what is the meaning of convolution first.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In mathematical terms, a convolution is the combination of two functions to produce a third function, which has the properties of the two combined functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The term &lt;em&gt;convolution&lt;/em&gt; refers to the resulting third function, as well as the process of computing the combination of two functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:media-text {"mediaId":192,"mediaType":"image"} --&gt;

&lt;div class="wp-block-media-text alignwide"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/convolution_of_box_signal_with_itself2.gif){.wp-image-192}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph --&gt;
&lt;/p&gt;
By sliding function *g(t*) onto *f(t)*, we produce a third function *(f\*g)(t)*. We say that *(f\*g)(t)* is the convolution of *f(t)* and *g(t)*

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Now we have a rough idea of what convolution is, we can go back to see how convolution works in the context of image processing.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Convolution of Images&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To begin, we have converted the image to a &lt;em&gt;n x n&lt;/em&gt; matrix of numbers from 0-255 which indicates the intensity.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Next, we take a smaller matrix of size &lt;em&gt;m x m&lt;/em&gt;, where &lt;em&gt;m &amp;lt; n&lt;/em&gt;, and slide it over the original matrix. This smaller matrix is called a filter.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:media-text {"mediaId":196,"mediaType":"image","mediaWidth":23} --&gt;

&lt;div class="wp-block-media-text alignwide" style="grid-template-columns:23% auto;"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/screen-shot-2016-07-24-at-11-25-13-pm2.png){.wp-image-196}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph --&gt;
&lt;/p&gt;
Image that has been converted to a matrix of numbers. For simplicity, we'll just use 0 and 1.

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:media-text {"mediaId":197,"mediaType":"image","mediaWidth":15} --&gt;

&lt;div class="wp-block-media-text alignwide" style="grid-template-columns:15% auto;"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/screen-shot-2016-07-24-at-11-25-24-pm1.png){.wp-image-197}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph --&gt;
&lt;/p&gt;
A smaller matrix, called a filter, that we'll use to slide over the original matrix

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:media-text {"mediaId":198,"mediaType":"image"} --&gt;

&lt;div class="wp-block-media-text alignwide"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/convolution_schematic.gif){.wp-image-198}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph --&gt;
&lt;/p&gt;
As we slide the filter over the matrix, we do a matrix multiplication, and take the result of the multiplication for our convolution matrix.

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The convolution here can be seen as combining the original matrix and the filter to produce a third matrix, which is our convolved feature matrix.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The intuition behind this is that we are using the filter to extract features from the image. Different filter values will extract out different features from the image.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph {"align":"center"} --&gt;

&lt;p&gt;&lt;img alt="" class="wp-image-200" src="/media/2018/12/screen-shot-2016-08-05-at-11-03-00-pm.png"&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can also use multiple filters to produce multiple Convoluted feature maps, which is called "Depth"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":204,"align":"center","width":374,"height":188} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2018/12/screen-shot-2016-08-10-at-3-42-35-am.png){.wp-image-204 width="374" height="188"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When building a CNN, the model learns the values of the filters on its own, while we have to specify other parameters like number of filters, filter size, stride and zero-padding.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For a given set of values, convolution (which is a set of filters) generates a new set of values. The depth of the new set of output corresponds to the number of filters, as each filter generates its own set of values.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Removing Negative values from Convolved Features&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;After we produce a Convolved feature map from the original image, we perform another operation called ReLU (Rectified Linear Unit) on each element.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;What ReLU does is that it replaces all negative values to 0.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Why we need to apply ReLU on a convolved feature map is because the Convolution step is a linear operation. To account for non-linearity, we need to introduce a nonlinear function such as ReLU.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The resulting feature map after applying ReLU is called a Rectified feature map.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":201} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/12/screen-shot-2016-08-07-at-6-18-19-pm.png){.wp-image-201}

&lt;figcaption&gt;
Convoluted feature map becomes a Rectified feature map, after ReLU is applied to each pixel.  
This process changes all negative values to a 0 value

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Dimensionality Reduction through Pooling&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After we have extracted the Convoluted feature map, and passed it through our ReLU function to produce a Rectified feature map, we can reduce the feature map through a process called pooling.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are 3 types of pooling: Max pooling, Sum pooling and Average pooling. We'll talk about Max pooling, because it works better in practice, and once you understand Max pooling, Sum pooling and Average pooling works the same way.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In doing Max pooling, we define yet another window size &lt;em&gt;k x k&lt;/em&gt;, but in this case, we do not slide the window across the Rectified feature map. Instead, we divide the feature map up into the window size, and take the max value from it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":203} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/12/screen-shot-2016-08-10-at-3-38-39-am.png){.wp-image-203}

&lt;figcaption&gt;
A Max pooling window size of 2x2.  
After we pass the Convolved feature map through ReLU, we get a Rectified feature map.  
We take the maximum value of the window size to get the reduced matrix.  

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Fully Connected Layer&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;After we have broken down the image through iterative process of Convolution, ReLU and pooling, we get a set of matrices to represent the important features of the original image.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We then line up each of the values of the pooled matrix into a single vector, and feed it into a fully connected neural network.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When the neural network does it's learning via gradient descent or some other optimization algorithm, only the weights in the neural network and the values in the filter layer changes. The size of the filter and step size do not change.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Features at each Layer&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;We now have the 3 basic steps of a CNN: Convolution, ReLU and Pooling.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can repeat this step numerous times to reduce the image, and extract out important features.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":205,"align":"center","width":606,"height":144} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2018/12/screen-shot-2016-08-08-at-2-26-09-am.png){.wp-image-205 width="606" height="144"}  
&lt;figcaption&gt;
Repeated Convolution + ReLU and Pooling to reduce the image and extract important features.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The more layers we have, the more complicated features we can extract out from the image. At each layer, we reconstruct simple layers to form more complex layers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:media-text {"mediaId":206,"mediaType":"image"} --&gt;

&lt;div class="wp-block-media-text alignwide"&gt;

&lt;figure class="wp-block-media-text__media"&gt;
![]({attach}media/2018/12/screen-shot-2016-08-10-at-12-58-30-pm.png){.wp-image-206}
&lt;/figure&gt;
&lt;div class="wp-block-media-text__content"&gt;

&lt;!-- wp:paragraph {"align":"left"} --&gt;
&lt;/p&gt;
In the first layer, we pick out simple features like edges and lines.

&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;


In the second layer, we're able to form parts of the face such as eyes and ears.

&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;


In the last layer, we can form the full face from all the layers

&lt;p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;!-- /wp:media-text --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In another example, we can visually see how the CNN breaks down an image using Convolution + ReLU and pooling to extract important features, and make a classification at the end.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":207,"align":"center","width":748,"height":423} --&gt;

&lt;div class="wp-block-image"&gt;

&lt;figure class="aligncenter is-resized"&gt;
![]({attach}media/2018/12/conv_all.png){.wp-image-207 width="748" height="423"}
&lt;/figure&gt;

&lt;/div&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The intuition here is that we are making predictions here based on several features maps. If we have feature maps telling us there is two eyes, a nose and a mouth, we can make a prediction that it is a face.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;We've seen in this post how to do the following steps in a CNN&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Transform an image to a numerical vector&lt;/li&gt;
&lt;li&gt;Apply a filter to extract a Convoluted feature map&lt;/li&gt;
&lt;li&gt;Apply ReLU to transform negative values to 0&lt;/li&gt;
&lt;li&gt;Apply Pooling to get your Rectified feature map&lt;/li&gt;
&lt;li&gt;Repeat until extract important features&lt;/li&gt;
&lt;li&gt;Pass them into a fully connected layer to perform prediction&lt;/li&gt;
&lt;li&gt;Learning only changes the weights of the connected layer and the filter matrix values&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;</content></entry><entry><title>Model Optimizers Beyond Gradient Descent in Deep Learning</title><link href="/model-optimizers-beyond-gradient-descent-in-deep-learning.html" rel="alternate"></link><published>2019-02-10T09:52:00+00:00</published><updated>2019-02-10T09:52:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-02-10:/model-optimizers-beyond-gradient-descent-in-deep-learning.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to talk about the draw backs and constrains of a simple Gradient Descent algorithm when applied to Deep Learning models, and also talk about other optimization algorithms that aim to solve those problems.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These problems mainly arise due to the complex error surface in Deep …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to talk about the draw backs and constrains of a simple Gradient Descent algorithm when applied to Deep Learning models, and also talk about other optimization algorithms that aim to solve those problems.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These problems mainly arise due to the complex error surface in Deep Learning models, where Gradient Descent is unable to perform as well.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Challenges with Gradient Descent&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;Too many Local Minimas&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One of the problems that Gradient Descent faces is having a the algorithm converge to a local minima, instead of the true global minima. Even in a simple 2 dimensional problem, we face the issue, which gets even worse when our problem scales up to higher dimensions. But here we'll see that the local minima problem is not a huge issue with Deep Learning models.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The first source that contributes to a local minima is &lt;strong&gt;model identifiability&lt;/strong&gt;. An identifiable model is a model that given an output, the weights or the structure of the network can be identified. In other words, there is a one-to-one mapping of parameters to out. If a model is non-identifiable, it means that for a given output, there exists more than one set of parameters that can produce it. &lt;strong&gt;A fully connected feed-forward neural network is non-identifiable&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":181,"width":435,"height":388} --&gt;

&lt;figure class="wp-block-image is-resized"&gt;
![]({attach}media/2018/12/multi-layer_neural_network-vector2.png){.wp-image-181 width="435" height="388"}

&lt;figcaption&gt;
Different paths and connections in the neural network may give the same output. This give rise to the characteristics of being non-identifiable.

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Why this is so is because there exists a huge number of different permutations of neuron connections within the model that will produce the same output. A network with &lt;em&gt;n&lt;/em&gt; neurons has &lt;em&gt;n!&lt;/em&gt; possible parameter combinations.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;So why is model non-identifiability not an issue with Deep Learning models? That is because, even though the models themselves are non-identifiable, they all have the same behaviors. So given a group of non-identifiable models, they will all react the same way to the same inputs. And because of this property, there exists only a single local minima for a given non-identifiable model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Spurious Local Minima&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Another problem that a local minima can give us is being spurious. Spurious means giving false information about itself, and a spurious local minima means that the local minima incurring a higher loss function value than the true local minima. In a sense, the local minima is lying to us, and presents itself as the global minima.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;However, there has been many studies that shows that the local minima actually exhibits similar properties to the global minima, and hence, this too isn't a problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Wrong Directions in Gradient Descent&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:heading {"level":4} --&gt;&lt;/p&gt;
&lt;h4&gt;Non-Uniform and Changing Gradients&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The actual challenge to Gradient Descent as we shall see, is not the problem of local minima, but finding the right path for the algorithm to descend towards.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Intuitively, the gradient is supposed to descend towards the steepest direction, or the direction that brings the gradient value closer to zero. However, just by using this simple heuristic alone can be problematic on complex error surfaces (which is a common property of Deep Learning Models).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A complex error surface has the properties of uneven gradients, and hence when we move from point to point, the gradient underneath our path may possibly change. This is opposed to a simple error surface that is circular, where the gradient is constant throughout a single direction. Having this changing gradient may result in our algorithm going towards the wrong direction, because it doesn't account for the changes that happens as we are moving.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Mathematically, we can quantify how much the gradient changes as we are moving by calculating the second derivative. This can be captured by calculating how much the gradient as w2 changes as we change the value of w1, and we store this value in a Hessian Matrix. And a Hessian Matrix that tells us the gradient changes as we move, is called an &lt;strong&gt;ill-conditioned&lt;/strong&gt; matrix.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Calculating this Hessian matrix turns out to be extremely expensive if we do it at each step, and so to tackle the problem of changing gradients, we factor in the &lt;strong&gt;momentum&lt;/strong&gt; parameter.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Momentum-Based Optimization&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Earlier, we stated that we may go into the wrong direction because we don't account for changing gradients, and also, if we decide to account for changing gradients using second derivatives, calculating a Hessian Matrix is extremely expensive.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The solution to this is instead of calculating the Hessian Matrix at every optimization step, we factor in the value of the previous gradient into the calculation of the current gradient. By taking into account of the previous gradient value to find the current gradient, the fluctuations of gradient value is drastically reduced.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This approach of remembering previous gradients is called &lt;strong&gt;Momentum&lt;/strong&gt;. This technique is analogous to taking a moving average of stock prices the market  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":178} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/12/movingaverage.gif){.wp-image-178}

&lt;figcaption&gt;
Fluctuations in the stock market price are reduced by looking at the averag

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can thinking of the wildly fluctuating gradients at each point being represented by the green line, while the average is represented by the yellow line. Momentum based optimizers use the yellow line to calculate the change in gradient.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To conclude this post, we have seen how there are problems applying simple gradient descent to complex error surfaces that are present in Deep Learning models.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Local minimas are not a problem, but changing gradients due to its complex surface are a problem. To try to factor in changing surfaces, we could calculate the Hessian Matrix, but that turns out to be extremely expensive.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As a solution, we use Momentum based optimizers instead, which factors in previous gradient values to the calculation of the current gradient.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Optimizers"></category></entry><entry><title>Gradient Descent</title><link href="/gradient-descent.html" rel="alternate"></link><published>2019-02-03T20:10:00+00:00</published><updated>2019-02-03T20:10:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-02-03:/gradient-descent.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A machine learning model consists of weights, and those weights, given a set of inputs, are used in the calculation process to produce a prediction. The prediction is then fed into a loss function, to calculate the the total error. Using this error, we feed it into an optimization algorithm …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A machine learning model consists of weights, and those weights, given a set of inputs, are used in the calculation process to produce a prediction. The prediction is then fed into a loss function, to calculate the the total error. Using this error, we feed it into an optimization algorithm, which goes back to the model and tweaks the weights.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This tweaking process is the learning, and how we do the tweaking is optimization algorithm.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are a few popular ways to perform weight tweaking and model optimization, that is, how do we decide how to tweak the weights. In this post, we're going to be talking about Gradient Descent.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Gradient Descent&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In our model, assume we have 2 weights, w1 and w2, for optimization.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We can plot all possible weights w1 and w2 can have, to all possible errors on a graph, and this will produce an bowl shape, where the bottom of the bowl corresponds to the lowest possible error.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":165} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/gradient_descent_method.png){.wp-image-165}

&lt;figcaption&gt;
The X and Y axis represents the values of w1 and w2.  
The Z axis represents the values of the error.

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;What we're tweaking here are the values of  w1 and w2. When we start shifting the values around the X and Y axis, the point on the bowl shape also shifts correspondingly. The goal here is to tweak the values of w1 and w2 such that the point on the bowl rests directly at the bottom, which has the lowest error value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;So how do we know, at each point of time on the bowl shape, where do we move to? Here's where we calculate the gradient of that point of the bowl. At the bottom of the bowl, the gradient will be 0, because it'll be a horizontal surface. All other points on the bowl will have a non-zero gradient value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":166} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/512px-gradient_descent-svg.png){.wp-image-166}

&lt;figcaption&gt;
Top down view of the bowl. As we shift w1 and w2 around, the point on the bowl shifts as well. We want the point to slowly traverse towards the center, where error is minimized.

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The heuristic we'll use is to a new point such that the new gradient value on the bowl is getting smaller. This is the idea of descending gradient, until it reaches a minimum.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One hyper-parameter we can tune in our optimization algorithm is how fast the point moves. That is to say, at each descent step, how far away should the new point be. A big step might get you to the bottom faster, but you might end up overshooting, and be perpetually oscillating around the bottom, never reaching the end. A small step on the other hand will take a much longer time. This distance of each descent step is called the &lt;strong&gt;learning rate&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In mathematical terms, Gradient Descent is the partial derivative of the error or loss function, with respect to the weights.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Stochastic Gradient Descent&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The process we described above is the vanilla way of doing Gradient Descent, and it's called &lt;strong&gt;Batch Gradient Descent&lt;/strong&gt;. This means that we take all the possible data points in a single batch, and compute the error surface, or the bowl.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In reality, the error surface isn't always so smooth in the shape of a bowl, but may consist several saddle points. Saddle points are points on the graph that are almost horizontal, but it's not the true minimum of the graph. This can lead to an issue of early stoppage, where our Gradient Descent thinks it has found the lowest point on the error surface.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":167} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/saddle_point-svg.png){.wp-image-167}

&lt;figcaption&gt;
The point stops at a saddle point, which has a zero gradient as well. Clearly that is not the lowest point on the graph, and our algorithm has prematurely halted.  

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One of the solutions to this is &lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;. In batch, we take all possible data points and plot the error surface. In Stochastic, we only use one single data point, and we estimate the error surface. The result is a dynamic error surface, which decreases the chance of us encountering a saddle point.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The downside to Stochastic Gradient Descent is that we're performing an estimation of the error surface based only on 1 point, which may not be an accurate representation of the error surface.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;And the obvious solution to this is called &lt;strong&gt;Mini-Batch Gradient Descent&lt;/strong&gt;, where instead of performing the error surface estimation based on one point, we use a group of points, or mini batches.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To recap, in this post we've talked about one of the optimization algorithm, Gradient Descent. This algorithm tells you how to tweak your weights to minimize the loss function of your model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are three models, each improving on the other:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Batch Gradient Descent: Plots the error surface based on all points. This might lead to early convergence on saddle points.&lt;/li&gt;
&lt;li&gt;Stochastic Gradient Descent: Estimates and plots the error surface based on a single point. This leads to a poor estimation of the error surface.&lt;/li&gt;
&lt;li&gt;Mini-batch Gradient Descent: Uses small batches of the data set to perform the error surface estimation.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;</content><category term="Gradient Descent"></category></entry><entry><title>Learning in Machine Learning</title><link href="/learning-in-machine-learning.html" rel="alternate"></link><published>2019-01-27T17:14:00+00:00</published><updated>2019-01-27T17:14:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-01-27:/learning-in-machine-learning.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When we talk about machine learning, it's mostly a black box, where everything is nicely wrapped in easy to call library functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Scipy, Numpy, Scikit-learn help us abstract all the nitty gritty details underlying machine learning&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to see where exactly the learning takes place, and …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When we talk about machine learning, it's mostly a black box, where everything is nicely wrapped in easy to call library functions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Scipy, Numpy, Scikit-learn help us abstract all the nitty gritty details underlying machine learning&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to see where exactly the learning takes place, and what happens when you "train" a model.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Steps of Learning&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;In every algorithm, the learning process follows this formula:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Predict -&amp;gt; Evaluate -&amp;gt; Tune -&amp;gt; Repeat&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When we first throw in a bunch of features, the model initially makes blind &lt;strong&gt;Predictions&lt;/strong&gt; as to what the outcome is. Because it makes shots in the dark, the &lt;strong&gt;Evaluation&lt;/strong&gt; of the model is going to be very poor initially. The model then learns of its errors, and &lt;strong&gt;Tunes&lt;/strong&gt; its hyper-parameters to minimize the errors. After tuning, it &lt;strong&gt;Repeats&lt;/strong&gt; the process of prediction, and the cycle continues until a satisfactory Error value is obtained.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;When training the model, the learning process comes from telling the machine where it went wrong, or the Errors it has committed. The Error is derived from the difference of the model output and the desired outcome.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Error/Loss Functions&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;When the model makes a prediction, there is bound to be errors in the the desired outcome, and the actual outcome. The difference between the desired and actual outcome can be represented in various ways called Loss Functions.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Some way of calculating this Error, or Loss Function, are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Classification Accuracy&lt;/li&gt;
&lt;li&gt;Log Loss&lt;/li&gt;
&lt;li&gt;Confusion Matrix  &lt;/li&gt;
&lt;li&gt;Root Mean Square Error (RMSE)&lt;/li&gt;
&lt;li&gt;F1 Score&lt;/li&gt;
&lt;li&gt;Area Under Curve (AUC)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These Loss functions tell the model how badly it has done in its job of prediction, and to kindly go back and tune the way it performs its predictions.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;The Optimization Functions&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;To tune the way it performs predictions, the model uses Optimization Functions.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Using the Error value produced by either one of those loss functions, the model then tunes itself using Optimization Functions, which adjusts its hyper-parameters, to try to minimize those Error values.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are also several ways for the model to tune it hyper-parameters based on the Error value computed. I'll only be listing them, as going through each of them requires a post on its own:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;li&gt;Momentum&lt;/li&gt;
&lt;li&gt;Adaptive Movement Estimation (Adam)&lt;/li&gt;
&lt;li&gt;Adagrad&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These Optimization algorithms are optimizing, or minimizing, the Error value calculated previously.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Repeat&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;So you got your Loss function to tell you how badly you did, and the Optimization function for your model to tweak it's parameters. Now all you have to do is to keep repeating these steps, and your model is "Learning". But wait!  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Over/Under Fitting&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Is there such a thing as learning too much? In the context of machine learning, this scenario is entirely possible, where you model learns too much about the training data, which results in poor performance on unseen data.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This is analogous to a student studying for his final exam, and the way he does it is to memorize every single questions and answers from the past year papers, with little contextual understanding. Obviously when he takes the final exam, the questions will be different, and he will do very poorly.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In machine learning, overfitting is a problem when we have over-tuned the parameters in the model to a specific data set, resulting in poor performance in other data sets.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Some ways to overcome Overfitting are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Throw in more data (akin to studying more past year papers)  &lt;/li&gt;
&lt;li&gt;Cross validation during training&lt;/li&gt;
&lt;li&gt;Early stopping to stop learning too much&lt;/li&gt;
&lt;li&gt;Regularization that forces simplicity on your model  &lt;/li&gt;
&lt;li&gt;Ensemble to take the average of various models  &lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Underfitting on the other, is not as common of a problem as overfitting. Underfitting means that your model has not learnt much, and as a result it cant perform well. This is analogous to student studying too little for his final exams.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In Overfitting, your model is too complex. In Underfitting, your model is too simple.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;So that's it! You've understood the abstracted underling principles of what happens when a machine "Learns", and the possibility of learning too much or too little.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For each prediction, we get an error value, and using this error value, we use optimization functions to change the way we perform our prediction.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You've also seen some ways to prevent overfitting, which is a more common problem than underfitting.  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Machine learning"></category></entry><entry><title>Word2Vec</title><link href="/word2vec-and-skip-gram.html" rel="alternate"></link><published>2019-01-20T14:24:00+00:00</published><updated>2019-01-20T14:24:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-01-20:/word2vec-and-skip-gram.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the field of machine learning, when we're dealing with text processing, we can't just read in the strings of the sentence to train our model. The model requires numerical vectors, and word embedding is a way to convert your sentences into these vectors.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are various word embedding techniques …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the field of machine learning, when we're dealing with text processing, we can't just read in the strings of the sentence to train our model. The model requires numerical vectors, and word embedding is a way to convert your sentences into these vectors.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are various word embedding techniques for converting strings into vectors. Some of the common ones are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Bag of Words (BoW)&lt;/li&gt;
&lt;li&gt;TF-IDF&lt;/li&gt;
&lt;li&gt;Word2Vec&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I've briefly touched on BoW and TF-IDF in my previous posts. In this post, we're going to be looking at Word2Vec.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Difference between BoW&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Word2Vec is different from BoW, as BoW produces a single value for each word, which is the count of the word occurrence in the corpus. Word2Vec on the other hand, produces a vector representation for each word (as the name implies, word to vector)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Having a numerical vector tied to a single word has more benefits, as compared to a single count number. Some of the features are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Cosine similarity between the vectors can indicate semantic similarity&lt;/li&gt;
&lt;li&gt;The vectors produced for each word are fixed length, resulting in a low dimensional output (As compared to BoW, which results in a high dimensional and sparse vector)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;As a result, it's much easier to perform machine learning related task to the condense Word2Vec representations of the word.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Generating the vectors&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are two methods for generating the vectors in Word2Vec:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Skip-gram model&lt;/li&gt;
&lt;li&gt;Continuous Bag of Words (CBoW)&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Skip-gram Model&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Skip-gram is like N-gram, but instead of consecutive words, it skips around the given window.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the example below, the windows size is 2, which is to say 2 words before, and 2 words after the target word. The Skip-gram model then picks out all combinations of word-pairs within this window, not only consecutive ones (like in N-grams)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":135} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/training_data.png){.wp-image-135}

&lt;figcaption&gt;
http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the skip-gram model, we're going to train a neural network  with a single hidden layer to perform the following task: Given an input word, output the probabilities of each word being "close" to the input word. This closeness is defined in a window:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We're going to throw all these word pairs in our one layer neural network, and train our model to identify nearby words for a given input word. So, the higher the frequency a pair of words occur together, the model learns this co-occurrence, and is able to give a higher probability that the word exists together.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For example, in our training set, if we feed it with many instances of the word-pair ("Apple", "Orange"), because they happen to be in many sentences such as "Apples and oranges", our model picks up this co-occurrence and gives "Orange" a higher probability. On the other hand, word-pairs like ("Apple", "Day"), which could occur in a sentence, "An apple a day keeps the doctor away" occur less frequently, and model gives "Day" a lower probability.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The catch here however, is that we're going to use the weights trained in the hidden layer of the neural network as our product, instead of the output itself. We want to use the hidden layer of the trained model to give each word a vector representation&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The single hidden layer will have N number of neurons. In this example, we're going to assume N = 300, because 300 neurons was what Google used to train their Word2Vec model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Our model will look something like this&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":139} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/presentation11.jpg){.wp-image-139}

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In the training phase, one hot encoding is used for the input and outputs. During the validation phase, the inputs is a one hot encoding, while the output is a probability for each word indicating their "closeness"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once the model is trained, we're interested only in the hidden layer. The weight matrix would be of the size (Number of words X Number of neurons), and this is actually the word vector we're looking for.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:image {"id":138} --&gt;

&lt;figure class="wp-block-image"&gt;
![]({attach}media/2018/11/weightmatrix1.jpg){.wp-image-138}

&lt;figcaption&gt;
Word Vector for each word, generated from the hidden layer  

&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- /wp:image --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The feature of this word vector generated from the weight matrix is that, for similar words, their vectors would be "close" to each other (Cosine distance). This is because of the way we used word-pairs to train the model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Continuous Bag of Words&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A CBoW is just a Skip-gram reversed.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The input to a CBoW is a group of context words, and the output of the model tries to predict a single word that fits into the context of all the input words.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;CBoW represents the data differently&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Hi fred how was the pizza?&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;CBOW&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grams&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Hi fred how&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;fred how was&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;how was the&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;Skip&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gram&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;skip&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grams&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Hi fred how&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;Hi fred was&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;fred how was&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;fred how the&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;or more intuitively, &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;CBOW&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="n"&gt;ate&lt;/span&gt; &lt;span class="n"&gt;_____&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; 
&lt;span class="n"&gt;Predict&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;given&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="n"&gt;food&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;Skip&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gram&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;___&lt;/span&gt; &lt;span class="n"&gt;___&lt;/span&gt; &lt;span class="n"&gt;___&lt;/span&gt; &lt;span class="n"&gt;food&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Given&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;what&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;what&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt; &lt;span class="n"&gt;around&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="n"&gt;ate&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;</content><category term="Text processing"></category></entry><entry><title>No title [270]</title><link href="/270.html" rel="alternate"></link><published>2019-01-14T22:13:00+00:00</published><updated>2019-01-14T22:13:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-01-14:/270.html</id><content type="html"></content></entry><entry><title>Text Processing</title><link href="/text-processing.html" rel="alternate"></link><published>2019-01-13T18:41:00+00:00</published><updated>2019-01-13T18:41:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-01-13:/text-processing.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to be exploring some typical methods for text processing for machine learning. When we're talking about machine learning with text, there are several areas of interest including &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Sentiment Analysis&lt;/li&gt;
&lt;li&gt;Question Answering&lt;/li&gt;
&lt;li&gt;Information Retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before we do that, we must first understand that a machine learning …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this post, we're going to be exploring some typical methods for text processing for machine learning. When we're talking about machine learning with text, there are several areas of interest including &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Sentiment Analysis&lt;/li&gt;
&lt;li&gt;Question Answering&lt;/li&gt;
&lt;li&gt;Information Retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Before we do that, we must first understand that a machine learning model only takes in numerical values, or vectors, and not strings in the text. The problem now is how do we transform the collection of strings into vectors of numbers.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are several pre-processing steps, and we'll take a look at them below.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Tokenization&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Tokenization is splitting up the sentence into to words or phrases.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There's Sentence Tokenizing, and Word Tokenizing, both of which are apparent in what they do. We'll mostly be using Word Tokenizing to split up a sentence in its constituent words. The example below uses NLTK's word_tokenize&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;from nltk.tokenize import word_tokenize &amp;gt;&amp;gt;&amp;gt; string = "Hello! I am a sentence!" &amp;gt;&amp;gt;&amp;gt; word_tokenize(string ) ['Hello', '!', 'I', 'am', 'a', 'sentence', '!']&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Normalization&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once the sentence has been broken up into it's words, we need to normalize it, so as to remove any unwanted meaning attached to features like capitalization. This process transforms the words, and picks out useful features.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There are several common methods for normalization:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Lemmatization&lt;/li&gt;
&lt;li&gt;Stemming&lt;/li&gt;
&lt;li&gt;Capitalization&lt;/li&gt;
&lt;li&gt;Special Characters&lt;/li&gt;
&lt;li&gt;Stopwords&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lemmatization and Stemming are pretty similar, where they both transform the words into their generalized forms. The difference is in how they change the word.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:table --&gt;

&lt;hr&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;         &lt;span class="n"&gt;Lemmatization&lt;/span&gt;   &lt;span class="n"&gt;Stemming&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Studying   Study           Study
  Studies    Study           Studi&lt;/p&gt;
&lt;hr&gt;
&lt;!-- /wp:table --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Stemming removes any suffixes, leaving behind it's inflected word. The outcome is not always desirable as you can see, cutting the -es from Studies. One common stemmer is the Porter stemmer, which reduces the words to its 'root' form.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Lemmatization on the other hand is smarter, and uses linguistics to reduce the word to it's base meaning. 'Studies' and 'Studying' both have the same base meaning of 'Study'. However, before you can apply lemmatization, you need to have a trained dictionary for that language to discover what is the base meaning. Luckily for us, the English language has many of such dictionaries.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Capitalization and Special Characters transformation is simply turning all the words into lowercase, and removing non-alphabet characters&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; sentence = sentence.lower() &amp;gt;&amp;gt;&amp;gt; sentence = re.sub('[^a-zA-Z]',' ',sentence)&lt;/code&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Stopwords removal is a method for removing common stopwords in a text. Stopwords carry little to no meaning to them, and are sentimentally agnostic, hence they should be removed so as not to generate too much noise in our matrix. A list of common stopwords can be found in &lt;a href="https://gist.github.com/sebleier/554280"&gt;NLTK's collection&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Transforming Tokens to Vectors&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;Bag of Words&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once we have our collection of pre-processed tokens, we now need to transform them into features, or numeric vectors for us to fit into our model&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Bag of Words (BoW) model is one way to quantize the text into numerical information. It is also called Text Vectorization, because we're converting a sentence into a numerical vector.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;BoW captures the counts of the words in a sentence &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;John&lt;/span&gt; &lt;span class="n"&gt;likes&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;watch&lt;/span&gt; &lt;span class="n"&gt;movies&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Mary&lt;/span&gt; &lt;span class="n"&gt;likes&lt;/span&gt; &lt;span class="n"&gt;movies&lt;/span&gt; &lt;span class="n"&gt;too&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;

&lt;span class="ss"&gt;&amp;quot;John&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;likes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;to&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;movies&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Mary&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;likes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;movies&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;too&amp;quot;&lt;/span&gt;

&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;John&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;likes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;to&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;movies&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Mary&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;too&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The downside of BoW model is that we lose word order, which is important when it comes to sentiment analysis. The ordering of the words in a sentence can produce very different meanings&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;"not all apples are bad"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;"all apples are not bad"&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The former implies that not every single apple is bad, but there can be bad ones. The latter implies that every single apple is not bad, which means there are no bad ones.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, BoW counts are not normalized, which loses another feature of word importance. Words that occur very frequently such as stopwords hold little weight if they appear multiple times, and in every document. We want words that are rare, and occur less frequently. These words will have stronger features.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;TF-IDF&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After we have the collection of words generated from BoW, we can count the frequency of the word, and the presence of the word in a given document. This  technique is called Term-Frequency - Inverse Document Frequency (TF-IDF) model.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This is calculated by counting the number of times the word appears in all documents (TF), and the number of documents this word appears in (DF). We take the inverse of DF (IDF), because we don't want words that appear too frequently in all documents. &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A word with a high TF-IDF indicates a high term frequency, low document count. This highlights important issues in a document, but that are not shared across the whole corpus&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":4} --&gt;

&lt;h4&gt;N-Grams&lt;/h4&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The BoW model grows linearly with each distinct vocabulary. With every new word added, the vector size increases by 1. This leads to an extremely spares and high dimension vector. To attempt to reduce the dimensions, we group words together into what we call N-grams, where N is the number of words in the group.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;N-grams are an improvement because it reduces the dimensionality of the vector, and it also captures context from the surrounding words.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Below shows a 2-gram representation of a sentence:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:code --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;John&lt;/span&gt; &lt;span class="n"&gt;likes&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;watch&lt;/span&gt; &lt;span class="n"&gt;movies&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Mary&lt;/span&gt; &lt;span class="n"&gt;likes&lt;/span&gt; &lt;span class="n"&gt;movies&lt;/span&gt; &lt;span class="n"&gt;too&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;

&lt;span class="ss"&gt;&amp;quot;John likes&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;likes to&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;to watch&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;watch movies&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;movies Mary&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;Mary likes&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;likes movies&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;&amp;quot;movies too&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- /wp:code --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We should be careful however, in choosing the appropriate value of N. If we generate too much N-grams (N is small), we end up generating too much noise.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After the N-gram collection is generated, we can future refine the selection with the heuristic:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Remove high and low frequency n-grams&lt;/li&gt;
&lt;li&gt;High Frequency n-grams = Stop words&lt;/li&gt;
&lt;li&gt;Low Frequency n-grams = Rare words&lt;/li&gt;
&lt;li&gt;Keep medium frequency n-grams&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Training a Model with the Vectors&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Once we have pre-processed the sentences to tokens, and vectorized them into numerical values, we can use those vectors to train our models to answer our questions.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Text processing"></category></entry><entry><title>Pass The Hash Attack</title><link href="/pass-the-hash-attack.html" rel="alternate"></link><published>2019-01-06T10:45:00+00:00</published><updated>2019-01-06T10:45:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2019-01-06:/pass-the-hash-attack.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Passing the Hash attack is a way of logging on to the machine without knowing the actual password of the user. It uses the hash value for authentication, instead of the plain text passwords.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This attack vector is possible in Windows, due to how they store the passwords in their …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Passing the Hash attack is a way of logging on to the machine without knowing the actual password of the user. It uses the hash value for authentication, instead of the plain text passwords.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;This attack vector is possible in Windows, due to how they store the passwords in their system &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;How Windows stores your passwords in memory&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;The Local Security Authority Subsystem Service, LSASS.exe, is a process that runs in memory, and it is responsible for performing tasks such as:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;

&lt;ul&gt;
&lt;li&gt;Enforcing Security Policies&lt;/li&gt;
&lt;li&gt;Handling Login Verification&lt;/li&gt;
&lt;li&gt;Performing Password Changes&lt;/li&gt;
&lt;li&gt;Generating Access Tokens&lt;/li&gt;
&lt;li&gt;Writing to Windows Security Log&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;LSASS.exe is a crucial component for running Windows, and a forceful termination of LSASS.exe will result in the Welcome screen losing its accounts, requiring a restart of the machine.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After a user logs on to the system, a variety of credentials are generated and stored in LSASS.exe, which functions as a Single-Sign-On (SSO). The SSO is to allow quick and automated user authentication for resources. These credentials includes Kerberos Tickets, NTLM Hashes, LM Hashes and clear text passwords.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Because LSASS.exe is running in memory, it should be no surprise that all these credentials and hashes are stored in memory as well. This makes it a valuable target for attackers to steal credentials.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:quote {"className":"is-style-default"} --&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;If you discover that LSASS.exe is not in C:\Windows\System32, or that it is consuming more resources than necessary, that is a cause for concern.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- /wp:quote --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Extracting Password Hash from Memory&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Since the password hashes are all stored in memory, all we have to do is to find techniques to extract the information. There are already many existing ways to do this, the most famous being the tool &lt;a href="https://github.com/gentilkiwi/mimikatz/wiki"&gt;Mimikatz&lt;/a&gt; &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;One way of doing this is to dump the LSASS.exe process from memory to disk by using tools such as ProcDump (Which is a Microsoft Signed Binary, so it won't trigger any red flags when executed).&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;After you have dumped the password hashes, there are two attack scenarios that can happen:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Decrypt the password hashes to obtain the plaintext password&lt;ul&gt;
&lt;li&gt;The hashes are encrypted using the Windows API &lt;strong&gt;LsaProtectMemory&lt;/strong&gt;.  We can simply decrypt it by calling &lt;strong&gt;LsaUnprotectMemory&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Don't decrypt the hash, and simply pass it to the authentication mechanism (Pass the Hash Attack)&lt;ul&gt;
&lt;li&gt;Inject the hash to LSASS.exe and open session with the injected hash.&lt;/li&gt;
&lt;li&gt;Implement part of the NTLM protocol for the authentication with the hash and send commands over the network with protocols like SMB, WMI, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Detecting a Pass The Hash Attack using Windows Event Log&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;You can detect Pass the Hash attack by reviewing your Windows Event Security Log.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;A Pass the Hash attack takes places with the NTLM authentication type, and it can be seen in the Event Log with the following features:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;NTLM connection takes place&lt;/li&gt;
&lt;li&gt;Event ID 4624 (“&lt;em&gt;An account was successfully logged on&lt;/em&gt;”)&lt;/li&gt;
&lt;li&gt;Logon Type 3 &lt;em&gt;(“A user or computer logged on to this computer from the network”&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Authentication Package NTLM (or by logon process name NtLmSsp)&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;These features are indicative of an NTLM login process, but it does not mean that a Pass the Hash has taken place. Further analysis, such as user behavior, allowed logon techniques and privileges assigned can tell you more.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content><category term="Pass the hash"></category><category term="Windows"></category></entry><entry><title>Setting Up Your Own IDS</title><link href="/setting-up-your-own-ids.html" rel="alternate"></link><published>2018-12-30T19:49:00+00:00</published><updated>2018-12-30T19:49:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-12-30:/setting-up-your-own-ids.html</id><summary type="html">&lt;h1&gt;Mininet Floodlight Snort&lt;/h1&gt;
&lt;p&gt;In this post, we're going to be building our own IDS setup to play around with.&lt;/p&gt;
&lt;p&gt;This setup can be used as a POC, or to just see how an IDS works. We're going to be using 3 technologies here.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Mininet, which is a program to create …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;h1&gt;Mininet Floodlight Snort&lt;/h1&gt;
&lt;p&gt;In this post, we're going to be building our own IDS setup to play around with.&lt;/p&gt;
&lt;p&gt;This setup can be used as a POC, or to just see how an IDS works. We're going to be using 3 technologies here.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Mininet, which is a program to create your own virtual network on your host.&lt;/li&gt;
&lt;li&gt;Snort, which is an IDS program&lt;/li&gt;
&lt;li&gt;Floodlight, which is an SDN controller&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[gallery ids="110,109,108" type="rectangular" link="none"]&lt;/p&gt;
&lt;h2&gt;The Setup&lt;/h2&gt;
&lt;p&gt;We're going to setup an SDN network with 5 hosts, with host 5 sniffing traffic on host 4 using Snort.&lt;/p&gt;
&lt;p&gt;This project will have 3 malicious actors (h1, h2, h3), a victim machine (h4) and an IDS using Snort sniffer (h5)&lt;/p&gt;
&lt;p&gt;We will configure the network such that the 5 hosts are connected to the a switch, and the switch is connected to Floodlight SDN Controller. h1, h2 and h3 will attack h4 with a DoS attack, and h5 will be able to pick it up using Snort rules.&lt;/p&gt;
&lt;h2&gt;Setting up floodlight&lt;/h2&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
git://github.com/floodlight/floodlight.git&lt;br&gt;
\$ cd floodlight&lt;br&gt;
\$ git submodule init&lt;br&gt;
\$ git submodule update&lt;br&gt;
\$ ant&lt;/p&gt;
&lt;p&gt;\$ sudo mkdir /var/lib/floodlight&lt;br&gt;
\$ sudo chmod 777 /var/lib/floodlight&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;After you've configured Floodlight, run it with:&lt;br&gt;
&lt;code&gt;$ java -jar target/floodlight.jar&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Floodlight GUI will be running on http://localhost:8080/ui/pages/index.html&lt;/p&gt;
&lt;h2&gt;Setting up mininet&lt;/h2&gt;
&lt;p&gt;Clone and install:&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ git clone git://github.com/mininet/mininet&lt;br&gt;
\$ cd mininet&lt;br&gt;
\$ sudo ./util/install.sh -a&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Mininet is now installed.&lt;/p&gt;
&lt;p&gt;Spawn your network with the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ sudo mn --topo single,5 --controller=remote,ip=127.0.0.1,port=6653&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Spawns a single layer network, with 5 hosts connected to a switch.&lt;/p&gt;
&lt;p&gt;The switch is connected to a remote controller, which is the floodlight service you setup earlier.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: your port specified in this command should be &lt;code&gt;6653&lt;/code&gt; and not &lt;code&gt;8080&lt;/code&gt;. &lt;code&gt;8080&lt;/code&gt; is used for showing the UI, &lt;code&gt;6653&lt;/code&gt; is used for communicating with your switch.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If your floodlight service is running on another machine, configure the &lt;code&gt;ip&lt;/code&gt; and &lt;code&gt;port&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;h2&gt;Setting up Snort (In Ubuntu)&lt;/h2&gt;
&lt;p&gt;Before installing Snort, you have to first install DAQ&lt;/p&gt;
&lt;p&gt;Updating your apt&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ apt-get update -y&lt;br&gt;
\$ apt-get upgrade -y&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Installing dependencies&lt;br&gt;
&lt;code&gt;$ apt-get install openssh-server ethtool build-essential libpcap-dev libpcre3-dev libdumbnet-dev bison flex zlib1g-dev liblzma-dev openssl libssl-dev&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Grabbing DAQ source (Change the value of the version to the lastest one)&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ wget https://www.snort.org/downloads/snort/daq-2.0.6.tar.gz&lt;br&gt;
\$ tar xvf daq-2.0.6.tar.gz&lt;br&gt;
\$ cd daq-2.0.6&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Configure and install DAQ&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ ./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Now that you've installed DAQ, you can proceed to install Snort&lt;/p&gt;
&lt;p&gt;Grabbing Snort source (Change the value of the version to the lastest one)&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ wget https://www.snort.org/downloads/snort/snort-2.9.8.3.tar.gz&lt;br&gt;
\$ tar vzf snort-2.9.8.3.tar.gz&lt;br&gt;
\$ cd snort-2.9.8.3&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Configure and install Snort&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ ./configure --enable-sourcefire &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Link the libraries&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ ldconfig&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Creating a symbolic link to Snort binary&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ ln -s /usr/local/bin/snort /usr/sbin/snort&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Test it out!&lt;br&gt;
&lt;code&gt;$ snort -V&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After Snort is up and running, you will need to create directory structures for it&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
\$ mkdir /etc/snort&lt;/p&gt;
&lt;p&gt;\$ mkdir /etc/snort/preproc_rules&lt;/p&gt;
&lt;p&gt;\$ mkdir /etc/snort/rules&lt;/p&gt;
&lt;p&gt;\$ mkdir /var/log/snort&lt;/p&gt;
&lt;p&gt;\$ mkdir /usr/local/lib/snort_dynamicrules&lt;/p&gt;
&lt;p&gt;\$ touch /etc/snort/rules/white_list.rules&lt;/p&gt;
&lt;p&gt;\$ touch /etc/snort/rules/black_list.rules&lt;/p&gt;
&lt;p&gt;\$ touch /etc/snort/rules/local.rules&lt;/p&gt;
&lt;p&gt;\$ chmod -R 5775 /etc/snort/&lt;/p&gt;
&lt;p&gt;\$ chmod -R 5775 /var/log/snort/&lt;/p&gt;
&lt;p&gt;\$ chmod -R 5775 /usr/local/lib/snort&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;h2&gt;Configuring Snort Rules&lt;/h2&gt;
&lt;p&gt;Download Snort rules here https://www.snort.org/downloads&lt;/p&gt;
&lt;p&gt;Edit your &lt;code&gt;snort.conf&lt;/code&gt; accordingly to remove any preprocessors you don't have&lt;/p&gt;
&lt;p&gt;If you're having trouble, &lt;code&gt;$ sudo find / -type f -name snort.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Adding a rule in &lt;code&gt;snort.conf&lt;/code&gt; to catch DoS by ICMP packets&lt;/p&gt;
&lt;p&gt;&lt;code&gt;alert icmp any any -&amp;amp;gt; any any (threshold: type both, track by_dst, count 70, seconds 10; msg: "DoS by ICMP detected"; sid:1001;)&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Mirroring port h4 to h5 and sniff using Snort&lt;/h2&gt;
&lt;p&gt;Command to mirror h4 traffic to h5&lt;br&gt;
&lt;code&gt;mininet$ s1 ovs-vsctl -- set Bridge "s1" mirrors=@m -- --id=@s1-eth4 get Port s1-eth4 -- --id=@s1-eth5 get Port s1-eth5 -- --id=@m create Mirror name=e4toe5 select-dst-port=@s1-eth4 output-port=@s1-eth5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now all traffic that is flowing into h4 will be mirrored onto h5, where Snort is running.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mininet$ xterm h5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In the new terminal spawned for h5, run:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;h5$ ifconfig&lt;/code&gt; to get the adapter name&lt;/p&gt;
&lt;p&gt;&lt;code&gt;h5$ snort -i &amp;amp;lt;Adapter name&amp;amp;gt; -c &amp;amp;lt;snort.conf location&amp;amp;gt; &amp;amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;h5 is now sniffing traffic on h4&lt;/p&gt;
&lt;h2&gt;Starting the attack&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;mininet$ h1 ping -f h4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This launches a barrage of ICMP packets from h1 to h4, which will subsequently be detected by h5, who is sniffing h4.&lt;/p&gt;
&lt;p&gt;h5 will then write an alert which you should see in &lt;code&gt;/var/log/snort/alert&lt;/code&gt; the message &lt;code&gt;"DoS by ICMP detected"&lt;/code&gt;&lt;/p&gt;</content><category term="Mininet"></category><category term="SDN"></category><category term="Snort"></category></entry><entry><title>Software Defined Networking (SDN)</title><link href="/software-defined-networking-sdn.html" rel="alternate"></link><published>2018-12-23T10:29:00+00:00</published><updated>2018-12-23T10:29:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-12-23:/software-defined-networking-sdn.html</id><summary type="html">&lt;h1&gt;What is an SDN&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Software Defined Networking is a way of abstracting away the control logic of networking and packet switching away from the physical switches, and passing that control to a SDN Controller.&lt;/p&gt;
&lt;p&gt;The main idea of this is to allow the control to perform decision making on what …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;What is an SDN&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Software Defined Networking is a way of abstracting away the control logic of networking and packet switching away from the physical switches, and passing that control to a SDN Controller.&lt;/p&gt;
&lt;p&gt;The main idea of this is to allow the control to perform decision making on what to do with the packets on the switches behalf.&lt;/p&gt;
&lt;h1&gt;Components and Architecture of a SDN&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="Untitled Diagram (1)" class="alignnone size-full wp-image-105" height="406" src="/media/2018/11/untitled-diagram-1.png" width="686"&gt;&lt;/p&gt;
&lt;p&gt;It'll make more sense when the flow is explained bottom up, from the infrastructure layer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Infrastructure layer (Data Plane)]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is where your physical switches are. The packets from the network, be it intranet or internet, flows through these switches. Conventionally, a dedicated software will be running on each of the switches, deciding what do with the each packet that passes through them.&lt;/p&gt;
&lt;p&gt;Now, instead of the switches making the decision, the control is passed to the Control layer. This means that the switches will have to query the SDN Controller about what action to take for each packet.&lt;/p&gt;
&lt;p&gt;But it's not that dumb to query the controller for every single packet. The SDN Switch has a table which stores a set of rules as to what action to perform for which packet. Only when a packet does not match any rows on the table, does the SDN Switch query the controller.&lt;/p&gt;
&lt;p&gt;The SDN Switch gets the information from the SDN Controller via Southbound protocols, such as Openflow. (We'll cover that later)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Control layer (Control Plane)]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The SDN Controller acts as the brains of the system. You can think of it as the CPU, where it brokers requests from the hardware to the application, vice-versa.&lt;/p&gt;
&lt;p&gt;The applications are able to push their desired changes down to the controller, where the controller disseminates the changes down to the SDN Switches via Openflow.&lt;/p&gt;
&lt;p&gt;One scenario might be a change in firewall rules done on a firewall application. This change is then push down to the SDN Controller, and down to the SDN Switches.&lt;/p&gt;
&lt;p&gt;An example of an SDN Controller is &lt;a href="https://github.com/floodlight/floodlight"&gt;Floodlight &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Application layer&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;The application layer where all your applications sit. Before SDN, they used to sit on the physical switch itself. That made it tedious to execute updates or changes to the software on the switch when you have multiple switches.&lt;/p&gt;
&lt;p&gt;With SDN, these applications are taken out of the switch, and resides elsewhere. These applications can also be virtualized via a concept known as Network Functions Virtualization (NFV). NFV is just another way of describing virtualizing Networking Software, such as firewalls and IDS systems.&lt;/p&gt;
&lt;p&gt;North-Bound API (OpenDayLight)&lt;/p&gt;
&lt;p&gt;South-Bound API (Openflow)&lt;/p&gt;
&lt;h1&gt;Benefits of a SDN&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;In the past, your network topology was defined by your physical switches. Now that the applications have been extracted out the switches, your network topology is effectively defined by your software (hence the name Software Defined Network).&lt;/p&gt;
&lt;p&gt;This gives you more control the of switches, and the ease of configuring them.&lt;/p&gt;
&lt;p&gt;One draw back of SDN is the introduction of a single point of failure. Although it does give you more granular security by controlling each SDN Switch, the bottle neck lies in the SDN Controller.&lt;/p&gt;</content><category term="SDN"></category></entry><entry><title>Kaggle Boiler Plate</title><link href="/kaggle-boiler-plate.html" rel="alternate"></link><published>2018-12-16T21:33:00+00:00</published><updated>2018-12-16T21:33:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-12-16:/kaggle-boiler-plate.html</id><summary type="html">&lt;p&gt;I've been playing around with Kaggle competitions for a while, and there are usually quite a few steps to perform.&lt;/p&gt;
&lt;p&gt;I've compiled a list of them below, in sequential order. These are by no means hard and fast rules, but simple heuristics to follow!&lt;/p&gt;
&lt;p&gt;I've added links here and there …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been playing around with Kaggle competitions for a while, and there are usually quite a few steps to perform.&lt;/p&gt;
&lt;p&gt;I've compiled a list of them below, in sequential order. These are by no means hard and fast rules, but simple heuristics to follow!&lt;/p&gt;
&lt;p&gt;I've added links here and there to guide you a long.&lt;/p&gt;
&lt;h1&gt;Importing your libraries&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;You're gonna have to import the usual &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;sklearn&lt;/code&gt; to do your dataframe manipulations, and machine learning stuff.&lt;/p&gt;
&lt;p&gt;Aside from those, you'll likely be importing other stuff that are relevant in transforming your data.&lt;/p&gt;
&lt;h1&gt;Reading in training data and testing data&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;When you first start the project, the first thing you want to do is to read in the data. It's usually named &lt;code&gt;train.csv&lt;/code&gt; and probably contains a few million lines.&lt;/p&gt;
&lt;p&gt;You most probably won't be able to read in all the data at once, so you're gonna have to read in just a few lines to get a preview.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;df_train = pd.read_csv("train.csv", nrows=1000000)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Of course when you're doing the actual training of the model, you're going to have to read in the whole thing!&lt;/p&gt;
&lt;p&gt;We also read in the test set, usually called &lt;code&gt;test.csv&lt;/code&gt;. The reason why we're reading in the test set, is so that when we perform feature creation and data massaging, we can do it both on the test and train data.&lt;/p&gt;
&lt;h1&gt;Visualizing data&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;You're going to want to visualize the data you've read in to analyze for any outliers, or obvious trends that can be helpful in feature creation.&lt;/p&gt;
&lt;p&gt;For univariate analysis, I usually apply barchart, or histogram, while for bivariate analysis, I'll apply a scatter plot.&lt;/p&gt;
&lt;h3&gt;Univariate Analysis&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/residentmario/univariate-plotting-with-pandas"&gt;https://www.kaggle.com/residentmario/univariate-plotting-with-pandas&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Bivariate Analysis&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/residentmario/bivariate-plotting-with-pandas"&gt;https://www.kaggle.com/residentmario/bivariate-plotting-with-pandas&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Cleaning data&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;After visualizing your data, you'll more or less know the upper or lower bounds, outliers, and whats considered to be normal.&lt;/p&gt;
&lt;p&gt;You must now remove those values that lie outside those normal ranges. There are a common data abnormalities which are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Outliers&lt;/li&gt;
&lt;li&gt;Missing values&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some examples are: Taxi fares with negative values, coordinates that plot on the ocean, Null or NaN values, and many more.&lt;/p&gt;
&lt;p&gt;You want to be cleaning your data BEFORE training your model. If not, there will be unnecessary noise. You'll end up with a few lesser rows than your original training set.&lt;/p&gt;
&lt;p&gt;However, DO NOT CLEAN YOUR TESTING SET. The testing set is supposed to be untouched, aside from feature engineering.&lt;/p&gt;
&lt;h1&gt;Feature Engineering&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;After looking at your data, you will definitely need to engineer some features on your own. Doing this allows you to find features that correlated more strongly with the value you're predicting.&lt;/p&gt;
&lt;p&gt;We have 2 types of data type: Continuous and Discrete, and each of the data types have to be handled differently when doing feature engineering&lt;/p&gt;
&lt;p&gt;Continuous data runs in infinite ranges, while Discrete data are things that fall into categories.&lt;/p&gt;
&lt;p&gt;Example of Continuous data are prices, age and temperature. Strings are also considered Continuous data&lt;/p&gt;
&lt;p&gt;Examples of Discrete data are gender and types of cars.&lt;/p&gt;
&lt;h3&gt;Continuous Data Feature Engineering&lt;/h3&gt;
&lt;p&gt;For continuous data, we can bin the data into intervals.&lt;/p&gt;
&lt;p&gt;An example would be age group, where individual ages might be too scattered, but by grouping them in multiples of 5s or 10s, you might get a better representation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="mi"&gt;51&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;55&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;Group&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; 
&lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;Group&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; 
&lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;65&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;Group&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; 
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;53&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;55&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;62&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For strings, we need to extract out relevant data that can be represented in numeric form. One example is parsing of the dates. In your original data, you're given a datetime string, which isn't helpful at all. You'll want to engineer features such as the day of the week, the hour, month, year, or even the seconds. These numerical features are much more helpful as compared to a string value.&lt;/p&gt;
&lt;h3&gt;Discrete Data Feature Engineering&lt;/h3&gt;
&lt;p&gt;For discrete data, the categories in the data can be one-hot-encoded. The reason why we do that is because when we change the categories to numeric values, we don't want to accidentally imply meaning and hierarchy between the numbers.&lt;/p&gt;
&lt;p&gt;For example if we have 5 different categories of cars, and we change them numerically to 0, 1, 2, 3, 4, the machine may end up learning that the 4th category is more important than the 0th category, based on the simple fact that 4 is greater than 0.&lt;/p&gt;
&lt;p&gt;So to prevent this problem of false importance, we use one-hot-encoding. The idea of one-hot-encoding can be visually represented as such&lt;/p&gt;
&lt;p&gt;&lt;img alt="" class="alignnone wp-image-170" height="220" src="/media/2018/12/mtimfxh.png?w=300" width="560"&gt;&lt;/p&gt;
&lt;p&gt;This way, the categories are represented as 1s and 0s, which minimizes the possibility of learning false importance.&lt;/p&gt;
&lt;p&gt;We should take note that one-hot-encoding should be done on your train and test set combined. The reason why we want to do this is so we don't miss out data that is in the test and not in the train, vice-versa. If there is missing data, and we perform one-hot-encoding separately on the train and test, we will end up with missing columns, as one-hot-encoding does not generate them.&lt;/p&gt;
&lt;h3&gt;Feature Interaction&lt;/h3&gt;
&lt;p&gt;There is also Feature interaction, where two or more features are correlated or have interactions between each other. We can capture this interaction between two features by creating a new feature, which is a multiplication of these two correlated features.&lt;/p&gt;
&lt;h1&gt;Splitting of Data&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Once you've cleaned your data and created your features, you can now start training your model! But before you do that, you first need to split your data in a train and test set. This is for performing a validation test to evaluate your model.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;code&gt;y&lt;/code&gt; is your target value to predict.&lt;/p&gt;
&lt;p&gt;The way you use these values are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;y_train&lt;/code&gt; for training the model&lt;/li&gt;
&lt;li&gt;Feed &lt;code&gt;X_test&lt;/code&gt; to your model&lt;/li&gt;
&lt;li&gt;Evaluate the output with &lt;code&gt;y_test&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Scaling Data&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Because not all of your data will be in the same scale, we have to normalize them all to be of the same scale.&lt;/p&gt;
&lt;p&gt;For example, the scale for age can range from 0-90, while a pay range can go from 2000 - 10,000. This is bad for machine learning, because the model might attribute a hidden (but wrong) meaning to this difference in range.&lt;/p&gt;
&lt;p&gt;0 - 90 has a small range, while 2000 - 10,000 has a larger range.&lt;/p&gt;
&lt;p&gt;How we scale this is by using sklearn packages such as MinMax scaling.&lt;/p&gt;
&lt;p&gt;A potential problem to scaling is having data leakage, where we learn some attributes from the testing data set into the training dataset.&lt;/p&gt;
&lt;p&gt;How we overcome the problem of data leakage is to perform fit-transform on the training set, and only perform transform on your testing set&lt;/p&gt;
&lt;h1&gt;Training&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;You got to first identify if you're solving a classification or a regression problem, and a supervised or unsupervised problem.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sklearn&lt;/code&gt; provides a wide range of models for you to pick from.&lt;/p&gt;
&lt;p&gt;Models for Supervised learning in &lt;code&gt;sklearn&lt;/code&gt;: &lt;a href="http://scikit-learn.org/stable/supervised_learning.html"&gt;http://scikit-learn.org/stable/supervised_learning.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Models for Unsupervised learning in &lt;code&gt;sklearn&lt;/code&gt;: &lt;a href="http://scikit-learn.org/stable/unsupervised_learning.html"&gt;http://scikit-learn.org/stable/unsupervised_learning.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There's an overpowered model right now called XGBoost, but I highly recommend using it AFTER you've played around with other models. This is to allow you to have an understanding of how other models work, because XGBoost is definitely not a silver bullet.&lt;/p&gt;
&lt;p&gt;Installing XGBoost is a little bit tricky, because its an external library.&lt;/p&gt;
&lt;p&gt;If you're using Windows, these are the steps I followed: &lt;a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en"&gt;https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And the Linux version:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[code lang=&amp;quot;text&amp;quot;]&lt;/span&gt;
&lt;span class="na"&gt;$ pip install xgboost&lt;/span&gt;
&lt;span class="na"&gt;$ git clone https://github.com/dmlc/xgboost# cd xgboost-master&lt;/span&gt;
&lt;span class="na"&gt;$ make&lt;/span&gt;
&lt;span class="na"&gt;$ cd python-package/&lt;/span&gt;
&lt;span class="na"&gt;$ python setup.py install&lt;/span&gt;
&lt;span class="k"&gt;[/code]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can now &lt;code&gt;import xgboost&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;See how much easier it is on Linux.&lt;/p&gt;
&lt;h1&gt;Validation&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Once your model is trained, you would need to validate the output with &lt;code&gt;y_test&lt;/code&gt;. &lt;code&gt;y_test&lt;/code&gt; contains the true values, while your model outputs a set of predicted values.&lt;/p&gt;
&lt;p&gt;Again, &lt;code&gt;sklearn&lt;/code&gt; provides a suite of tools for performing evaluation, depending on what model you were using: &lt;a href="http://scikit-learn.org/stable/modules/model_evaluation.html"&gt;http://scikit-learn.org/stable/modules/model_evaluation.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you get a bad score here, you'll want to revisit your feature engineering, or data cleaning again to see what you can do differently. Remember, more features != better model!&lt;/p&gt;
&lt;h1&gt;Prediction&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Pump in the testing set into your model you trained, and get a set of output values. There'll be no evaluation on your side here. Evaluation will be done by Kaggle once you submit them. This is essentially your answer to their problem.&lt;/p&gt;
&lt;h1&gt;Writing to CSV&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Kaggle usually provides a file called &lt;code&gt;sample_submission.csv&lt;/code&gt; to show you the format with the competition requires for submission.&lt;/p&gt;
&lt;p&gt;Transform your answers to fit into that model, then write the answers to CSV for submission&lt;/p&gt;
&lt;p&gt;&lt;code&gt;​​​​​df.to_csv("my_submission.csv", index=False)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I notice that you'll want to include &lt;code&gt;index=False&lt;/code&gt; to exclude the row numbers in the dataframe&lt;/p&gt;
&lt;h1&gt;Submit Your Entry&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;That's it! Go on and submit your entry to Kaggle, and see how you rank against other Kagglers. Don't be disheartened if you didn't perform well, it takes a few iterations to improve your model.&lt;/p&gt;
&lt;p&gt;Also, don't be afraid to read up on other people's kernels to gain inspiration!&lt;/p&gt;
&lt;!-- wp:image --&gt;

&lt;figure class="wp-block-image"&gt;
&lt;img alt&gt;&lt;/img&gt;

&lt;/figure&gt;

&lt;!-- /wp:image --&gt;</content></entry><entry><title>Async and Await in C#</title><link href="/async-and-await-in-c.html" rel="alternate"></link><published>2018-12-09T22:40:00+00:00</published><updated>2018-12-09T22:40:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-12-09:/async-and-await-in-c.html</id><summary type="html">&lt;h2&gt;Async and Await in C&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; are used when we are doing asynchronous programming. Why we would want to do asynchronous programming, is due to performance issues. When we have two unrelated tasks that are in the program, and one task takes a long time to process, it …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Async and Await in C&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; are used when we are doing asynchronous programming. Why we would want to do asynchronous programming, is due to performance issues. When we have two unrelated tasks that are in the program, and one task takes a long time to process, it should not be holding up the other task.&lt;/p&gt;
&lt;p&gt;We use Asynchronous programming to hand over program controls to ensure that no one process is holding up the entire program.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; are used together to make a program asynchronous.&lt;/p&gt;
&lt;p&gt;Below is a simple example to make a program asynchronous&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
static void Main(string[] args)&lt;br&gt;
{&lt;br&gt;
DoSomething();&lt;br&gt;
Console.WriteLine("Control to Main!");&lt;br&gt;
Console.ReadLine();&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;public static async void DoSomething()&lt;br&gt;
{&lt;br&gt;
await Delay();&lt;br&gt;
Console.WriteLine("Control back to Method!");&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;async static Task Delay()&lt;br&gt;
{&lt;br&gt;
await Task.Delay(5000);&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The output on the console:&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
Control to Main!&lt;br&gt;
&amp;lt;after a 5 second delay&amp;gt;&lt;br&gt;
Control back to Method!&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;You first have to declare the method asynchronous with &lt;code&gt;async&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;async static Task Delay()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Next, we put the keyword &lt;code&gt;await&lt;/code&gt; beside the command that will take a long time.&lt;/p&gt;
&lt;p&gt;What &lt;code&gt;await&lt;/code&gt; does is this&lt;br&gt;
- It awaits for the command to be completed&lt;br&gt;
- While it is awaiting, it passes control back up to the caller&lt;br&gt;
- After the command is completed, the control is passed back to the callee&lt;/p&gt;
&lt;p&gt;If we look at the code, the program first calls &lt;code&gt;DoSomething()&lt;/code&gt;, which calls &lt;code&gt;await Delay()&lt;/code&gt;, which then executes &lt;code&gt;await Task.Delay(5000);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;await Task.Delay(5000);&lt;/code&gt; is executed, &lt;code&gt;Delay()&lt;/code&gt; passes control back up to the caller, which is &lt;code&gt;DoSomething()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Because &lt;code&gt;DoSomething()&lt;/code&gt; is awaiting &lt;code&gt;Delay()&lt;/code&gt;, it passes control back up again to &lt;code&gt;Main()&lt;/code&gt;, which then executes &lt;code&gt;Console.WriteLine("Control to Main!");&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After &lt;code&gt;await Task.Delay(5000);&lt;/code&gt; is completed, it returns to &lt;code&gt;DoSomething()&lt;/code&gt;, which executes &lt;code&gt;Console.WriteLine("Control back to Method!");&lt;/code&gt;, and finally returns to &lt;code&gt;Main()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Another example is given below&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
async Task&amp;lt;int&amp;gt; AccessTheWebAsync()&lt;br&gt;
{&lt;br&gt;
HttpClient client = new HttpClient();&lt;/p&gt;
&lt;p&gt;Task&amp;lt;string&amp;gt; getStringTask = client.GetStringAsync("http://msdn.microsoft.com");&lt;/p&gt;
&lt;p&gt;// You can do work here that doesn't rely on the string from GetStringAsync.&lt;br&gt;
DoIndependentWork();&lt;/p&gt;
&lt;p&gt;string urlContents = await getStringTask;&lt;br&gt;
//The thing is that this returns an int to a method that has a return type of Task&amp;lt;int&amp;gt;&lt;br&gt;
return urlContents.Length;&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Here, &lt;code&gt;Task getStringTask = client.GetStringAsync("http://msdn.microsoft.com");&lt;/code&gt; is called, followed by &lt;code&gt;DoIndependentWork();&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We next call &lt;code&gt;string urlContents = await getStringTask;&lt;/code&gt;, which awaits on &lt;code&gt;getStringTask&lt;/code&gt;. There are two possible scenerios here&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;After &lt;code&gt;DoIndependentWork()&lt;/code&gt; is completed, &lt;code&gt;Task getStringTask = client.GetStringAsync("http://msdn.microsoft.com");&lt;/code&gt; is completed as well, and &lt;code&gt;getStringTask&lt;/code&gt; is fully initialized. In this case, there is no control being passed back to the caller of &lt;code&gt;AccessTheWebAsync()&lt;/code&gt;, and the program just runs through.&lt;/li&gt;
&lt;li&gt;After &lt;code&gt;DoIndependentWork()&lt;/code&gt; is completed, &lt;code&gt;Task getStringTask = client.GetStringAsync("http://msdn.microsoft.com");&lt;/code&gt; NOT completed, and &lt;code&gt;getStringTask&lt;/code&gt; is NOT initialized. In this case, there control is passed back to the caller of &lt;code&gt;AccessTheWebAsync()&lt;/code&gt; for execution. Only after &lt;code&gt;getStringTask&lt;/code&gt; has been initialized, will the program pass back control to &lt;code&gt;AccessTheWebAsync()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And for obvious reasons, &lt;code&gt;async&lt;/code&gt; cannot be a modifier on the &lt;code&gt;Main&lt;/code&gt; method, because it is the root caller.&lt;/p&gt;</content><category term="Async"></category><category term="Await"></category></entry><entry><title>The Culture Code</title><link href="/the-culture-code.html" rel="alternate"></link><published>2018-12-02T22:38:00+00:00</published><updated>2018-12-02T22:38:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-12-02:/the-culture-code.html</id><summary type="html">&lt;h2&gt;Culture Code&lt;/h2&gt;
&lt;p&gt;I've just finsihed reading &lt;a href="https://www.amazon.com/Culture-Code-Secrets-Highly-Successful/dp/0525492461"&gt;The Culture Code&lt;/a&gt;, and it was a really good book. Good books are those that either introduces new ideas, or reintroduces known ideas to be relevant.&lt;/p&gt;
&lt;p&gt;In this book, he explores what are the cultural values that make up successful team. 3 cultural values …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Culture Code&lt;/h2&gt;
&lt;p&gt;I've just finsihed reading &lt;a href="https://www.amazon.com/Culture-Code-Secrets-Highly-Successful/dp/0525492461"&gt;The Culture Code&lt;/a&gt;, and it was a really good book. Good books are those that either introduces new ideas, or reintroduces known ideas to be relevant.&lt;/p&gt;
&lt;p&gt;In this book, he explores what are the cultural values that make up successful team. 3 cultural values were identified, and they are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Provide Psychological Safety&lt;/li&gt;
&lt;li&gt;Embrace Vulnerability&lt;/li&gt;
&lt;li&gt;Create Purpose&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Psychological Safety&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Psychological safety means that person feels safe. Not physically safe (physical safety is assumed to be present, by law), but mentally safe.&lt;/p&gt;
&lt;p&gt;Safe to sound out ideas, safe to make mistakes, safe to question assumptions.&lt;/p&gt;
&lt;p&gt;By providing a safe environment for the employees to work in, they can perform at their best.&lt;/p&gt;
&lt;p&gt;Some actions to provide psychological safety are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Overcommunicate your listening&lt;/p&gt;
&lt;p&gt;Let the person know that his ideas are valued, and he is being listened to. Avoid interrupting the person when he is talking. Seek to understand, and not just listen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Embrace the messenger&lt;/p&gt;
&lt;p&gt;Bringing bad news is tough, and you should appreciate the person who is willing to do it. Don't shoot the messenger, he is doing everyone a favour by telling the bad news. If he didn't care, he wouldn't even tell. By telling, it shows that he cares, so care for him too.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overdo Thank-Yous&lt;/p&gt;
&lt;p&gt;Let the person know how appreciative you are. Even if you are his leader, thank him for allowing you to coach him. When things are going right, thank the person. When things are going wrong, thank the person. Thank the least significant person. By thanking the person, we let him feel that he is valued.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Eliminate bad apples&lt;/p&gt;
&lt;p&gt;The bad apples lead to the broken window theory. A single person with bad behaviour encourages others to follow suit. Eliminate the bad behaviour, or eliminate the person. No one is to be a dickhead.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create Safe, Collison rich places&lt;/p&gt;
&lt;p&gt;A collison rich place is one that meetings can happen spontaneously. Serendipity is what they call it. Lunch corner that encourage people to hang out together instead of eating at their desk. Game corners that allow people to have fun together. Physical proximity plays a big part in cooperative behaviour.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure everyone has a voice&lt;/p&gt;
&lt;p&gt;Simple enough. Make sure everyone is able to voice out their opinions. No idea/opinion is a stupid idea/opinion. Whats worse than having bad ideas, is having no ideas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Avoid the sandwich feedback&lt;/p&gt;
&lt;p&gt;The idea of the sandwich feedback is to lessen the impact of the negative feedback, but thats really full of shit. Separate your feedbacks into two portions, Good feedback, and then Bad feedback. That's it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Have fun together&lt;/p&gt;
&lt;p&gt;Duh.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Embrace Vulnerability&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;We're all not as smart as we think we are, and the sooner your team realizes that, the quicker they will grow. If everyone acknowledges they suck, everyone will want to learn. If the team constantly exudes the air of false confidence, no one will dare to exhibit fallibility, and that will cause a huge crack in team dynamics&lt;/p&gt;
&lt;p&gt;Even if you're a leader, make your vulnerabilities known (Not personal or character vulnerabilities, but professional ones). Admit to what you don't know, and your subordinates will respect you more, else they will (and they will), think that you're an arrogant ass.&lt;/p&gt;
&lt;p&gt;Everyone secretly feels vulnerable, and when you show yourself to be vulnerable, this gives an opportunity for them to relate to you. "Oh hey, you don't know what's going on too! Let's learn together!"&lt;/p&gt;
&lt;p&gt;Some actions to embrace vulnerability are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Make sure the leader is the first to be vulnerable&lt;/p&gt;
&lt;p&gt;Only when the leader shows that it's okay to be vulnerable, will his subordinates follow suit. If they leader projects the image that vulnerability is unacceptable, no one would show it.&lt;/p&gt;
&lt;p&gt;3 questions leaders should ask: What should I continue doing, what am I not doing enough, how can I enable you.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overcommunicate Expectations&lt;/p&gt;
&lt;p&gt;Make sure everyone knows their roles well, and exactly what is expected of them. Only with defined roles can someone identify what their lacking to fulfill those roles and meet those expectations. If someone doesn't know where he's going, then he doesn't what he needs to improve on.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feedback Feedback Feedback&lt;/p&gt;
&lt;p&gt;Let the team know how well they are doing, how badly they are doing. Use methods such as AARs (After Action Reviews) to elicit feedback, and to give feedback. Sample questions are: What were the intended results, what were the actual results, what caused the results, what will we do same, what will we do different, what have we learnt.&lt;/p&gt;
&lt;p&gt;Feedback should be entirely professional, and never personal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Embrace the discomfort&lt;/p&gt;
&lt;p&gt;Vulnerability is something personal, and bringing it out to public can be quiet uncomfortable, but entirely necessary. Only by letting everyone know, will there be an opportunity for feedback and growth.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Create Purpose&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Create a story for the team to be part of. Create something that is greater than the self, and people would sacrifce themselves for it. If there is no greater purpose and only self interest, the team cannot function optimally.&lt;/p&gt;
&lt;p&gt;Some actions to create purpose are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Be extremely clear about your priorities&lt;/p&gt;
&lt;p&gt;What are we about? Where are we headed? Everyone must know about this, and it shoulden't be enigmatic and unclear. An unclear story leads to unclear actions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The purpose of proficiency, and the purpose of creativity&lt;/p&gt;
&lt;p&gt;Proficiency is needed for repeatable tasks, Creativity is needed for new tasks. Identify within the group which teams are for proficiency, which teams are for creativity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Embrace the use of catchphrases&lt;/p&gt;
&lt;p&gt;Even if they sound cheesy, but the work. A company motto that is easy to remember and simple to understand builds an identiy that the teams can assume. "Talk Less, Do More", "Work Hard, Be Nice"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use artifacts&lt;/p&gt;
&lt;p&gt;To build a convincing story, you sometimes need physical artifacts to bring out the realism in it. The Navy Seals display the battle gears of KIA operators, Pixar displays their Oscars. Showcase something significant to the company that sets the backdrop for the story.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Focus on barsetting behaviours&lt;/p&gt;
&lt;p&gt;Writing clean code, using source control and other behaviours that are consider best practices. When the team focuses on those behaviours, it becomes part of the identity that the team can assume. "Our team does xxx behaviours!" It's like a culture of excellence that originates from being part of the team.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Readings"></category><category term="The Culture Code"></category></entry><entry><title>C# Pass By Value</title><link href="/c-pass-by-value.html" rel="alternate"></link><published>2018-11-25T22:37:00+00:00</published><updated>2018-11-25T22:37:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-11-25:/c-pass-by-value.html</id><summary type="html">&lt;h2&gt;Pass by Value vs Reference&lt;/h2&gt;
&lt;h3&gt;Pass by value&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;When we pass call a function, we sometimes pass in some values for the function to use. Typically, it would look like this&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(parameters)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;&lt;code&gt;void swapValues(int x, int y)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When we pass a value to the function &lt;code&gt;swapValue()&lt;/code&gt;, we are …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Pass by Value vs Reference&lt;/h2&gt;
&lt;h3&gt;Pass by value&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;When we pass call a function, we sometimes pass in some values for the function to use. Typically, it would look like this&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(parameters)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;&lt;code&gt;void swapValues(int x, int y)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When we pass a value to the function &lt;code&gt;swapValue()&lt;/code&gt;, we are passing it by value.&lt;/p&gt;
&lt;p&gt;What this means is that, a new memory region is allocated from the stack for the new parameters &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, and the value of that memory region is set to the value that was passed to it.&lt;/p&gt;
&lt;p&gt;I'll write a post on what happens in the memory region when a function is called in the future (dealing with functions stack frame allocation etc). But for now, when we call a function, it is allocated a function stack frame, with all its variables and paramters contained within the frame.&lt;/p&gt;
&lt;p&gt;Let's look at the following code block&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
public static void Main()&lt;br&gt;
{&lt;br&gt;
int x = 10;&lt;br&gt;
int y = 20;&lt;/p&gt;
&lt;p&gt;swapValues(10, 20);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;void swapValues(int x, int y)&lt;br&gt;
{&lt;br&gt;
int temp;&lt;/p&gt;
&lt;p&gt;temp = x;&lt;br&gt;
x = y;&lt;br&gt;
y = temp;&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;Main()&lt;/code&gt; calls &lt;code&gt;swapValues()&lt;/code&gt;, a new stack frame is allocated just for &lt;code&gt;swapValues()&lt;/code&gt; to store all its local variables, and parameters passed into it. The stack frame will be the new memory region for the two paramters &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, and assigns them to the values that was passed to them, which are &lt;code&gt;10&lt;/code&gt; and &lt;code&gt;20&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Because it's a new memory region, whatever changes that are done in the function &lt;code&gt;swapValues()&lt;/code&gt; will only affect the newly allocated memory regions of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; in the stack frame of &lt;code&gt;swapValues()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That is to say, the values of &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; in the &lt;code&gt;Main&lt;/code&gt; function stack frame will be left untouched!&lt;/p&gt;
&lt;p&gt;This kind of defeats the purpose of the function...&lt;/p&gt;
&lt;p&gt;So how do we fix it?&lt;/p&gt;
&lt;h3&gt;Pass by Reference&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Let's tweak the code above slightly to make it pass by reference&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
public static void Main()&lt;br&gt;
{&lt;br&gt;
int x = 10;&lt;br&gt;
int y = 20;&lt;/p&gt;
&lt;p&gt;swapValues(10, 20);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;void swapValues(ref int x, ref int y)&lt;br&gt;
{&lt;br&gt;
int temp;&lt;/p&gt;
&lt;p&gt;temp = x;&lt;br&gt;
x = y;&lt;br&gt;
y = temp;&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The only difference is adding the keyword &lt;code&gt;ref&lt;/code&gt; in front of the function parameters, which tell the function to reference to the objects passed in. This means that whatever work that is done in &lt;code&gt;swapValues()&lt;/code&gt; will work directly on the values in &lt;code&gt;Main()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The difference between passing by value and passing by reference is shown below&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Passing by value: Allocates memory space on the stack frame and assigns it the value of the object that were passed into the function
    &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Passing by reference: Does not allocate memory space on the stack frame, uses the object that was passed in directly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case, whatever changes done to &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; in the function &lt;code&gt;swapValues()&lt;/code&gt; will directly modify the values inside the stack frame of &lt;code&gt;Main()&lt;/code&gt;!&lt;/p&gt;
&lt;h3&gt;Reference Objects&lt;/h3&gt;
&lt;hr&gt;
&lt;h3&gt;Modifying the reference object part 1&lt;/h3&gt;
&lt;p&gt;Now heres the tricky part. Some objects are reference objects, which is to say they are pointers to begin with. An example would be a string in C, or an array object.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
public static void Main()&lt;br&gt;
{&lt;br&gt;
int[] myArrayMain = new int[] {1, 2, 3, 4, 5};&lt;/p&gt;
&lt;p&gt;editArray(myArrayMain);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;void editArray(int[] myArrayParam)&lt;br&gt;
{&lt;br&gt;
myArrayParam[0] = 7;&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The above code will changes &lt;code&gt;myArrayMain&lt;/code&gt; to &lt;code&gt;{0, 2, 3, 4, 5}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When we call the function &lt;code&gt;editArray()&lt;/code&gt;, we create a new stack frame for &lt;code&gt;editArray()&lt;/code&gt; to hold its local variables and paramters. Because &lt;code&gt;myArrayParam&lt;/code&gt; is a reference object, we create a pointer on the stack frame to hold any value that is passed into &lt;code&gt;myArrayParam&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We are passing in &lt;code&gt;myArrayMain&lt;/code&gt;, which is a reference object. That means, the value of &lt;code&gt;myArrayMain&lt;/code&gt; is an address, which points to the first element in the array.&lt;/p&gt;
&lt;p&gt;When we pass &lt;code&gt;myArrayMain&lt;/code&gt; to &lt;code&gt;myArrayParam&lt;/code&gt;, we are assigning &lt;code&gt;myArrayParam&lt;/code&gt; to the value of the &lt;code&gt;myArrayMain&lt;/code&gt;, which is an address that points to the first element of &lt;code&gt;myArrayMain&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;Memory pointer layout:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;myArrayParam&lt;/code&gt; --&amp;gt; &lt;code&gt;myArrayMain&lt;/code&gt; --&amp;gt; &lt;code&gt;memory of first element in myArrayMain (1)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So any changes made to &lt;code&gt;myArrayParam&lt;/code&gt; in &lt;code&gt;editArray()&lt;/code&gt; will be propagated to the &lt;code&gt;myArrayMain&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Modifying the reference object part 2&lt;/h3&gt;
&lt;p&gt;Now what happens when we change &lt;code&gt;editArray()&lt;/code&gt; to create a new array? Will &lt;code&gt;myArrayMain&lt;/code&gt; be overwritten?&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
public static void Main()&lt;br&gt;
{&lt;br&gt;
int[] myArrayMain = new int[] {1, 2, 3, 4, 5};&lt;/p&gt;
&lt;p&gt;editArray(myArrayMain);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;void editArray(int[] myArrayParam)&lt;br&gt;
{&lt;br&gt;
myArrayParam[0] = new int[] {6, 7, 8, 9, 10};&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Nope. &lt;code&gt;myArrayMain&lt;/code&gt; will still remain as &lt;code&gt;{1, 2, 3, 4, 5}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When we call &lt;code&gt;myArrayParam[0] = new int[] {6, 7, 8, 9, 10};&lt;/code&gt;, we are repointing &lt;code&gt;myArrayParam&lt;/code&gt; to something else. This breaks the memory pointer layout above&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
myArrayParam --&amp;gt; myArrayMain --&amp;gt; memory of first element in myArrayMain (1)&lt;/p&gt;
&lt;p&gt;becomes&lt;/p&gt;
&lt;p&gt;myArrayParam --&amp;gt; memory of first element in myArrayParam (6)&lt;/p&gt;
&lt;p&gt;myArrayMain --&amp;gt; memory of first element in myArrayMain (1)&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h3&gt;Modifying the reference object part 3&lt;/h3&gt;
&lt;p&gt;Lets look at the final attempt. This time, we call &lt;code&gt;ref&lt;/code&gt; on the array that is passed in&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
public static void Main()&lt;br&gt;
{&lt;br&gt;
int[] myArrayMain = new int[] {1, 2, 3, 4, 5};&lt;/p&gt;
&lt;p&gt;editArray(myArrayMain);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;void editArray(ref int[] myArrayParam)&lt;br&gt;
{&lt;br&gt;
myArrayParam[0] = new int[] {6, 7, 8, 9, 10};&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Remember that when we call &lt;code&gt;ref&lt;/code&gt;, in the stack frame of &lt;code&gt;editArray()&lt;/code&gt;, no new memory is allocted, and the original &lt;code&gt;myArrayMain&lt;/code&gt; is used.&lt;/p&gt;
&lt;p&gt;The memory pointer layout is now&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
myArrayParam --&amp;gt; memory of first element in myArrayMain (1)&lt;/p&gt;
&lt;p&gt;myArrayMain --&amp;gt; memory of first element in myArrayMain (1)&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Both &lt;code&gt;myArrayParam&lt;/code&gt; and &lt;code&gt;myArrayMain&lt;/code&gt; now point to the first element in &lt;code&gt;myArrayMain&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So when the code block is ran, &lt;code&gt;myArrayMain&lt;/code&gt; will change to &lt;code&gt;{6, 7, 8, 9, 10}&lt;/code&gt;!&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Phew! That was a long and confusing read, so here's a TLDR:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C# passes by value&lt;/li&gt;
&lt;li&gt;When a function is called, a stack frame is allocated for local and parameter variables&lt;/li&gt;
&lt;li&gt;The parameter variables are assigned to the value that was passed in&lt;/li&gt;
&lt;li&gt;No memory in the stack frame is allocated for parameters that are prefixed with &lt;code&gt;ref&lt;/code&gt;, but are accessed directly from the caller function&lt;/li&gt;
&lt;li&gt;Arrays are reference objects&lt;/li&gt;
&lt;li&gt;The values they hold are the memory space of the first element in the array&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for reading!!&lt;/p&gt;
&lt;p&gt;Further reading: http://www.yoda.arachsys.com/csharp/parameters.html Excellent page!!!&lt;/p&gt;</content></entry><entry><title>How HTTPS Works</title><link href="/how-https-works.html" rel="alternate"></link><published>2018-11-18T22:36:00+00:00</published><updated>2018-11-18T22:36:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-11-18:/how-https-works.html</id><summary type="html">&lt;h2&gt;How does HTTPS work?&lt;/h2&gt;
&lt;p&gt;We all know to use a HTTPS site instead of a HTTP, because it is more secure. We roughly know that the messages sent to and fro the client and server are encrypted, so any snooping person wouldn't know the contents, but how does it all …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;How does HTTPS work?&lt;/h2&gt;
&lt;p&gt;We all know to use a HTTPS site instead of a HTTP, because it is more secure. We roughly know that the messages sent to and fro the client and server are encrypted, so any snooping person wouldn't know the contents, but how does it all work?&lt;/p&gt;
&lt;p&gt;This post is motivated by Google's announcement that it is going to label all HTTP sites as insecure. HTTP sites are those that do not implement any encryption, and all your passwords and traffic are in plain text. The question should be, why do HTTP sites even exist anymore...&lt;/p&gt;
&lt;h2&gt;The HTTP in HTTPS&lt;/h2&gt;
&lt;p&gt;HTTP traffic is how the client talks to the server. Its the language that is spoken when transferring information over the internet.&lt;/p&gt;
&lt;p&gt;Below is an example of a HTTP traffic of a &lt;code&gt;GET&lt;/code&gt; request sent to the server. It is sent when a user keys in his credentials, and clicks onto the login button.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
GET /bin/login?user=dumb+user&amp;amp;pw=12345&amp;amp;action=login HTTP/1.1&lt;br&gt;
Accept: image/gif, image/jpeg, */*&lt;br&gt;
Referer: http://127.0.0.1:8000/login.html&lt;br&gt;
Accept-Language: en-us&lt;br&gt;
Accept-Encoding: gzip, deflate&lt;br&gt;
User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&lt;br&gt;
Host: 127.0.0.1:8000&lt;br&gt;
Connection: Keep-Alive&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Because there is no encryption, all the contents are in plain text, including the username and password. By using a traffic inspection tool like WireShark, it takes little to no effort to analyze and pick out information like this.&lt;/p&gt;
&lt;h2&gt;The S in HTTPS&lt;/h2&gt;
&lt;p&gt;So we want to encrypt the traffic so that it is not in plain text, including all our passwords and contents we sent and recieve.&lt;/p&gt;
&lt;p&gt;HTTPS (HTTP Secure) is simply HTTP wrapped up in SSL/TLS.&lt;/p&gt;
&lt;p&gt;SSL is the predecessor of TLS, and both SSL 2.0 and 3.0 have been deprecated by the IETF (Internet Engineering Task Force, which is a community that develops and promotes protocols and standards pertaining to TCP/IP). As such, it is safer to disable SSL, and leave TLS and the default option for your browsers.&lt;/p&gt;
&lt;p&gt;The being said, SSL/TLS does not does the actual encryption. It is only a handshake protocol that happens between the client and the server.&lt;/p&gt;
&lt;p&gt;During the handshake, the following steps are taken:&lt;/p&gt;
&lt;p&gt;1) Hello&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The client initiates the request by sending a &lt;code&gt;ClientHello&lt;/code&gt;, which contains the information needed by the server to connect to the client via SSL, such as the cipher suites the client supports, and the SSL versions it supports.
    &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;The server then responds with a &lt;code&gt;ServerHello&lt;/code&gt;, which contains similar information, and with the decision to use which cipher suite and SSL version to use&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2) Certificate Verification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The server now has to prove it's identity to the client, and it does so by an SSL certificate
    &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An SSL certificate is a file that contains information about the server. This includes domain name, server name or hostname, organization name, location, the server's public key and certificate validity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The client either verifies the certificate with a CA, or implicitly trusts the certificate (Clicking on the button "Trust Anyway")&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3) Key Exchange&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the client trusts the server, and the cipher suites have been chosen, the client generates a symmetric key to be used for encryption and decryption.
    &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The symmetric key is then encrypted using the server's public key, an sent over to the server. (Asymmetric encryption is used to encrypt the symmetric key to be used. Encrypt-ception!)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The following messages sent and recieved by the client and the server are thus encrypted/decrypted by this symmetric key&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;HTTP sends everything in plain text. We then use SSL/TLS to encrypt the plain text traffic, to prevent people from snooping in on our information.&lt;/p&gt;
&lt;p&gt;We briefly described the processes involved in setting up the SSL/TLS connection, which includes the initiation, certificate verification, and key exchange.&lt;/p&gt;
&lt;p&gt;Happy surfing!&lt;/p&gt;</content><category term="HTTPS"></category></entry><entry><title>Kernel Module Signing</title><link href="/kernel-module-signing.html" rel="alternate"></link><published>2018-11-11T22:35:00+00:00</published><updated>2018-11-11T22:35:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-11-11:/kernel-module-signing.html</id><summary type="html">&lt;h1&gt;Linux Kernel Signing&lt;/h1&gt;
&lt;h2&gt;Kernel Tainting&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;When dealing with offensive secuirty in the Linux space, we typically concern ourselves with kernel tainting. A kernel taint occurs when an unsigned module is loaded into the Linux kernel, which may potentially be used for malicious purposes.&lt;/p&gt;
&lt;p&gt;A kernel taint does not always mean …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Linux Kernel Signing&lt;/h1&gt;
&lt;h2&gt;Kernel Tainting&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;When dealing with offensive secuirty in the Linux space, we typically concern ourselves with kernel tainting. A kernel taint occurs when an unsigned module is loaded into the Linux kernel, which may potentially be used for malicious purposes.&lt;/p&gt;
&lt;p&gt;A kernel taint does not always mean that something bad has happened to your machine, it just means that the machine's state has been unoffically modified. (Think of it as a warrantly for a device such as an Xbox. If you unoffically modify the hardware, its considered tainted, and the warranty is voided).&lt;/p&gt;
&lt;p&gt;Some actions that may cause a kernel taint are:&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
- The use of a proprietary (or non-GPL-compatible) kernel module—this is the most common cause of tainted kernels and usually results from loading proprietary NVIDIA or AMD video drivers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The use of staging drivers, which are part of the kernel source code but are not fully tested&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The use of out-of-tree modules that are not included with the Linux kernel source code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Forcible loading or unloading of a kernel module (such as forcibly inserting a module not built for the current version of the kernel)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The use of an SMP (multiprocessor) kernel on certain unsupported uniprocessor CPUs, primarily older AMD Athlon processors&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overriding of the ACPI DSDT, sometimes needed to correct for power-management bugs (see here for details)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Certain critical error conditions, such as machine check exceptions and kernel oopses&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Certain serious bugs in the system firmware (BIOS, UEFI) which the kernel must work around&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;p&gt;&lt;a href="https://unix.stackexchange.com/questions/118116/what-is-a-tainted-kernel-in-linux"&gt;Source from Stackoverflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Each of these actions will produce a certain flag that will be useful for debugging purposes by the vendor or sys admin.&lt;/p&gt;
&lt;p&gt;When you insert a module that's unsigned, a message will be logged that says&lt;/p&gt;
&lt;p&gt;&lt;code&gt;%s module verification failed: signature and/or required key missing - tainting kernel&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This can be found in the kernel source code here: &lt;a href="https://elixir.bootlin.com/linux/latest/source/kernel/module.c#L3691"&gt;tainted message printing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to not taint the kernel, we must sign the module.&lt;/p&gt;
&lt;h2&gt;Kernel Module Signing&lt;/h2&gt;
&lt;hr&gt;
&lt;h4&gt;Recap on public-private keys&lt;/h4&gt;
&lt;p&gt;Before we talk about kernel module signing, lets briefly recap on public-private key encryption&lt;/p&gt;
&lt;p&gt;&lt;img alt="Public-Private key usage" src="https://i-technet.sec.s-msft.com/dynimg/IC19080.gif"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://technet.microsoft.com/en-us/library/aa998077(v=exchg.65).aspx"&gt;Source from Microsoft&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When I want to sign a module, I sign it using my private key. Anyone can use my public key to verify the signature. If another malicious software claims to be my module, the don't have my private key, and using my public key will thus result in a key mismatch.&lt;/p&gt;
&lt;p&gt;As opposed to encryption, where I use your public key to lock a message, and only you have your private key to unlock it.&lt;/p&gt;
&lt;p&gt;Signing ensures integrity, Encryption ensures confidentiality. (The last one in CIA being availability, but this is assuming the contents are always available)&lt;/p&gt;
&lt;h4&gt;Back to signing kernel modules&lt;/h4&gt;
&lt;p&gt;If you wanna read deeper, go to this post here: &lt;a href="http://cs.dartmouth.edu/~bx/blog/2015/10/02/a-history-of-linux-kernel-module-signing.html"&gt;A History of Linux Kernel Module Signing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'll be talking about the main ideas.&lt;/p&gt;
&lt;p&gt;A general implementation of module signing is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Developer builds module&lt;/li&gt;
&lt;li&gt;Developer hashes the module or parts of the module and signs the hash using their private key. The signature is embedded together with the module&lt;/li&gt;
&lt;li&gt;User retrieves the signed version of the module&lt;/li&gt;
&lt;li&gt;User hashes the same parts of the module that the developer hashed and checks that the hash they created matches the hash signed with the developer’s public key&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Over the years, different signing mechanism have came (and gone)&lt;/p&gt;
&lt;h4&gt;First version&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Signature&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;ELF&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;named&lt;/span&gt; &lt;span class="o"&gt;`&lt;/span&gt;&lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="n"&gt;module_sig&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt;&lt;span class="o"&gt;`&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;Only&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;sections&lt;/span&gt; &lt;span class="n"&gt;whose&lt;/span&gt; &lt;span class="k"&gt;names&lt;/span&gt; &lt;span class="n"&gt;contain&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="nb"&gt;text&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt; &lt;span class="k"&gt;or&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;are&lt;/span&gt; &lt;span class="n"&gt;hashed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;[code lang=text]&lt;br&gt;
1 for (i = 1; i &amp;lt; hdr-&amp;gt;e_shnum; i++) {&lt;br&gt;
2 name = secstrings+sechdrs[i].sh_name;&lt;br&gt;
3&lt;br&gt;
4 /* We only care about sections with "text" or&lt;br&gt;
5 "data" in their names */&lt;br&gt;
6 if ((strstr(name, "text") == NULL) &amp;amp;&amp;amp;&lt;br&gt;
7 (strstr(name, "data") == NULL))&lt;br&gt;
8 continue;&lt;br&gt;
9 /* avoid the ".rel.*" sections too. */&lt;br&gt;
10 if (strstr(name, ".rel.") != NULL)&lt;br&gt;
11 continue;&lt;br&gt;
12 /* add contents of section to signature */&lt;br&gt;
13 ...&lt;br&gt;
14 }&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h4&gt;Second version&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Performs&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="k"&gt;large&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;ELF&lt;/span&gt; &lt;span class="n"&gt;metadata&lt;/span&gt; &lt;span class="n"&gt;sanity&lt;/span&gt; &lt;span class="n"&gt;checks&lt;/span&gt; &lt;span class="k"&gt;before&lt;/span&gt; &lt;span class="n"&gt;validating&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;signature&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Signature&lt;/span&gt; &lt;span class="n"&gt;itself&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="err"&gt;“&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;module_sig&lt;/span&gt;&lt;span class="err"&gt;”&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;just&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;first&lt;/span&gt; &lt;span class="k"&gt;version&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;data&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="k"&gt;are&lt;/span&gt; &lt;span class="n"&gt;hashed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Corresponding&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="k"&gt;are&lt;/span&gt; &lt;span class="n"&gt;hashed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Relocation&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt; &lt;span class="n"&gt;along&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="k"&gt;any&lt;/span&gt; &lt;span class="n"&gt;symbols&lt;/span&gt; &lt;span class="n"&gt;they&lt;/span&gt; &lt;span class="n"&gt;reference&lt;/span&gt; &lt;span class="k"&gt;get&lt;/span&gt; &lt;span class="n"&gt;hashed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Third Version&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;Module&lt;/span&gt; &lt;span class="nv"&gt;signature&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;wrapped&lt;/span&gt; &lt;span class="nv"&gt;around&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;notes&lt;/span&gt; &lt;span class="nv"&gt;section&lt;/span&gt; `&lt;span class="nv"&gt;SHT_NOTE&lt;/span&gt;`, &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;named&lt;/span&gt; `.&lt;span class="nv"&gt;module&lt;/span&gt;.&lt;span class="nv"&gt;sig&lt;/span&gt;`
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;Everything&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;Second&lt;/span&gt; &lt;span class="nv"&gt;version&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;empty&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;allocatable&lt;/span&gt; &lt;span class="nv"&gt;sections&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;Second&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;first&lt;/span&gt; &lt;span class="nv"&gt;version&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;hash&lt;/span&gt; &lt;span class="nv"&gt;empty&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;allocatable&lt;/span&gt; &lt;span class="nv"&gt;sections&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Fourth version and beyond&lt;/h4&gt;
&lt;p&gt;Lets take a deeper look into this version, as its the version thats most widely used for most kernels today.&lt;/p&gt;
&lt;p&gt;The source code for kernel version 4.17 can be found here: &lt;a href="https://elixir.bootlin.com/linux/v4.17/source/kernel/module.c#L3659"&gt;4.17 Source code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The function in question is &lt;code&gt;load_module&lt;/code&gt;, which is called whenever you insmod a module.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;load_module&lt;/code&gt;, we see that we call &lt;code&gt;module_sig_check&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
/* Allocate and load the module: note that size of section 0 is always&lt;br&gt;
zero, and we rely on this for optional sections. */&lt;br&gt;
static int load_module(struct load_info *info, const char __user *uargs,&lt;br&gt;
int flags)&lt;br&gt;
{&lt;br&gt;
struct module *mod;&lt;br&gt;
long err;&lt;br&gt;
char *after_dashes;&lt;/p&gt;
&lt;p&gt;err = module_sig_check(info, flags);&lt;br&gt;
if (err)&lt;br&gt;
goto free_copy;&lt;/p&gt;
&lt;p&gt;...&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Looking at the &lt;code&gt;module_sig_check&lt;/code&gt; code, it calls &lt;code&gt;mod_verify_signature&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
static int module_sig_check(struct load_info *info, int flags)&lt;br&gt;
{&lt;br&gt;
int err = -ENOKEY;&lt;br&gt;
const unsigned long markerlen = sizeof(MODULE_SIG_STRING) - 1;&lt;br&gt;
const void *mod = info-&amp;gt;hdr;&lt;/p&gt;
&lt;p&gt;/*&lt;br&gt;
* Require flags == 0, as a module with version information&lt;br&gt;
* removed is no longer the module that was signed&lt;br&gt;
*/&lt;br&gt;
if (flags == 0 &amp;amp;&amp;amp;&lt;br&gt;
info-&amp;gt;len &amp;gt; markerlen &amp;amp;&amp;amp;&lt;br&gt;
memcmp(mod + info-&amp;gt;len - markerlen, MODULE_SIG_STRING, markerlen) == 0) {&lt;br&gt;
/* We truncate the module to discard the signature */&lt;br&gt;
info-&amp;gt;len -= markerlen;&lt;br&gt;
err = mod_verify_sig(mod, &amp;amp;info-&amp;gt;len);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;if (!err) {&lt;br&gt;
info-&amp;gt;sig_ok = true;&lt;br&gt;
return 0;&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;/* Not having a signature is only an error if we're strict. */&lt;br&gt;
if (err == -ENOKEY &amp;amp;&amp;amp; !sig_enforce)&lt;br&gt;
err = 0;&lt;/p&gt;
&lt;p&gt;return err;&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Take note that &lt;code&gt;mod_verify_sig&lt;/code&gt; has to return &lt;code&gt;0&lt;/code&gt; for it to call &lt;code&gt;info-&amp;amp;gt;sig_ok = true&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, we look a code snippet of &lt;code&gt;mod_verify_sig&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
struct module_signature {&lt;br&gt;
u8 algo; /* Public-key crypto algorithm [0] */&lt;br&gt;
u8 hash; /* Digest algorithm [0] */&lt;br&gt;
u8 id_type; /* Key identifier type [PKEY_ID_PKCS7] */&lt;br&gt;
u8 signer_len; /* Length of signer's name [0] */&lt;br&gt;
u8 key_id_len; /* Length of key identifier [0] */&lt;br&gt;
u8 __pad[3];&lt;br&gt;
__be32 sig_len; /* Length of signature data */&lt;br&gt;
};&lt;/p&gt;
&lt;p&gt;/*&lt;br&gt;
* Verify the signature on a module.&lt;br&gt;
*/&lt;br&gt;
int mod_verify_sig(const void *mod, unsigned long *_modlen)&lt;br&gt;
{&lt;br&gt;
struct module_signature ms;&lt;br&gt;
size_t modlen = *_modlen, sig_len;&lt;/p&gt;
&lt;p&gt;pr_devel("==&amp;gt;%s(,%zu)\n", __func__, modlen);&lt;/p&gt;
&lt;p&gt;if (modlen &amp;lt;= sizeof(ms))&lt;br&gt;
return -EBADMSG;&lt;/p&gt;
&lt;p&gt;memcpy(&amp;amp;ms, mod + (modlen - sizeof(ms)), sizeof(ms));&lt;br&gt;
modlen -= sizeof(ms);&lt;/p&gt;
&lt;p&gt;sig_len = be32_to_cpu(ms.sig_len);&lt;br&gt;
if (sig_len &amp;gt;= modlen)&lt;br&gt;
return -EBADMSG;&lt;br&gt;
modlen -= sig_len;&lt;br&gt;
*_modlen = modlen;&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;p&gt;We see that at the end of the module, we have two pieces of information:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Module signature struct, which stores information about the module signature&lt;/li&gt;
&lt;li&gt;The signature itself&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Cracking it&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;I have no idea how to crack it, but if anyone finds a flaw in this and prevents kernel taint, it means that they can insert whatever malicious modules they like without tainting the kernel.&lt;/p&gt;
&lt;p&gt;Without a kernel taint, forensics and incident responders would be duped.&lt;/p&gt;</content><category term="Kernel Module"></category></entry><entry><title>Python Tips and Tricks</title><link href="/python-tips-and-tricks.html" rel="alternate"></link><published>2018-11-04T22:32:00+00:00</published><updated>2018-11-04T22:32:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-11-04:/python-tips-and-tricks.html</id><summary type="html">&lt;h2&gt;Summary of Python tips, tricks, and to-dos&lt;/h2&gt;
&lt;p&gt;These pointers are what I picked up from the book &lt;code&gt;Python Tricks: The Book&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The book itself is a summary, and here i'll be doing a summary of a summary.&lt;/p&gt;
&lt;p&gt;Python is great because of its flexibility, but that itself could potentially be …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Summary of Python tips, tricks, and to-dos&lt;/h2&gt;
&lt;p&gt;These pointers are what I picked up from the book &lt;code&gt;Python Tricks: The Book&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The book itself is a summary, and here i'll be doing a summary of a summary.&lt;/p&gt;
&lt;p&gt;Python is great because of its flexibility, but that itself could potentially be a double edged sword. It can be so easy to abuse and write really messy code, yet the program still runs fine.&lt;/p&gt;
&lt;p&gt;Lets talk about the points made in the book. I only picked out points that I feel that are useful and that I have very little exposure to. Don't get me wrong, all the points in the book are great, just some greater than others.&lt;/p&gt;
&lt;h2&gt;Assertions&lt;/h2&gt;
&lt;p&gt;If the asserted condition returns true, nothing happens.&lt;br&gt;
If the asserted condition returns false, &lt;code&gt;AssertionError&lt;/code&gt; exception is raised.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
def price_after_discount(0ld_price, discount):&lt;br&gt;
new_price = 0ld_price * discount&lt;br&gt;
assert 0 &amp;lt;= new_price &amp;lt;= old_price&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This block of code applies a discount the an item. We assert that the new price is greater than zero, and not more than the old price.&lt;/p&gt;
&lt;p&gt;Assert is different from a regular exception in that it's meant for unrecoverable errors. Recoverable errors are things like &lt;code&gt;File not found&lt;/code&gt;, where you can fix it (by putting the file where it should be) and try to run the program again. Asserts are meant for internal sanity checking.&lt;/p&gt;
&lt;p&gt;Don't use Assert for data validation, because it can be optimized away.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
def delete_product(prod_id, user):&lt;br&gt;
assert user.is_admin()&lt;br&gt;
assert store.has_product(prod_id) 'Unknown product'&lt;br&gt;
store.get_product(prod_id).delete()&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;When you optimize away asserts, we remove checking if the user is admin, or if the store has the product.&lt;/p&gt;
&lt;h2&gt;Context Managers&lt;/h2&gt;
&lt;p&gt;When you do OO in python and you create classes to use, you can set context managers that dictate what happens when you enter and exit the code.&lt;/p&gt;
&lt;p&gt;This is done by defining &lt;code&gt;__enter__&lt;/code&gt; and &lt;code&gt;__exit__&lt;/code&gt; functions&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
class ManagedFile:&lt;br&gt;
def __init__(self, name):&lt;br&gt;
self.name = name&lt;/p&gt;
&lt;p&gt;def __enter__(self):&lt;br&gt;
self.file = open(self.name, 'w')&lt;br&gt;
return self.file&lt;/p&gt;
&lt;p&gt;def __exit__(self, exc_type, exc_val, exc_tb):&lt;br&gt;
if self.file:&lt;br&gt;
self.file.close()&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;p&gt;&lt;code&gt;__enter__&lt;/code&gt; is called when the execution enters the context of the statement, and &lt;code&gt;__exit__&lt;/code&gt; is called when it leaves the context.&lt;/p&gt;
&lt;h2&gt;Underscores and Dunders&lt;/h2&gt;
&lt;p&gt;On naming the variables in python, each name has a different meaning:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;SingleLeadingUnderscore: &lt;code&gt;_var&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Purely conventional, this tells the reader that the variable is only meant for use internal to the function.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SingleTrailingUnderscore: &lt;code&gt;var_&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Purely conventional, putting an underscore at the back prevents naming conflicts with Python's keywords&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DoubleLeadingUnderscore: &lt;code&gt;__var&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When double underscores are infront, Python name-mangles the variable, and puts the class name in front of it.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
   class Test: def __init__(self):&lt;br&gt;
   self.foo = 11&lt;br&gt;
   self._bar = 23&lt;br&gt;
   self.__baz = 42&lt;br&gt;
   [/code]&lt;/p&gt;
&lt;p&gt;When you look at the attributes of object &lt;code&gt;Test&lt;/code&gt;, we see that &lt;code&gt;__baz&lt;/code&gt; has become &lt;code&gt;_Test__baz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
   &amp;gt;&amp;gt;&amp;gt; t = Test()&lt;br&gt;
   &amp;gt;&amp;gt;&amp;gt; dir(t)&lt;br&gt;
   ['_Test__baz', '__class__', '__delattr__' ... ]&lt;br&gt;
   [/code]&lt;/p&gt;
&lt;p&gt;This is done to protect the variable from being overridden in subclasses that extends from the parent class&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DoubleLeadingandTrailingUnderscore: &lt;code&gt;__var__&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Leading and trailing underscores are left untouched by Python. They are reserved for special usage in Python, such as &lt;code&gt;__init__&lt;/code&gt; and &lt;code&gt;__call__&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SingleUnderscore: &lt;code&gt;_&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Meant to represent a variable that is temporary and insignificant&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
   for _ in range(5):&lt;br&gt;
   print("Hello World)&lt;br&gt;
   [/code]&lt;/p&gt;
&lt;p&gt;&lt;code&gt;_&lt;/code&gt; also represents the last value of the Python interpreter session&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;String Formatting&lt;/h2&gt;
&lt;p&gt;Old method: &lt;code&gt;"Hello, %s" % name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;New method: &lt;code&gt;"Hello, {}".format(name)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The new method is more powerful, because the order in &lt;code&gt;format&lt;/code&gt; doesn't matter&lt;/p&gt;
&lt;p&gt;&lt;code&gt;'Hey {name}, there is a 0x{errno:x} error!'.format(errno=errno, name=name)&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Python Functions&lt;/h2&gt;
&lt;p&gt;Python's functions are first class objects.&lt;/p&gt;
&lt;p&gt;What this means is that they can be assigned to variables, stored in data structures, and passed as arguements&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; funcs = [bark, str.lower, str.capitalize]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; funcs&lt;br&gt;
[&amp;lt;function yell at 0x10ff96510&amp;gt;, &amp;lt;method 'lower' of 'str' objects&amp;gt;, &amp;lt;method 'capitalize' of 'str' objects&amp;gt;]&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h2&gt;Lambdas&lt;/h2&gt;
&lt;p&gt;Lambdas declare small anonymous functions. It's a declarative way of programming&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; add = lambda x, y: x + y&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; add(5, 3)&lt;br&gt;
8&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The syntax: &lt;code&gt;lambda x, y&lt;/code&gt; are the inputs. &lt;code&gt;x + y&lt;/code&gt; is the action to carry out and return.&lt;/p&gt;
&lt;p&gt;A more complete example:&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; tuples = [(1, 'd'), (2, 'b'), (4, 'a'), (3, 'c')]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; sorted(tuples, key=lambda x: x[1])&lt;br&gt;
[(4, 'a'), (2, 'b'), (3, 'c'), (1, 'd')]&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The tuple is passed into the lambda function, and it returns the second element, which is assigned to key. The output is then sorted according to the second value.&lt;/p&gt;
&lt;h2&gt;Decorators&lt;/h2&gt;
&lt;p&gt;Decorators let you modify the behavior of the callee, without modifying the callee's code itself.&lt;/p&gt;
&lt;p&gt;Some common use case for decorators are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logging&lt;/li&gt;
&lt;li&gt;User authentication&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
def uppercase(func):&lt;br&gt;
def wrapper():&lt;br&gt;
original_result = func()&lt;br&gt;
modified_result = original_result.upper()&lt;br&gt;
return modified_result&lt;br&gt;
return wrapper&lt;/p&gt;
&lt;p&gt;@uppercase&lt;br&gt;
def greet():&lt;br&gt;
return 'Hello!'&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; greet()&lt;br&gt;
'HELLO!'&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;When we put the decorator on &lt;code&gt;greet()&lt;/code&gt;, we are passing the function to our decorator function.&lt;/p&gt;
&lt;p&gt;The output is then gotten from the decorator&lt;/p&gt;
&lt;p&gt;Decorators are done bottom to top&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
@strong&lt;br&gt;
@emphasis&lt;br&gt;
def greet():&lt;br&gt;
return 'Hello!&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;&lt;code&gt;emphasis&lt;/code&gt; is executed first, before &lt;code&gt;strong&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Decorators can also accept arguments by using &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt;. The arguments are gotten from the original function, and passed to the decorators.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
def proxy(func):&lt;br&gt;
def wrapper(*args, **kwargs):&lt;br&gt;
return func(*args, **kwargs)&lt;br&gt;
return wrapper&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h2&gt;*args and **kwargs&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; are optional arguments to a function.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
def foo(required, *args, **kwargs):&lt;br&gt;
print(required)&lt;br&gt;
if args:&lt;br&gt;
print(args)&lt;br&gt;
if kwargs:&lt;br&gt;
print(kwargs)&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; foo() TypeError:&lt;br&gt;
"foo() missing 1 required positional arg: 'required'"&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; foo('hello')&lt;br&gt;
hello&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; foo('hello', 1, 2, 3)&lt;br&gt;
hello (1, 2, 3)&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; foo('hello', 1, 2, 3, key1='value', key2=999)&lt;br&gt;
hello (1, 2, 3) {'key1': 'value', 'key2': 999}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;&lt;code&gt;*args&lt;/code&gt; collects extra positional arguments&lt;br&gt;
&lt;code&gt;**kwargs&lt;/code&gt; collects extra keywords as a dictionary&lt;/p&gt;
&lt;h2&gt;Writing your own exception class&lt;/h2&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
class NameTooShortError(ValueError):&lt;br&gt;
pass&lt;/p&gt;
&lt;p&gt;def validate(name):&lt;br&gt;
if len(name) &amp;lt; 10::&lt;br&gt;
raise NameTooShortError(name)&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h2&gt;References, Shallow Copying and Deep Copying&lt;/h2&gt;
&lt;h4&gt;References&lt;/h4&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
new_list = original_list&lt;br&gt;
new_dict = original_dict&lt;br&gt;
new_set = original_set&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This just creates references, and any modifications done to &lt;code&gt;original_&lt;/code&gt; will also modify &lt;code&gt;new_&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs.append("Hello")&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
[/code]&lt;/p&gt;
&lt;h4&gt;Shallow Copying&lt;/h4&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
new_list = list(original_list)&lt;br&gt;
new_dict = dict(original_dict)&lt;br&gt;
new_set = set(original_set)&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This makes a new list, but the children objects in the list are not copied.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs.append("Hello")&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs[1][0] = "X"&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], ['X', 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], ['X', 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;h4&gt;Deep Copying&lt;/h4&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
new_list = copy.deepcopy(original_list)&lt;br&gt;
new_dict = copy.deepcopy(original_dict)&lt;br&gt;
new_set = copy.deepcopy(original_set)&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This creates an entirely new instance, and copies all the children too.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs.append("Hello")&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs[1][0] = "X"&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; xs&lt;br&gt;
[[1, 2, 3], ['X', 5, 6], [7, 8, 9], "Hello"]&lt;br&gt;
&amp;gt;&amp;gt;&amp;gt; ys&lt;br&gt;
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]&lt;/p&gt;
&lt;p&gt;[/code]&lt;/p&gt;
&lt;h2&gt;Generators&lt;/h2&gt;
&lt;p&gt;Generators generate values JIT (Just In Time). This is opposed to making a list, and iterating through it.&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
genexpr = ('Hello' for i in range(3))&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; next(genexpr)&lt;br&gt;
'Hello'&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; next(genexpr)&lt;br&gt;
'Hello'&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; next(genexpr)&lt;br&gt;
'Hello'&lt;/p&gt;
&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; next(genexpr)&lt;br&gt;
StopIteration&lt;br&gt;
[/code]&lt;/p&gt;</content></entry><entry><title>No title [98]</title><link href="/98.html" rel="alternate"></link><published>2018-10-31T22:12:00+00:00</published><updated>2018-10-31T22:12:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-31:/98.html</id><content type="html"></content></entry><entry><title>Kaggle Data Science</title><link href="/datascience.html" rel="alternate"></link><published>2018-10-31T22:11:00+00:00</published><updated>2018-10-31T22:11:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-31:/datascience.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I'm branching out my learning into Data Science, mostly from Kaggle.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You'll find my Kaggle kernels here.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Predicting Taxi Fare&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"&gt;https://www.kaggle.com/c/new-york-city-taxi-fare-prediction&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/jinhaochan/TaxiFare/blob/master/Taxi%20Fares.ipynb"&gt;https://github.com/jinhaochan/TaxiFare/blob/master/Taxi%20Fares.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;RMSE: 3.88522&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Model: XGBoost&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this problem, I was supposed to predict …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I'm branching out my learning into Data Science, mostly from Kaggle.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;You'll find my Kaggle kernels here.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Predicting Taxi Fare&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"&gt;https://www.kaggle.com/c/new-york-city-taxi-fare-prediction&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/jinhaochan/TaxiFare/blob/master/Taxi%20Fares.ipynb"&gt;https://github.com/jinhaochan/TaxiFare/blob/master/Taxi%20Fares.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;RMSE: 3.88522&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Model: XGBoost&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this problem, I was supposed to predict taxi fares in NYC. It can be modeled as a regression problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;There was a lot of data cleaning to do, with many odd numbered features such as passenger size, and coordinates on the water.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Without the airport features, my model has an RMSE of 4.14398. After adding in those features, it drastically dropped to 3.88522. Those are some really strong features!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Movie Sentiment Analysis&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only"&gt;https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only&lt;/a&gt;&lt;a href="https://www.kaggle.com/earthshaker/lstm-cnn-glove-bidirectional-gru-aggregation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/Charmanderander/SentimentAnalysis/blob/master/sentanalysis.ipynb"&gt;https://github.com/jinhaochan/SentimentAnalysis/blob/master/sentanalysis.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Accuracy: 0.65095&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Model: Ensemble by Voting&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this problem, we were given a collection of phrases, which were broken down from sentences. Instead of predicting the sentiment for each sentence, we had to predict the sentiment for each phrase.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The pre-processing steps I did were&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;Lower casing&lt;/li&gt;
&lt;li&gt;Removing non alphabets&lt;/li&gt;
&lt;li&gt;Lemmatization&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The final output for each phrase was then chosen by voting from all the models.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list {"ordered":true} --&gt;

&lt;ol&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;CNN&lt;/li&gt;
&lt;li&gt;Glove Transfer-Learning with Bidirectional GRU&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Interestingly enough, Glove + CNN performs poorer than just CNN. This may be because the word vectors trained in Glove were in a different context (i.e. not Movie Sentiment Analysis)&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading --&gt;

&lt;h2&gt;Predicting Future Sales&lt;/h2&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.kaggle.com/c/competitive-data-science-predict-future-sales"&gt;https://www.kaggle.com/c/competitive-data-science-predict-future-sales&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/Charmanderander/salesforcast/blob/master/saleforecast.ipynb"&gt;https://github.com/jinhaochan/salesforcast/blob/master/saleforecast.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;RMSE: 1.16462&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;&lt;strong&gt;Model: LSTM + GRU&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this competition, we had to predict what the next month's sale was for each item for each shop.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The data given to us was daily sales for each item, so we had to do some data aggregation to convert it to a monthly sales value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;We were given 33 months of training data, so I modeled it to a time series problem.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For training, months 0 - 32 was the training data, and month 33 was the target value.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;For testing, months 1 - 33 was the testing data, and we need to predict the values for month 34.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;The model I used was a 2 layer GRU using a dropout layer of 0.3  &lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>Non-Kaggle</title><link href="/non-kaggle.html" rel="alternate"></link><published>2018-10-31T21:43:00+00:00</published><updated>2018-10-31T21:43:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-31:/non-kaggle.html</id><summary type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Here, you'll find Data science projects that work on data sets not from Kaggle.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Detecting Botnet traffic&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Dataset: &lt;a href="https://mcfp.weebly.com/the-ctu-13-dataset-a-labeled-dataset-with-botnet-normal-and-background-traffic.html"&gt;https://mcfp.weebly.com/the-ctu-13-dataset-a-labeled-dataset-with-botnet-normal-and-background-traffic.html&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/Charmanderander/BotnetDetection/blob/master/NetFlow-Botnet.ipynb"&gt;https://github.com/jinhaochan/BotnetDetection/blob/master/NetFlow-Botnet.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this data set, we were given traffic of both Botnet and normal traffic. I built …&lt;/p&gt;</summary><content type="html">&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Here, you'll find Data science projects that work on data sets not from Kaggle.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:heading {"level":3} --&gt;

&lt;h3&gt;Detecting Botnet traffic&lt;/h3&gt;
&lt;!-- /wp:heading --&gt;

&lt;!-- wp:separator --&gt;

&lt;hr&gt;
&lt;!-- /wp:separator --&gt;

&lt;p&gt;&lt;/p&gt;
&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Dataset: &lt;a href="https://mcfp.weebly.com/the-ctu-13-dataset-a-labeled-dataset-with-botnet-normal-and-background-traffic.html"&gt;https://mcfp.weebly.com/the-ctu-13-dataset-a-labeled-dataset-with-botnet-normal-and-background-traffic.html&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Notebook: &lt;a href="https://github.com/Charmanderander/BotnetDetection/blob/master/NetFlow-Botnet.ipynb"&gt;https://github.com/jinhaochan/BotnetDetection/blob/master/NetFlow-Botnet.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this data set, we were given traffic of both Botnet and normal traffic. I built a classifier to determine if a given traffic is anomalous or not.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;I used the NetFlow data, and their features to build my model. I removed all source and destination information, as I wanted my classifier to learn solely on network behavioral data. And also, in reality, all the source and destination information will be different, so there is no use for my model to learn them.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;In this problem, the data set was hugely unbalanced. I had significantly smaller set of Botnet traffic. To deal with this, I upsampled the amount of Botnet traffic.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;

&lt;p&gt;Also, I had to find a balance between precision and recall. In detecting Botnet traffic, having a low precision and high recall is more desirable, as the cost of precision is cheap. It is more important for me to catch every single traffic that is a Botnet.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;</content></entry><entry><title>No title [70]</title><link href="/70.html" rel="alternate"></link><published>2018-10-30T22:55:00+00:00</published><updated>2018-10-30T22:55:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-30:/70.html</id><content type="html"></content></entry><entry><title>Side Projects</title><link href="/fullstack-website.html" rel="alternate"></link><published>2018-10-30T22:38:00+00:00</published><updated>2018-10-30T22:38:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-30:/fullstack-website.html</id><summary type="html">&lt;p&gt;When I'm not busy at work churning out ideas and code, I'll be dabbling around with other technologies.&lt;/p&gt;
&lt;p&gt;My goals whenever I try out a new technology, is to not only learn how it works, but to be proficient enough to create a simple product.&lt;/p&gt;
&lt;p&gt;Here are some of the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I'm not busy at work churning out ideas and code, I'll be dabbling around with other technologies.&lt;/p&gt;
&lt;p&gt;My goals whenever I try out a new technology, is to not only learn how it works, but to be proficient enough to create a simple product.&lt;/p&gt;
&lt;p&gt;Here are some of the things I've made!&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Full Stack Web Application&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;This web app was made for fun as a joke between friends.&lt;/p&gt;
&lt;p&gt;The stack I used was Django, Bootstrap, and Postgres. It is hosted on Heroku.&lt;/p&gt;
&lt;p&gt;It allows users to login via Facebook, and write posts to suggest challenges to my friends&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stormy-caverns-87920.herokuapp.com/"&gt;https://stormy-caverns-87920.herokuapp.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Android Mobile Game]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I decided to dabble around with writing a mobile application, and came up with a simple game, where players had to tap either Left or Right, depending on the instruction shown on the screen.&lt;/p&gt;
&lt;p&gt;I successfully published it on the App Store, and it currently has a 4 Star Review (By 2 people. It's mean to be a joke). However, it is currently unavailable on the App store, as there was some settings that need to be changed, and I decided it wasn't worth the effort.&lt;/p&gt;
&lt;p&gt;If anyone wants me to republish it, let me know!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Charmanderander/Tapper"&gt;https://github.com/Charmanderander/Tapper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Telegram Bot for Guitar Chords]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Do you play the guitar? Ever wanted chords to a song now, but feeling too lazy to browse your mobile phone to search for chords, and even if you find a link, it's poorly optimized for the mobile screen, resulting in you not being able to see the entire chords in one line?&lt;/p&gt;
&lt;p&gt;If so, use this bot!&lt;/p&gt;
&lt;p&gt;When you send it a name, it searches and crawls &lt;a href="https://www.ultimate-guitar.com/"&gt;https://www.ultimate-guitar.com/&lt;/a&gt; for the song, and returns you the chords in a readable format!&lt;/p&gt;
&lt;p&gt;The bot is currently not running, because I can't find a more permanent place to host it other than my Raspberry Pi.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Charmanderander/telegramBot"&gt;https://github.com/Charmanderander/telegramBot&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Automated LumberJack Game on Telegram]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Playing around with C#, I built a Windows executable program to automatically play the LumberJack game on Telegram.&lt;/p&gt;
&lt;p&gt;It uses a basic form of image recognition to find the play zone, and send commands based on the current position of the Lumber Jack&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Charmanderander/LumberHack"&gt;https://github.com/Charmanderander/LumberHack&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;... More to come!&lt;/p&gt;</content></entry><entry><title>No title [61]</title><link href="/61.html" rel="alternate"></link><published>2018-10-30T22:31:00+00:00</published><updated>2018-10-30T22:31:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-30:/61.html</id><content type="html"></content></entry><entry><title>Kernel Modules in Linux</title><link href="/kernel-modules-in-linux.html" rel="alternate"></link><published>2018-10-29T22:31:00+00:00</published><updated>2018-10-29T22:31:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-10-29:/kernel-modules-in-linux.html</id><summary type="html">&lt;p&gt;The Linux kernel is an open source operating system, as compared to propitiatory ones like Windows, or MacOS.&lt;/p&gt;
&lt;p&gt;The entire source code of the Linux kernel can be found here: &lt;a href="https://elixir.bootlin.com/linux/latest/source"&gt;Source Code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;TLDR of a Linux kernel is that it's made up of many different modules.&lt;/p&gt;
&lt;p&gt;The bare Linux kernel …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Linux kernel is an open source operating system, as compared to propitiatory ones like Windows, or MacOS.&lt;/p&gt;
&lt;p&gt;The entire source code of the Linux kernel can be found here: &lt;a href="https://elixir.bootlin.com/linux/latest/source"&gt;Source Code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;TLDR of a Linux kernel is that it's made up of many different modules.&lt;/p&gt;
&lt;p&gt;The bare Linux kernel without any modules is amazingly small (Arch Linux, which is notorious for coming with minimal packages installed, has a base size of only 800MB. Compare that to your Windows OS, which requires 20GB)&lt;/p&gt;
&lt;p&gt;Linux kernel modules are (relatively) small pieces of code that can be inserted and unloaded from the kernel.&lt;/p&gt;
&lt;p&gt;This makes the kernel very configurable and open for customization, because anyone can write a kernel module and insert it into the kernel, giving it new custom functions and commands.&lt;/p&gt;
&lt;p&gt;Kernel modules can be loaded by calling &lt;code&gt;insmod&lt;/code&gt; and removed by calling &lt;code&gt;rmmod&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Note the distinction between kernel modules and kernel drivers. A kernel driver is a subset of a kernel module, and the driver is a piece of code that talks to some hardware (Sound speaker driver, USB driver etc). A kernel module is a generic description of any code that can be inserted into the kernel.&lt;/p&gt;
&lt;p&gt;In this post, I'm going to give a crash course for writing and compiling a kernel module.&lt;/p&gt;
&lt;p&gt;There are two components for writing a kernel module:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The C file, which consists of the source code of the kernel module&lt;/li&gt;
&lt;li&gt;The Makefile, which specifies a number of parameters when building your module, including; which compiler to use, where to get the libraries from and what kind of object to produce&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Lets talk about the C file first&lt;/p&gt;
&lt;h2&gt;C file&lt;/h2&gt;
&lt;p&gt;Below is a sample code of a C file that compiles to a kernel module&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Required&lt;br&gt;
#include &amp;lt;linux/init.h&amp;gt;&lt;br&gt;
#include &amp;lt;linux/module.h&amp;gt;&lt;br&gt;
#include &amp;lt;linux/kernel.h&amp;gt;&lt;/p&gt;
&lt;p&gt;// Optional&lt;br&gt;
MODULE_LICENSE("GPL");&lt;/p&gt;
&lt;p&gt;// Optional&lt;br&gt;
int myint = 3;&lt;br&gt;
module_param(myint, int, 0);&lt;br&gt;
MODULE_PARM_DESC(myint, "Value of my integer");&lt;/p&gt;
&lt;p&gt;// Required&lt;br&gt;
static int __init mymodule_init(void){&lt;br&gt;
printk(KERN_INFO "Init module. Number is %d!\n", int);&lt;br&gt;
return 0;&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;// Required&lt;br&gt;
static void __exit mymodule_exit(void){&lt;br&gt;
printk(KERN_INFO "Exit module. Number is %d\n", int);&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;// Required&lt;br&gt;
module_init(mymodule_init);&lt;br&gt;
module_exit(mymodule_exit);&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;I've put some tags in the code to denote if those are optional or not. Lets go through each of them:&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Required&lt;br&gt;
#include &amp;lt;linux/init.h&amp;gt;&lt;br&gt;
#include &amp;lt;linux/module.h&amp;gt;&lt;br&gt;
#include &amp;lt;linux/kernel.h&amp;gt;&lt;/p&gt;
&lt;p&gt;//Optional&lt;br&gt;
#include &amp;lt;linux/moduleparam.h&amp;gt;&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;These are required for building any kernel module files. For a program as simple as this, these 3 headers are the bare minimum.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#include&lt;/code&gt; is only included if your module accepts parameters&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Optional&lt;br&gt;
MODULE_LICENSE("GPL");&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;If you want to do things the "right" and proper way, this should be required, but you can compile the kernel module without it.&lt;/p&gt;
&lt;p&gt;However, there are some kernel functions that require this licensed to be defined, before you can call them. (&lt;code&gt;kallsyms&lt;/code&gt; is one of them)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Optional&lt;br&gt;
int myint = 3;&lt;br&gt;
module_param(myint, int, 0);&lt;br&gt;
MODULE_PARM_DESC(myint, "Value of my integer");&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This code block here is for receiving inputs from the user during &lt;code&gt;insmod&lt;/code&gt;. If no inputs are specified, the default value becomes 3.&lt;/p&gt;
&lt;p&gt;An example would be &lt;code&gt;insmod  myint=5&lt;/code&gt;, which will then set the value of &lt;code&gt;myint&lt;/code&gt; to 5&lt;/p&gt;
&lt;p&gt;The last value of &lt;code&gt;module_param(myint, int, 0);&lt;/code&gt; describes the permissions of the file created under &lt;code&gt;/sys/module/p2/parameters/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MODULE_PARM_DESC(myint, "Value of my integer");&lt;/code&gt; just describes the parameter&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Required&lt;br&gt;
static int __init mymodule_init(void){&lt;br&gt;
printk(KERN_INFO "Init module. Number is %d!\n", int);&lt;br&gt;
return 0;&lt;br&gt;
}&lt;/p&gt;
&lt;p&gt;// Required&lt;br&gt;
static void __exit mymodule_exit(void){&lt;br&gt;
printk(KERN_INFO "Exit module. Number is %d\n", int);&lt;br&gt;
}&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;These two code blocks are absolutely required in a kernel module.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;__init&lt;/code&gt; tells the module what to do on &lt;code&gt;insmod&lt;/code&gt;, and &lt;code&gt;__exit&lt;/code&gt; tells tells it what to do on &lt;code&gt;rmmod&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Notice that &lt;code&gt;__init&lt;/code&gt; returns an integer, while &lt;code&gt;__exit&lt;/code&gt; returns a void.&lt;/p&gt;
&lt;p&gt;The integer returned by &lt;code&gt;__init&lt;/code&gt; tells us if &lt;code&gt;insmod&lt;/code&gt; has been successful or not.&lt;/p&gt;
&lt;p&gt;From the code inside, when you run &lt;code&gt;insmod&lt;/code&gt;, you will print a message in &lt;code&gt;dmesg&lt;/code&gt; that says &lt;code&gt;"Init module. Number is %d&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And when you &lt;code&gt;rmmod&lt;/code&gt; the module, it will print &lt;code&gt;Exit module. Number is %d&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
// Required&lt;br&gt;
module_init(mymodule_init);&lt;br&gt;
module_exit(mymodule_exit);&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;Finally, these are required as well.&lt;br&gt;
It overrides &lt;code&gt;module_init&lt;/code&gt; and &lt;code&gt;module_exit&lt;/code&gt; functions with your &lt;code&gt;mymodule_init&lt;/code&gt; and &lt;code&gt;mymodule_exit&lt;/code&gt; modules&lt;/p&gt;
&lt;h2&gt;Makefile&lt;/h2&gt;
&lt;p&gt;Once you're done with the C program, we can move on to the Makefile.&lt;/p&gt;
&lt;p&gt;The make file for this toy program is extreme simple, but once you move on to larger, more complicated kernel modules, your Makefile will similary blow up in size&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
obj-m+=mymodule.o&lt;/p&gt;
&lt;p&gt;all:&lt;br&gt;
make -C /lib/modules/\$(shell uname -r)/build/ M=\$(PWD) modules&lt;br&gt;
clean:&lt;br&gt;
make -C /lib/modules/\$(shell uname -r)/build/ M=\$(PWD) clean&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The whole contents of a make file are very arcane, and you can read up the full list here: &lt;a href="http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/"&gt;A Simple Makefile Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'll just go through things which are essential&lt;/p&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
obj-m+=mymodule.o&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This tells the make file what object name to output. Take note that the name &lt;code&gt;mymodule.o&lt;/code&gt; should have exactly the same name as your C file.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
all:&lt;br&gt;
make -C /lib/modules/\$(shell uname -r)/build/ M=\$(PWD) modules&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;This specifies where to get your libraries from when making your project.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;-C&lt;/code&gt; flag tells it to change directory to the folder containing the libraries. In this case, it is your kernel source code, since it's a kernel module you're building&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;M&lt;/code&gt; variable (not flag) tells the make file where your original source code is, so it can grab the libraries specified in &lt;code&gt;-C&lt;/code&gt;, and build the files specified in &lt;code&gt;M=&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When you type the command &lt;code&gt;make&lt;/code&gt;, by default, you are calling &lt;code&gt;make all&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;[code lang=text]&lt;br&gt;
clean:&lt;br&gt;
make -C /lib/modules/\$(shell uname -r)/build/ M=\$(PWD) clean&lt;br&gt;
[/code]&lt;/p&gt;
&lt;p&gt;The clean command cleans up your working directory, by deleting all object files, and intermediate files.&lt;/p&gt;
&lt;p&gt;Essentially, this reverts everything back to only having your C source code file.&lt;/p&gt;
&lt;p&gt;To invoke the clean command, run &lt;code&gt;make clean&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;That's it&lt;/h1&gt;
&lt;p&gt;This is an extremely dumbed down, tldr version of how to write a kernel module.&lt;/p&gt;
&lt;p&gt;It's way more complex than this, but hopefully it'll serve as a stepping stone to start out!&lt;/p&gt;</content></entry><entry><title>Subtle Art Of Not Giving a F*CK</title><link href="/subtle-art-of-not-giving-a-fck.html" rel="alternate"></link><published>2018-09-01T16:24:00+00:00</published><updated>2018-09-01T16:24:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-09-01:/subtle-art-of-not-giving-a-fck.html</id><summary type="html">&lt;p&gt;So I've seen this book around for quite some time, but have been avoiding it because i'm quite saturated with self-help books. However, one day I decided to make an impulse purchase on this, and I've definitely not regretted it.&lt;/p&gt;
&lt;p&gt;Below are some of the summary points he made:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;So I've seen this book around for quite some time, but have been avoiding it because i'm quite saturated with self-help books. However, one day I decided to make an impulse purchase on this, and I've definitely not regretted it.&lt;/p&gt;
&lt;p&gt;Below are some of the summary points he made:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not giving a f*ck does &lt;strong&gt;NOT&lt;/strong&gt; mean indifference. It means that you have a goal you want to achieve, and you don't give a f*ck about what it takes to get it. (criticism, doubt, naysayers)&lt;/li&gt;
&lt;li&gt;It's important to give a f*ck about something. This can be translated to: It's important to find a problem you want to solve (This is as opposed to: It's important to find something that makes you happy!) By finding a problem you are interested in and you want to solve, you are then willing to go through the suffering that entails solving the problem, and the following satisfaction (or the elusive happiness!). Problems -&amp;gt; Solutions -&amp;gt; Satisfaction&lt;/li&gt;
&lt;li&gt;Embrace mediocrity. You are not the special 1% high achievers. You are the 99% that makes the rest of the world. Being normal and average is okay, that's why its called the average. If everyone was special, then special would be average, and the next tier would be exceptionally special (which, if every special person thought they would be, it would become average again). Don't stress about being &lt;strong&gt;THE &lt;/strong&gt;best. STRIVE to be &lt;strong&gt;YOUR&lt;/strong&gt; best. And even if your best is globally average, so what?&lt;/li&gt;
&lt;li&gt;Take responsibility for everything that's happening to you, emphasis being on feelings. Don't offload the responsibility of feeling happy to someone else. If someone is an asshole to you, you are responsible to how you feel about it. If you hate your job and your bosses, you are responsible to do something about it. Once you take ownership of things in your life, you will have more control and direction over where it's headed. Stop victimizing yourself.&lt;/li&gt;
&lt;li&gt;Questions your beliefs. You've had them for a long time, and it got you to where you are. The kicker is: [Did you get here &lt;strong&gt;BECAUSE&lt;/strong&gt; of it, or did you get here &lt;strong&gt;IN SPITE&lt;/strong&gt; of it?]{style="text-decoration:underline;"}&lt;strong&gt; &lt;/strong&gt;Tear down and evaluate your beliefs. An example: I used to belief that if people didn't make time for me, they didn't care about me. That's extremely selfish thinking, and obviously not true. They are just as busy as you are. Safe to say, that belief has been torn down. Don't be so sure about yourself.&lt;/li&gt;
&lt;li&gt;If you feel like you're not motivated to do stuff, then this simple graph will help you: Actions -&amp;gt; Inspiration -&amp;gt; Motivation -&amp;gt; Action. Simple, to get motivated, you have to start.&lt;/li&gt;
&lt;li&gt;Following the action from point 6: When you do anything, commit yourself entire to doing it. Don't half ass your way through life. Do it well. Read in depth. Understand everything about that problem and domain (to the best of your ability). Aim high up to master it, and even if you fail, you would have landed pretty far anyway. &lt;strong&gt;&lt;em&gt;"Aim For The Stars, If You Fail, You'll Land On The Moon."&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now i'll elaborate on a thought or an idea that came when reading this book, which is how to measure success.&lt;/p&gt;
&lt;p&gt;Success should be measured by a metric that is entirely under &lt;strong&gt;YOUR &lt;/strong&gt;control. It's something stems directly from your effort, not others.&lt;/p&gt;
&lt;p&gt;Here's an example of a measurement using a metric not within your control:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Success means people like me&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can't control how people feel, so success is very volatile and questionable. Does he really like you? Or does he pretend to, to get something from you.&lt;/p&gt;
&lt;p&gt;Now we phrase it such that the measurement is in your control:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Success means people trust me&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can control this by having integrity, by not lying and cheating people. People will distrust you when you lie to them over and over again. When you promise to deliver, but you fail repeatedly. Building trust is entirely in your control: you choose to break it or not.&lt;/p&gt;
&lt;p&gt;A more common example would be:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Success is when me and my friends communicate and hang out often&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That seems fine, but you can't control your friends schedules or availability. If they get very busy with life and work, and fail to hang out with you, would YOU have failed?&lt;/p&gt;
&lt;p&gt;Here's how to phrase it better:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Success is when I'm there for my friends when they need me&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There we go, now control is entirely in your hands. If your friends need you and require your assistance, physically or emotionally, will YOU be there? Now you can truly measure success, because it's entirely contingent on your actions.&lt;/p&gt;
&lt;p&gt;In short, success in all areas of life should be measured by things YOU can do. And in the event of a failure, it is entirely YOUR fault (see taking responsibility). Once you acknowledge it's YOUR fault, you can do something to change it. If it's not your fault, chances are, you can't change it. And if that's the case, don't give a f*ck will you?&lt;/p&gt;</content></entry><entry><title>Bioinformatics</title><link href="/bioinformatics.html" rel="alternate"></link><published>2018-07-18T16:03:00+00:00</published><updated>2018-07-18T16:03:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-07-18:/bioinformatics.html</id><summary type="html">&lt;p&gt;I've been doing this Coursera Specialization called Bioinformatics &lt;a href="https://www.coursera.org/specializations/bioinformatics"&gt;(Link to course page)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The course shows us how to apply computational solutions to non-computational, but highly complex problems. The complexity of Bioinformatics comes from the huge amount of data (huge meaning billions), and how different permutations and combinations of those data …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been doing this Coursera Specialization called Bioinformatics &lt;a href="https://www.coursera.org/specializations/bioinformatics"&gt;(Link to course page)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The course shows us how to apply computational solutions to non-computational, but highly complex problems. The complexity of Bioinformatics comes from the huge amount of data (huge meaning billions), and how different permutations and combinations of those data points produce vastly difference outcomes.&lt;/p&gt;
&lt;p&gt;The data points in question are called &lt;strong&gt;Nucleotides,  &lt;/strong&gt;which form the basis of &lt;strong&gt;DNA&lt;/strong&gt;. (&lt;a href="https://www.youtube.com/watch?v=zwibgNGe4aY"&gt;Check out the videos here for a quick crash course in DNA and stuff&lt;/a&gt;). A lot of the problems are solved using Pattern-Finding algorithms, with a huge emphasis on Big-O and optimization over time. Given a huge collection of Nucleotides, we want to find patterns in them to tell us interesting stories. An example would be trying to find a pattern within the DNA that translates to producing the protein that regulates your sleep cycle.&lt;/p&gt;
&lt;p&gt;Some of the Computer Science concepts used in the course include Graph Theory (Euler Cycles, Paths, DeBruijn) and Matrix Manipulations (Laplace Rule of Succession). Aside from those, there are other complex solutions that are specific to Bioinformatics (Motif Finding, Profile Generation, Mass Spectrum Consistency).&lt;/p&gt;
&lt;p&gt;The choice of language I chose to was Python&lt;strong&gt;3&lt;/strong&gt; (emphasis on 3) mainly due to flexibility and familiarity. I believe my life would have been much easier if I adopted data science packages such as Numpy and Pandas for large data manipulations.&lt;/p&gt;
&lt;p&gt;The coding problems were fun, and extremely challenging, which was what I was looking for. I've been building Web applications, Java applications, Kernel modules and a little bit of Mobile Programming, all of which had very similar applications: Building an end-product for consumers. Bioinformatics on the other hand, showed me a whole new set of problems which required me to take a very different thought approach.&lt;/p&gt;
&lt;p&gt;It showed me that Python can not only be used for scripting to automate mundane tasks, or build a web framework like Django. Instead, it can also be used to find mutations in your DNA, or how to sequence antibiotics, which is all pretty darn cool.&lt;/p&gt;
&lt;p&gt;I've completed the first course: &lt;strong&gt;Finding Hidden Messages in DNA (Bioinformatics I)&lt;/strong&gt;, and i'm finishing up with the second course: &lt;strong&gt;Genome Sequencing (Bioinformatics II)&lt;/strong&gt;. There are 7 courses in total, but I don't think i'll be doing all of them. Those two courses alone were enough to satisfy my curiosity in finding out other uses of Python.&lt;/p&gt;
&lt;p&gt;My codes that I wrote are on my Github page here: &lt;a href="https://github.com/Charmanderander/bioinfo"&gt;Bioinformatics&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I must admit, its not very clean or optimized code, but only because I did it in one iteration. In actual practice, code is meant to be destroyed and rewritten, because the first iteration gives you the idea, and the subsequent ones optimizes over it.&lt;/p&gt;
&lt;p&gt;I get lazy sometimes :)&lt;/p&gt;</content><category term="Bioinformatics"></category><category term="Coursera"></category></entry><entry><title>How Netflix Thinks of DevOps</title><link href="/how-netflix-thinks-of-devops.html" rel="alternate"></link><published>2018-07-13T07:02:00+00:00</published><updated>2018-07-13T07:02:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-07-13:/how-netflix-thinks-of-devops.html</id><summary type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=UTKIT6STSVM"&gt;Link to the video of how Netflix thinks about DevOps(Hint: They don't)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://netflix.github.io/"&gt;Netflix Github Page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead, what they do focus on is a lot about culture, which is really be what every company should be focusing on. In this era, for better or for worse, we as humans have …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=UTKIT6STSVM"&gt;Link to the video of how Netflix thinks about DevOps(Hint: They don't)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://netflix.github.io/"&gt;Netflix Github Page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead, what they do focus on is a lot about culture, which is really be what every company should be focusing on. In this era, for better or for worse, we as humans have become more "Me"-centric. How we actualize the vision of ourselves, and how much the company supports that actualization is an important factor influencing the decision of choosing where to work.&lt;/p&gt;
&lt;p&gt;I digress. Below are the summary points of the video of what Netflix does. It's entirely non-DevOps related, and entirely cultural.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Don't build systems that say NO to developers and engineers.&lt;ul&gt;
&lt;li&gt;In some companies, there's the concept of a "Need-To-Know-Basis", both on data access, and system access. There is absolutely no reason to do so, after all, we all have the same vision the company has (If not, why are you even there?). By denying access to both data and systems, you're essentially telling your engineers: "This is not your problem. You have no business to be looking at this. Focus only on what you're hired to do".&lt;/li&gt;
&lt;li&gt;In addition to breaking engineering serendipity and spontaneity, you're inducing a lot of overhead for policy crafting, determining who has access to what, and enforcing those rules.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Freedom and Responsibility&lt;ul&gt;
&lt;li&gt;Hire smart people, and get out of their way. Let them do what they were hired to do, and trust that they would do it. The engineers should have the freedom to choose and architect solutions they see best. The company should not restrain the engineer in the worst way possible; restrain their engineering choices.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Trading [X] for Innovation&lt;ul&gt;
&lt;li&gt;Where [X] is your core business concern. For Netflix, it was uptime of their services, and trading off some concerns for uptime to invest in innovation was one of their strategies. Think about what [X] is in your company, and instead of obsessing over the optimization of [X], ensure that an equal (if not more) effort is spent in innovation.&lt;/li&gt;
&lt;li&gt;The by-product of innovation also optimizes [X], and should not be seen as an activity to do "only if you have free time". That should be the main job you're doing: Innovation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cut down on Processes and Procedures (P&amp;amp;P)&lt;ul&gt;
&lt;li&gt;These "safety guardrails" do nothing but induce more administrative overhead. The opposite of introducing P&amp;amp;Ps is to cultivate more trust. Trust that your employees are doing the correct and right thing, instead of making them document everything and request permission.&lt;/li&gt;
&lt;li&gt;Having trust implicitly means delegating authority to them, and that means no P&amp;amp;Ps to request unnecessary permission.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Context&lt;ul&gt;
&lt;li&gt;Make sure the people you are working with have a quality and constant flow of context of the business, and business decisions. Being too caught up in your technical mumbo-jumbo and into the rabbit hole can lead you to lose sight of the bigger picture. Context of the business, and exactly why you are doing what you're doing should be constantly reinforced.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Required Standard&lt;ul&gt;
&lt;li&gt;Not "No required coding standards.", but rather no required tech stack requirements. Don't enforce tools to use, don't enforce tech stack to use. Instead, enable your engineers to choose what they want.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Silos/Walls/Fences Should be torn down&lt;ul&gt;
&lt;li&gt;As if this isn't obvious enough. Know your internal dependencies and consumers. Know exactly what is it they do and want, and know exactly what is expected of you. Knowing what each team does reduces the need for guessing, and cuts the cost of wrong anticipation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Guesses/Instinct/Tradition&lt;ul&gt;
&lt;li&gt;Don't rely on instinct. Back it up with quantitative data. Don't fall victim to tradition. Always challenge for a better alternative.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Finally, Culture&lt;ul&gt;
&lt;li&gt;Know what culture you have. The 8 points above are an example of what culture is. To give an example of a counter-culture:&lt;ul&gt;
&lt;li&gt;I build tightly controlled systems, and only allow relevant engineers to access the system.&lt;/li&gt;
&lt;li&gt;I tell the engineers exactly what to do, and rob them from their freedom.&lt;/li&gt;
&lt;li&gt;I forsake innovation, and focus only on KPIs.&lt;/li&gt;
&lt;li&gt;I introduce numerous P&amp;amp;Ps, because I don't trust my engineers to do the right thing.&lt;/li&gt;
&lt;li&gt;I don't focus on the Why enough, and only how the How and What&lt;/li&gt;
&lt;li&gt;I restrict my engineers to use a predefined tech stack, because change is bad, and we only support such technology.&lt;/li&gt;
&lt;li&gt;I silo my teams, and everything internal to one team is a "Need-To-Know" basis to another team&lt;/li&gt;
&lt;li&gt;It has always been done this why, so don't ask why. If it ain't broke, don't fix it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Make your comapny culture well-known, and when you ask every engineer what the culture is, they should be able to tell it to you right away. If you have differing cultures, and groups of people optimizing for different things, you'll end up with a lot of problems. Internal cohesion falls apart, and different groups will work towards different goals. This will tear the company from inside out. Pass on brilliant people if they do not fit into your culture.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</content></entry><entry><title>Core Design Principles</title><link href="/core-design-principles.html" rel="alternate"></link><published>2018-07-12T09:08:00+00:00</published><updated>2018-07-12T09:08:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-07-12:/core-design-principles.html</id><summary type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=llGgO74uXMI"&gt;Core Design Principles for Software Developers by Venkat Subramaniam&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Devoxx is a conference directed towards the Java, Android and HTML5 community.&lt;/p&gt;
&lt;p&gt;Some points that are language agnostic, and can be applied universally are summarized below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Good code can be changed without much hassle.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It is always impossible to get it …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=llGgO74uXMI"&gt;Core Design Principles for Software Developers by Venkat Subramaniam&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Devoxx is a conference directed towards the Java, Android and HTML5 community.&lt;/p&gt;
&lt;p&gt;Some points that are language agnostic, and can be applied universally are summarized below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Good code can be changed without much hassle.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It is always impossible to get it right the first time.&lt;/li&gt;
&lt;li&gt;Be unemotional in coding.&lt;/li&gt;
&lt;li&gt;People who are dangerous to work with (So you shouldn't become them): People who can't follow instructions, and people who only follow instructions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Take time to review code. (You can learn, and you can improve the design)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Simplicity is hard. Strive to achieve that.&lt;/li&gt;
&lt;li&gt;Simple keeps you focused (Imperative vs Declarative)&lt;/li&gt;
&lt;li&gt;Write code to solve real problems. (Don't code without knowing what it should do)&lt;/li&gt;
&lt;li&gt;Complexity (Inherent vs Accidental). Inherent Complexity comes from the problem. Accidental Complexity comes from the solution.&lt;/li&gt;
&lt;li&gt;Simple != Familiar (just because you know what it does, doesn't mean its simple)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good Design is one that hides Inherent complexity, and eliminates Accidental Complexity&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;YAGNIy (You Aren't Going To Need It (yet)) Don't implement things that you don't need yet. Do the important things first.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Cost of implementing now &amp;gt; Cost of implementing later = Postpone&lt;/li&gt;
&lt;li&gt;Cost of implementing now = Cost of implementing later = Postpone&lt;/li&gt;
&lt;li&gt;Cost of implementing now &amp;lt; Cost of implementing later = Do it now&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Have a Good Automated Testing. This prevents fear of postponing&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Cohesion is a code that does one thing and one thing only. This makes it easier for change.&lt;/li&gt;
&lt;li&gt;Similar code stays together. Dissimilar code stays away&lt;/li&gt;
&lt;li&gt;Coupling is what you depend on. Try to see if you can remove coupling. (You can't remove all dependencies, so make them loose)&lt;/li&gt;
&lt;li&gt;Knock out before you Mock out&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good Design has High Cohesion and Low Coupling&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;DRY (Don't repeat yourself) (Don't duplicate code, and effort)&lt;/li&gt;
&lt;li&gt;Every piece of knowledge in a system should have a single unambiguous authoritative representation&lt;/li&gt;
&lt;li&gt;CPD (Copy Paste Detector to find duplicated code)&lt;/li&gt;
&lt;li&gt;Don't write overly long functions and methods&lt;/li&gt;
&lt;li&gt;How long is a long method? SLAP (Single Level of Abstraction Principle)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SLAP: What was the level of abstraction of your function&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don't comment what, comment why&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Open Closed Principle: A software module should be open for extension, but close for modification&lt;/li&gt;
&lt;li&gt;Use DRY and YAGNI often&lt;/li&gt;
&lt;/ol&gt;</content></entry><entry><title>Contact</title><link href="/contact.html" rel="alternate"></link><published>2018-07-10T09:52:00+00:00</published><updated>2018-07-10T09:52:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-07-10:/contact.html</id><content type="html">&lt;p&gt;[contact-form][contact-field label="Name" type="name" required="1"/][contact-field label="Email" type="email" required="1"/][contact-field label="Comment" type="textarea" required="1"/][/contact-form]&lt;/p&gt;</content></entry><entry><title>Printing Subsets in a List</title><link href="/the-journey-begins.html" rel="alternate"></link><published>2018-07-10T09:52:00+00:00</published><updated>2018-07-10T09:52:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-07-10:/the-journey-begins.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;u&gt; Problem Statement &lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given a list of distinct items (or a set), print out all of its subset lists.&lt;/p&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[1, 2, 3, 4]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;:empty set: 1 1,2 1,3 1,4 1,2,3 1,2,4 1,3,4 1,2,3,4 2 2,3 2 …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;&lt;u&gt; Problem Statement &lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given a list of distinct items (or a set), print out all of its subset lists.&lt;/p&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[1, 2, 3, 4]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;:empty set: 1 1,2 1,3 1,4 1,2,3 1,2,4 1,3,4 1,2,3,4 2 2,3 2,4 2,3,4 3 3,4 4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt; Proposed Solution &lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For each given list, I would need to figure out how many set of subsets there are. In this case, the total number of subsets for a given list is &lt;code&gt;2^n&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is the total number of items in the list.&lt;/p&gt;
&lt;p&gt;The reason it is &lt;code&gt;2^n&lt;/code&gt; is because: For each item in the list, you have 2 possible choices to take; Append an item to it, or don't. And since you have &lt;code&gt;n&lt;/code&gt; items, you have a total of &lt;code&gt;2^n&lt;/code&gt; choices.&lt;/p&gt;
&lt;p&gt;After figuring out how many total subsets there are, that can be the terminating condition in a recursive solution, something like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;answer&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;math&lt;/span&gt;.&lt;span class="nv"&gt;pow&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;,&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;myList&lt;/span&gt;&lt;span class="ss"&gt;)))&lt;/span&gt;:
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;answer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In each step of the code, we need to clone the list into two to model them as the two potential choices; adding an item, or not adding an item. We add an item to each element in one list (adding an item), and preserve the original list (not adding an item), and join the two results together&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Given List = [1, 2]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Step 1: Add 1&lt;/p&gt;
&lt;p&gt;Initial set = {} (models choice of adding)&lt;br&gt;
Cloned set = {} (models choice of not adding)&lt;/p&gt;
&lt;p&gt;Resulting set that adds: {1}&lt;br&gt;
Resulting set that does not add: {}&lt;/p&gt;
&lt;p&gt;Result = {},{1}&lt;/p&gt;
&lt;p&gt;Step 2: Add 2&lt;/p&gt;
&lt;p&gt;Initial set = {},{1} (models choice of adding)&lt;br&gt;
Cloned set = {},{1} (models choice of not adding)&lt;/p&gt;
&lt;p&gt;Resulting set that adds: {2}, {1,2}&lt;br&gt;
Resulting set that does not add: {}, {1}&lt;/p&gt;
&lt;p&gt;Result = {}, {1}, {2}, {1,2}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We can see that taking the union of sets that add, and sets that do not add will give us the total subsets. The above is the pseudocode for the main body of code for our solution. Given that we have an idea of what the terminating condition will be like, we can model this as a recursive solution.&lt;/p&gt;
&lt;p&gt;In each recursion, we should&lt;/p&gt;
&lt;p&gt;1. Check if total number of items in the set is = &lt;code&gt;2^(length of list)&lt;/code&gt;&lt;br&gt;
2. Clone the given set&lt;br&gt;
3. Add the item to one of the set&lt;br&gt;
4. Take the union of the original set and the modified set&lt;br&gt;
5. Go back to step 1&lt;/p&gt;
&lt;p&gt;Translated to python3,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;printPattern&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;givenList&lt;/span&gt;, &lt;span class="nb"&gt;result&lt;/span&gt;, &lt;span class="nv"&gt;totalSubsets&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;result&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nv"&gt;totalSubsets&lt;/span&gt;:
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;result&lt;/span&gt;

        # &lt;span class="nv"&gt;models&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;adding&lt;/span&gt;
        &lt;span class="nv"&gt;clonedResult&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;copy&lt;/span&gt;.&lt;span class="nv"&gt;deepcopy&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;result&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

        &lt;span class="nv"&gt;itemToAdd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;givenList&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]

        # &lt;span class="nv"&gt;omititng&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="nv"&gt;we&lt;/span&gt; &lt;span class="nv"&gt;just&lt;/span&gt; &lt;span class="nv"&gt;added&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="k"&gt;next&lt;/span&gt; &lt;span class="nv"&gt;recursion&lt;/span&gt;
        &lt;span class="nv"&gt;newList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;givenList&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;:]

        # &lt;span class="nv"&gt;adding&lt;/span&gt; &lt;span class="nv"&gt;an&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;each&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;list&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;result&lt;/span&gt;:
                &lt;span class="nv"&gt;item&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;itemToAdd&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

        # &lt;span class="nv"&gt;taking&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;union&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;both&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;results&lt;/span&gt;
        &lt;span class="nb"&gt;result&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nv"&gt;clonedResult&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;printPattern&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;newList&lt;/span&gt;, &lt;span class="nb"&gt;result&lt;/span&gt;, &lt;span class="nv"&gt;totalSubsets&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Read here to understand why I used deepcopy: &lt;a href="https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list"&gt;How to clone or copy a list?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That's it!&lt;/p&gt;</content><category term="codexercise"></category></entry><entry><title>The Anomaly</title><link href="/the-anomaly.html" rel="alternate"></link><published>2018-02-25T16:27:00+00:00</published><updated>2018-02-25T16:27:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-02-25:/the-anomaly.html</id><summary type="html">&lt;p&gt;Death is not an anomaly to life.&lt;/p&gt;
&lt;p&gt;Life is an anomaly to death.&lt;/p&gt;
&lt;p&gt;Life is the antithesis to the hundreds and millions of years of nonexistence.&lt;/p&gt;
&lt;p&gt;A sudden spurt of existence, and all the emotions that come along with it.&lt;/p&gt;
&lt;p&gt;Happiness and sadness. Lust and love. Compassion and scorn. Empathy …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Death is not an anomaly to life.&lt;/p&gt;
&lt;p&gt;Life is an anomaly to death.&lt;/p&gt;
&lt;p&gt;Life is the antithesis to the hundreds and millions of years of nonexistence.&lt;/p&gt;
&lt;p&gt;A sudden spurt of existence, and all the emotions that come along with it.&lt;/p&gt;
&lt;p&gt;Happiness and sadness. Lust and love. Compassion and scorn. Empathy and envy. Pleasure and pain.&lt;/p&gt;
&lt;p&gt;A few years of existence, a fiesty pause to the infinite years of oblivion.&lt;/p&gt;
&lt;p&gt;Fear not Death, for it is the natural state we all came from.&lt;/p&gt;
&lt;p&gt;Waste not Life, for it presents a short chance of awareness.&lt;/p&gt;
&lt;p&gt;The absence of the fear of death, and the presence of the gusto for life allows you to live it fully, to each his own definition of fullness.&lt;/p&gt;
&lt;p&gt;The anomaly is the awareness you gain in life. The anomaly is the free will you inherited. The anomaly is the choice you are allowed.&lt;/p&gt;
&lt;p&gt;Use them well and appreciate them. Teach others to appreciate them as well. Having to a wrong view on what little life we have is an abhorrent waste.&lt;/p&gt;
&lt;p&gt;We all return to the natural state in the end that is nonexistence. The absence of awareness, free will and choice. That is the natural state. Seize what you have now and live life greatly.&lt;/p&gt;
&lt;p&gt;P.s this post was inspired after I went for an operation, and was put under general anesthesia. To me, the lost of conscious thought was akin to dying, and it was the closest I felt to Death.&lt;/p&gt;
&lt;p&gt;I was initially afraid, and asked the doctor how it would feel like. He told me it would be just like going to sleep and waking up. I guess in the context of Death, it's going to sleep and not waking up.&lt;/p&gt;
&lt;p&gt;Within this period of anesthesia induced sleep, I felt absolutely nothing and had no recollection of what happened. I then thought, perhaps the fear of Death lies in the fear of what one would experience after life, and because no one has lived to tell the tale (pun intended), it then translates to the fear of the unknown.&lt;/p&gt;
&lt;p&gt;My experience with general anesthesia then showed me that there is absolutely nothing. No experience, no memory, no thought, no knowledge of time. What's there to fear about nothingness? We end up fearing nothing, and to put a play on words, we should therefore fear nothing.&lt;/p&gt;</content></entry><entry><title>On Doing and Happiness</title><link href="/on-doing-and-happiness.html" rel="alternate"></link><published>2018-01-14T10:11:00+00:00</published><updated>2018-01-14T10:11:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2018-01-14:/on-doing-and-happiness.html</id><summary type="html">&lt;p&gt;I wrote some post a while back that explored what I felt that I should do, and to some extent, embarking on my passion hunt.&lt;/p&gt;
&lt;p&gt;I now feel that passion should not be tied down to one specific action. Be it a passion for sports, or drawing, or technology. Passion …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wrote some post a while back that explored what I felt that I should do, and to some extent, embarking on my passion hunt.&lt;/p&gt;
&lt;p&gt;I now feel that passion should not be tied down to one specific action. Be it a passion for sports, or drawing, or technology. Passion should be about life and living. We weren't born to paint, or to play basketball. We were born to live, and what we do with the life we live makes it worth while.&lt;/p&gt;
&lt;p&gt;Whatever makes you happy, you should pursue it. Don't be troubled that multiple things make you happy, and that you're a Jack of all trades, master of none. It's okay to want to do multiple things. What's important is your happiness. &lt;/p&gt;
&lt;p&gt;I think here is where I have to quickly draw the distinction between happiness and pleasure. Happiness is something that you feel at no expense of others. Happiness can also be shared with others. In other words, happiness has the broader community involved. When someone has a newborn baby or when someone graduates are examples of shared communal happiness. When you achieve something,  such as a pay raise or reach certain fitness goals, those are private happiness, but with the ability of being shared. People can be happy for you, or you're able to make others happy with that achievement.&lt;/p&gt;
&lt;p&gt;Pleasure on the other hand is entirely private, and has the danger of becoming destructive. The five of the seven sins are the perfect caricature of pleasure. Lust, gluttony, greed, sloth and wrath. These are activities which you indulge in purely for your own sake. They cannot be shared, and an overindulgence can lead to self destruction. It's okay to do pleasurable things, but they must be actively moderated. Eating unhealthy but tasty food, sleeping in and doing nothing, masturbation (contentious), playing video games are all pleasurable, and too much of it destroys oneself.&lt;/p&gt;
&lt;p&gt;Back to the point of doing, we should therefore engage in activities that bring about happiness, and cautiously engage in pleasurable activities. It's fine if you do multiple things. Some people find certain activities more appealing, and hence focus their efforts on it. Others find multiple activities appealing, and their efforts are more diverse instead of directed. There is no right or wrong, because in the end, both paths lead to happiness.&lt;/p&gt;</content></entry><entry><title>Hypervigilance and Mindfulness</title><link href="/hypervigilance-and-mindfulness.html" rel="alternate"></link><published>2017-12-26T13:35:00+00:00</published><updated>2017-12-26T13:35:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-12-26:/hypervigilance-and-mindfulness.html</id><summary type="html">&lt;p&gt;Hypervigilance is being in a constant state of look out for potential dangers and threats. Everything in a normal day could be viewed as a potential threat, and the endless worst case scenarios play out in all their different ways.&lt;/p&gt;
&lt;p&gt;Being in this state usually has a history behind it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hypervigilance is being in a constant state of look out for potential dangers and threats. Everything in a normal day could be viewed as a potential threat, and the endless worst case scenarios play out in all their different ways.&lt;/p&gt;
&lt;p&gt;Being in this state usually has a history behind it, be it PSTD, or living in constant fear for your safety as a child. As a result, this hypervigilant behavior is brought together into adulthood, where the dangers are suddenly more real and all around us. Car accidents, terrorism, a plane crash, a leaking gas pipe that engulfs everyone in flames.&lt;/p&gt;
&lt;p&gt;Hypervigilance is in effect mindfulness with fear attached to it. Mindfulness is the awareness of our surrounding, and of the people around us. To be mindful is to be in a state of peacefulness. You are aware of your surroundings, and you hold no feelings towards them. But once you start being aware of everything and being afraid of the unknown dangers, it turns into hypervigilance.&lt;/p&gt;
&lt;p&gt;Don't seek out unknown, or even non-existent threats. Just be aware and mindful of your surrounding. Attach no feelings to it, and you will be at peace.&lt;/p&gt;</content></entry><entry><title>Receiving and Giving</title><link href="/receiving-and-giving.html" rel="alternate"></link><published>2017-10-16T01:26:00+00:00</published><updated>2017-10-16T01:26:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-10-16:/receiving-and-giving.html</id><summary type="html">&lt;p&gt;There are two ways to achieve happiness. You either receive something from both yourself or others, or you can give something to others. &lt;/p&gt;
&lt;p&gt;Examples of receiving something that makes you happy: you eat good food; you have received a good meal. You have a good sleep; you have received a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are two ways to achieve happiness. You either receive something from both yourself or others, or you can give something to others. &lt;/p&gt;
&lt;p&gt;Examples of receiving something that makes you happy: you eat good food; you have received a good meal. You have a good sleep; you have received a good rest. Someone gives you a compliment; you have received praise. All the things on which you are on the receiving end that makes you happy, are things that nourishes you; your mind, body and soul. You have taken in something from the exterior. In fact, this is the more natural way we achieve happiness, but if we indulge too much in receiving, we become entitled and selfish. Natural, because it is in our instincts to seek pleasure. Selfish, because we may infringe on others happiness.&lt;/p&gt;
&lt;p&gt;To prevent an over-indulgence or dependence on being on the receiving end of things, we need to acknowledge that giving can be just as rewarding, if not more. Giving a hug, giving a compliment, giving time,  giving love, giving up your rights. There's a saying I read long ago: five up your rights for other people's happiness. Give up your happiness for other people's rights. Giving is not as natural as receiving, because it is somehow seen as being on the losing end, and we all don't like to lose. But is it really? There is almost always nothing to lose when you give, and in fact, both parties (the giver and the receiver) both have a net increase in happiness. &lt;/p&gt;
&lt;p&gt;The difference between giving and receiving is that you can only give within your means, a constrain that requires effort. Receiving requires absolutely no effort, and there is no limit to how much one can receive. As such, it is a lot easier to receive than to give. But it is the effort in giving that makes it so much more worthy and satisfactory. And this applies almost to everything else. The illusion of happiness in non-effort in life.&lt;/p&gt;
&lt;p&gt;Put in a little effort, give a little more, exhibit gusto, do away with the life of passivity, and you'll see that it's a lot more worth living and bearable. &lt;/p&gt;</content></entry><entry><title>The Meaning</title><link href="/the-meaning.html" rel="alternate"></link><published>2017-09-02T06:09:00+00:00</published><updated>2017-09-02T06:09:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-09-02:/the-meaning.html</id><summary type="html">&lt;p&gt;What is the meaning of life? Big question, and I approach this knowing that I can never find the answer. It is however, not the end that matters, but the means. The thought process. If I cannot find out what life is, at least I can deduce what life is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;What is the meaning of life? Big question, and I approach this knowing that I can never find the answer. It is however, not the end that matters, but the means. The thought process. If I cannot find out what life is, at least I can deduce what life is not by thinking about it.&lt;/p&gt;
&lt;p&gt;First, let us define what is meaning when we attempt to use it to describe life:&lt;/p&gt;
&lt;p&gt;[The Meaning of Meaning]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;When we say that something as meaning, we can refer to two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A Description.&lt;/li&gt;
&lt;li&gt;A Significance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Meaning, when used as a description, simply describes an action, a word or anything that requires inference. His actions of banging the table &lt;strong&gt;means&lt;/strong&gt; he is angry. His tone of saying this word &lt;strong&gt;means &lt;/strong&gt;he is sarcastic. The way he dresses &lt;strong&gt;means &lt;/strong&gt;he is an outgoing purpose&lt;/p&gt;
&lt;p&gt;But when we refer to meaning as a significance, we are not describing anything, but ascribing something to it. Ascription, is defined as&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;* to refer to a supposed cause, source, or author*&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.merriam-webster.com/dictionary/ascribe"&gt;https://www.merriam-webster.com/dictionary/ascribe&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is to say, when we ask what is the meaning of life, we ascribe a significance to it, and that significance is the supposed cause of life. The supposed cause of why we are here.&lt;/p&gt;
&lt;p&gt;Now that we have defined what we mean by meaning, let us proceed.&lt;/p&gt;
&lt;p&gt;[Is the meaning of life to seek pleasure?]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Humans instinctively seeks pleasure. We are pleasure driven, and want to feel good. Pleasurable food, pleasurable company, pleasurable work. But is the meaning to life just to seek out pleasure? Are we driven solely to seek pleasure? To me, this way of thinking sounds like we are holding too low of a standard to ourselves. Being pleasure driven limits our actions and thoughts to only a select few. Some actions are not pleasurable, but reaps enormous benefits. We must do those too.&lt;/p&gt;
&lt;p&gt;Having only to seek pleasure seems a little selfish too, that all our actions should be guided towards making ourselves happy. It seems to imply the absence of consideration for others, because if we do, there would definitely be some degree of compromise involved on our personal pleasures.&lt;/p&gt;
&lt;p&gt;Is this the supposed cause of life? That we are here just to feel good and then pass on? It may fit the bill for some people, but not for me.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pleasure: Too low a standard. Too selfish.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[Is the meaning of life to service about others?]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;This can be a valid meaning for some, but not to me. It requires you to hold a great deal of altruism, so much in fact that you are willing to forgo all of your needs to service others. I find that only religious people can lie in this category, because their goal is driven towards a divine unworldly being, and hence they are willing to forsake all that is earthly in return for Salvation.&lt;/p&gt;
&lt;p&gt;Can an atheist or a non-believer do the same? To give up all of his belongings, his career and his wants to be of service to others. I do not think so, as the non-religious are bounded by the tangible. Without any promise of reward to give up their earthly belongings and personal goals, one would not be enticed to do so.&lt;/p&gt;
&lt;p&gt;That does not mean that the non-religious cannot love as much as the religious. Both parties can love another person to the same degree, but both take different actions to express their love. Both would dedicate their lives to the service of others, but the non-religious would still hold on to his part, while the religious has already given up that part to their God.&lt;/p&gt;
&lt;p&gt;This seems like a good meaning to life. That we are here to help and assist others. It does not matter the degree of altruism, as long as we have it in mind. But to me, this does not seem significant enough to be my meaning to life. I cannot find myself dedicating a big part of my life and giving up all that I have to the service of others (Sorry, i'm just not that altruistic). Sure, I do give and contribute to society, but it is not a big part of me attribute this as the significance and meaning of my life.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Service to others: Good and valid meaning, just not mine&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[Is the meaning to life about reproduction?]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;The underlying biology in our genes drives us to find the perfect conditions to procreation and spreading life. However, we are lucky enough to be in a era (and country) where our basic needs of security is met. We have shelter, food, water, and all other basic necessities such that survival is not an immediate concern.&lt;/p&gt;
&lt;p&gt;In the absence of this constant threat of dying, we put our mental capabilities to good use and think in the abstract. Those whose basic necessities are already met, but still tirelessly seek them out are working to gain excess. The gluttonous and the materialist. They do not make use of the capabilities of their minds to give (ideas, abstraction), but are caught in the constant pleasures of what is already given (food, company).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reproduction: Conditions for reproduction are not a dire threat. Therefore no significance is gained in pursuing it&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[The the meaning to life about knowledge]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;I guess this is the only meaning that I find most appealing.&lt;/p&gt;
&lt;p&gt;Of all the living things on the earth, we have the most powerful brain. Why shouldn't we use it? An alligator uses its strong jaws for hunting. The lion uses its lethal fangs for the kill. The bird uses its wings to fly. Yet humans, for all its physical deficiencies in murderous Savannah, triumphs because of the brain.&lt;/p&gt;
&lt;p&gt;I wont go into detail the wondrous things the brain can do. It has helped us survive, and even more, thrive. One of the ways to train the brain and make use of its full potential is to gain knowledge. Technical knowledge (IT skills), Social knowledge (E.Q), General knowledge (I.Q), Moral knowledge (Beliefs), Spiritual knowledge (Religion) and many more. The key is to learn, and apply critical thinking onto the lessons learnt.&lt;/p&gt;
&lt;p&gt;Of course, not everything can be known, and not everything can be understand by rationality. The thirst for knowledge is like a hungry man. Inquire too much, and you would never be full. Inquire nothing, and you would starve. Inquiring in the right amount, and putting faith in the unanswerable, keeps you fill.&lt;/p&gt;
&lt;p&gt;This, amalgamated with the significance of service to others, can be the meaning of life, and also lead to a meaningful life*.&lt;/p&gt;
&lt;p&gt;To learn, To serve.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Discere Servire&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;* "Can be the meaning of life" is different from "Lead to a meaningful life". The former puts meaning in precedence, that we were placed here to fulfill the significance. The latter describes meaning as an emergent ascription, that is to say that life inherently has no meaning, but what we do gives it meaning. I believe that if we conclude the meaning to be both the prior and the posterior, we have found true meaning. I don't imagine this to be an easy task. Some find the prior without the posterior (A religious person who is stuck in a corporate job), and others, a posterior without the prior (A person who loves his job, but wonders if there is something greater). I am in the latter group, and I do know of a few people in the former group.&lt;/p&gt;</content></entry><entry><title>MEDITATIONS; Book 3; IN CARNUNTUM by Marcus Aurelius</title><link href="/meditations-book-3-in-carnuntum-by-marcus-aurelius.html" rel="alternate"></link><published>2017-07-24T13:34:00+00:00</published><updated>2017-07-24T13:34:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-07-24:/meditations-book-3-in-carnuntum-by-marcus-aurelius.html</id><summary type="html">&lt;p&gt;"Don’t waste the rest of your time here worrying about&lt;br&gt;
other people—unless it affects the common good. It will&lt;br&gt;
keep you from doing anything useful. You’ll be too&lt;br&gt;
preoccupied with what so-and-so is doing, and why, and&lt;br&gt;
what they’re saying, and what they’re thinking, and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;"Don’t waste the rest of your time here worrying about&lt;br&gt;
other people—unless it affects the common good. It will&lt;br&gt;
keep you from doing anything useful. You’ll be too&lt;br&gt;
preoccupied with what so-and-so is doing, and why, and&lt;br&gt;
what they’re saying, and what they’re thinking, and what&lt;br&gt;
they’re up to, and all the other things that throw you off and&lt;br&gt;
keep you from focusing on your own mind.&lt;br&gt;
You need to avoid certain things in your train of thought:&lt;br&gt;
everything random, everything irrelevant. And certainly&lt;br&gt;
everything self-important or malicious. You need to get used&lt;br&gt;
to winnowing your thoughts, so that if someone says, “What&lt;br&gt;
are you thinking about?” you can respond at once (and&lt;br&gt;
truthfully) that you are thinking this or thinking that. And it&lt;br&gt;
would be obvious at once from your answer that your&lt;br&gt;
thoughts were straightforward and considerate ones—the&lt;br&gt;
thoughts of an unselfish person, one unconcerned with&lt;br&gt;
pleasure and with sensual indulgence generally, with&lt;br&gt;
squabbling, with slander and envy, or anything else you’d be&lt;br&gt;
ashamed to be caught thinking."&lt;/p&gt;</content></entry><entry><title>What Kind Of Life Do I Want To Lead?</title><link href="/what-kind-of-life-do-i-want-to-lead.html" rel="alternate"></link><published>2017-07-22T15:11:00+00:00</published><updated>2017-07-22T15:11:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-07-22:/what-kind-of-life-do-i-want-to-lead.html</id><summary type="html">&lt;p&gt;That's a question I've began to re-ask myself. I think that over the short period my career as a Software Engineer (Or a Systems Analyst) for 2 years has changed my perceptions quite a bit.&lt;/p&gt;
&lt;p&gt;Things were much more straightforward as a fresh graduate. The only thing we were worried …&lt;/p&gt;</summary><content type="html">&lt;p&gt;That's a question I've began to re-ask myself. I think that over the short period my career as a Software Engineer (Or a Systems Analyst) for 2 years has changed my perceptions quite a bit.&lt;/p&gt;
&lt;p&gt;Things were much more straightforward as a fresh graduate. The only thing we were worried about was employment. Which company do i want to work in, which field of work do i want to dive into, how much starting salary should i aim for such that it is a good base were all the topics of discussion. Now, those were good questions to ask, but they were good and relevant only at that point of time. However, i'm long past that phase, and those questions have duly been answered, met, or just became irrelevant and obsolete. That does not mean that i should stop asking those types of questions. Life decisions and questions of which the answers influence your actions.&lt;/p&gt;
&lt;p&gt;What kind of life do i want to lead, is the question I've been asking. Now that i have a stable job and a steady flow of income, i think i can safely say that I've moved up the rungs of Maslow's Hierarchy of Needs for me to think about esteem. When i use the word "esteem" here, i'm referring to the value i see in myself, and the intrinsic value i'm able to bring to society. What sort of life do i have to lead in order for me to feel that my life is valuable? What decisions do i have to make, professions i have to engage in, or people i have to help that would give me meaning? I guess in this sense, a valuable life is a meaningful life, therefore perhaps the question i should be asking is &lt;strong&gt;What Gives Life Meaning?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here, i would like to take a quotation from a book "Man's Search for Meaning" by Viktor Frankl, where he says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What was really needed was a fundamental change in our attitude toward life. We had to learn ourselves and, furthermore, we had to teach the despairing men, that &lt;em&gt;it did not really matter what we expected from life, but rather what life expected from us&lt;/em&gt;. We needed to stop asking about the meaning of life, and instead think of ourselves as those who were being questioned by life—daily and hourly. Our question must consist, not in talk and meditation, but in right action and in right conduct. Life ultimately means taking the responsibility to find the right answer to its problems and to fulfill the tasks which it constantly sets for each individual.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is in direct contradiction to the question i have in mind. He seems to allude a life of passivity in decisions, where you only react to the lemons being thrown at you. While I do agree with this sort of thinking, where &lt;em&gt;"Our question must consists, not in talk and meditation, but in right action and in right conduct."&lt;/em&gt;, I feel that it should be augmented with another form of active thinking, and we should be doing both the passivity of reaction to life, as well as the proactive seeking to what we desire. Perhaps in his situation, the latter was not revealed to him as a choice.&lt;/p&gt;
&lt;p&gt;I have previously thought of some areas of life that, amalgamated together, give rise to meaning. They were: Self, Social, Spiritual and Professional. However, i've began to think that these were only generally good guidelines on how to compartmentalize my life, but not a guideline to find meaning, or how to direct my actions towards a more fulfilling life.&lt;/p&gt;
&lt;p&gt;Inherently, we are all pleasure seeking, and a very general meaning we all have is the attainment of satisfaction. Things that make us or others happy is definitely meaningful. But that's still extremely broad. What kind pleasures are we speaking about? Pleasures of mental stimulation? Pleasures of the flesh? Pleasures of social interaction? Pleasures of recognition? I guess a way to go get closer to the answer is to get further abstracted away from the original question. What gives me pleasure? That which gives me pleasure, gives me meaning. That which gives me meaning, gives me value.&lt;/p&gt;
&lt;p&gt;I think I shall leave answering this question for another post. What Gives Me Pleasure?&lt;/p&gt;</content></entry><entry><title>Triggers and the Environment</title><link href="/triggers-and-the-environment.html" rel="alternate"></link><published>2017-04-12T10:05:00+00:00</published><updated>2017-04-12T10:05:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-04-12:/triggers-and-the-environment.html</id><summary type="html">&lt;p&gt;I've recently finished reading a book by Marshall Goldsmith titled "Triggers", and in it details some very interesting bits of information.&lt;/p&gt;
&lt;p&gt;Before I go on to explain them, I would like to say that in the past, I was rather skeptical about reading such books. Books that teach you about …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've recently finished reading a book by Marshall Goldsmith titled "Triggers", and in it details some very interesting bits of information.&lt;/p&gt;
&lt;p&gt;Before I go on to explain them, I would like to say that in the past, I was rather skeptical about reading such books. Books that teach you about life skills, and talks about seemingly obvious stuff. But now, I've come to realize that maybe I don't know myself as much as I would like to, and the seemingly obvious was actually hidden from me, working unconsciously. Books that give me actionable insights on myself and onto others around me now draw my attention. A different phase of life requires a different set of guidance.&lt;/p&gt;
&lt;p&gt;Now, on to the actual topics and take away points of the book.&lt;/p&gt;
&lt;p&gt;There were many topics covered in the books, such as a slight introduction to psychology, decision fatigue, touching on willpower and other common themes that find their place in self-help books. I would like to focus however, on a few very specific points that he made, which I felt was what I was paying the money for.&lt;/p&gt;
&lt;p&gt;If the points could be summarized into a diagram, here it is&lt;/p&gt;
&lt;p&gt;&lt;img alt="Presentation1" class="alignnone size-full wp-image-558" height="720" src="https://jayhayche.files.wordpress.com/2017/04/presentation1.jpg" width="960"&gt;&lt;/p&gt;
&lt;p&gt;The environment that we are in induces certain triggers within us, whether we like it or not. As much self control we think we have, these triggers find their way into our minds unwillingly.&lt;/p&gt;
&lt;p&gt;When a trigger gets activated, say a colleague you detest walks in, or you arrive to work where its a stressful place, you will then face impulses. Impulses to do a certain set of pre-learned actions that put into safety. For example, if we get a stress trigger, we may have an impulse to eat food to calm our nerves.&lt;/p&gt;
&lt;p&gt;These impulsive behaviors caused by the triggers may not always be good. Shoving your face with food every time you feel stressed doesn't seem like a very healthy thing to do. Therefore, we must develop awareness of these impulsive behaviors. Before we act on anything, we have to be aware of it. Once we are aware, we can then &lt;strong&gt;rationally &lt;/strong&gt;make our choices.&lt;/p&gt;
&lt;p&gt;Here's a simple scenario that puts all of that into play:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I go to work&lt;/li&gt;
&lt;li&gt;The work environment is stressful&lt;/li&gt;
&lt;li&gt;The stressful environment triggers me&lt;/li&gt;
&lt;li&gt;An impulsive action that has been triggered is to munch on comfort sugary food&lt;/li&gt;
&lt;li&gt;I am aware that I have these impulses&lt;/li&gt;
&lt;li&gt;I am aware that I have a choice to not carry out these actions&lt;/li&gt;
&lt;li&gt;I choose not to eat the glazed donuts&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And this scenario can be emulated in almost any environment. From your boredom at home that triggers excessive napping, to feeling stressed that triggers smoking, to meeting someone you have animosity with that triggers angry words.&lt;/p&gt;
&lt;p&gt;The key take away from this lesson is to ultimately stop acting out on undesirable impulsive actions. And I personally feel that the greater lesson here is to learn how to have awareness of your own thoughts. Once you are aware, you can rationalize. Otherwise, it'll just be on autopilot mode.&lt;/p&gt;
&lt;p&gt;The book also taught me a simple exercise to do for myself. It's called the wheel of change. It tells us to identify areas in our life that we should:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create&lt;/li&gt;
&lt;li&gt;Eliminate&lt;/li&gt;
&lt;li&gt;Preserve&lt;/li&gt;
&lt;li&gt;Accept&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To show a naive example of this in practice: Creating better friendships, Eliminate toxic people, Preserving current friends, and Accepting friends for who they are.&lt;/p&gt;
&lt;p&gt;I took this exercise and combined it with the 4 circles of life, namely Social, Spiritual, Professional, and Personal. In the end, it sort of looks like a table like this.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Presentation1" class="alignnone wp-image-586" height="467" src="https://jayhayche.files.wordpress.com/2017/04/presentation11.jpg" width="623"&gt;&lt;/p&gt;
&lt;p&gt;I've spent a day on this table and filled it up with all the events to create, eliminate, preserve and accept. I've then stuck it right in front of me on my desk to constantly remind me of the work I need to do.&lt;/p&gt;
&lt;p&gt;P.S. I think as i'm starting to read more books at a greater frequency, I should start doing a book review on them. A review would help me recap the points that I've learnt, as well as to share the insights with others.&lt;/p&gt;</content></entry><entry><title>The Subjectivity of Suffering.</title><link href="/the-subjectivity-of-suffering-2.html" rel="alternate"></link><published>2017-03-28T07:03:00+00:00</published><updated>2017-03-28T07:03:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2017-03-28:/the-subjectivity-of-suffering-2.html</id><summary type="html">&lt;p&gt;How do we come to conclude that a certain event, or despairing predicament a person is in amounts to suffering?&lt;/p&gt;
&lt;p&gt;We know that we are suffering if we feel a certain amount of personal discomfort. The Sun is beating down on your exposed skin. Your legs weary from standing. Your …&lt;/p&gt;</summary><content type="html">&lt;p&gt;How do we come to conclude that a certain event, or despairing predicament a person is in amounts to suffering?&lt;/p&gt;
&lt;p&gt;We know that we are suffering if we feel a certain amount of personal discomfort. The Sun is beating down on your exposed skin. Your legs weary from standing. Your heart aches from a sour relationship. Your stomach growls in emptiness.&lt;/p&gt;
&lt;p&gt;We know for certain when we experience suffering, with our own subjective intangible metrics. Certain lines we cross that our mind tells us “Stop!”. And this threshold changes and varies with so many external factors. Your boss compared to your friend. 8 hours of sleep compared to 3 hours of sleep. An empty stomach compared to a ravanous one.&lt;/p&gt;
&lt;p&gt;Even to ourselves, for which we supposedly know best, cannot concretely define our own suffering, how then do we know for certain if another person is in a state of suffering?&lt;/p&gt;
&lt;p&gt;We see a person in a wheelchair, a disabled person with no arms or even a person without a home, and we immediately think of them as suffering.&lt;/p&gt;
&lt;p&gt;But are they really suffering subjectively? Or do we assume that they are suffering because they do not fit into our ideal visions of happiness?&lt;/p&gt;
&lt;p&gt;“He must be suffering because he is in a wheelchair, and is unable to walk and run.”&lt;/p&gt;
&lt;p&gt;“She must be suffering because she has no home and family to live with”&lt;/p&gt;
&lt;p&gt;Here, we project our beliefs of happiness onto them, and if they do not match any of them, we instinctively think that they are suffering.&lt;/p&gt;
&lt;p&gt;Is a man with no arms suffering, if he has become at peace with it, and lives his life to the fullest?&lt;/p&gt;
&lt;p&gt;What about a man with two functional arms, but with a troubled mind that wears him down everyday?&lt;/p&gt;
&lt;p&gt;And because we do not see the troubled mind, we have no projections of suffering, and we do not emphatize as much. That is the neglect depression suffers endure.&lt;/p&gt;
&lt;p&gt;This projection ultimately originates from ourselves. How we define how happiness should be achieved influences how much suffering we see other people have.&lt;/p&gt;
&lt;p&gt;A simple man sees a simple world, with happiness defined simply. He thus sees less suffering, because the simplest of events matches his views of attaining peace. Being able to eat a meal. Having a shelter over your head. Having a friend.&lt;/p&gt;
&lt;p&gt;A demanding man demands much from the world, with happiness defined complexly. He sees the most suffering, because it is so hard for him to be happy, and no one else should be. You must have a car. You must be earning a certain amount of income.&lt;/p&gt;
&lt;p&gt;I am not saying that there is no suffering. War, famine and death are very real sufferings.&lt;/p&gt;
&lt;p&gt;True sufferings are the ones that we can all relate to.&lt;/p&gt;
&lt;p&gt;Projected sufferings are the ones that don’t fit to our vision.&lt;/p&gt;
&lt;p&gt;That being said, true sufferings or projected sufferings, we must strive to eliminate or at least mitigate them.&lt;/p&gt;</content></entry><entry><title>Shadow Goodness and Badness</title><link href="/shadow-goodness-and-badness.html" rel="alternate"></link><published>2016-12-23T14:06:00+00:00</published><updated>2016-12-23T14:06:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-12-23:/shadow-goodness-and-badness.html</id><summary type="html">&lt;p&gt;The Shadow, a concept taken from a book I read, is a hidden part of our subconciousness. It works from the shadows, influencing our actions, our thoughts and our speech. All these happens, unknowing to us, while we are still left thinking we have full control of everything about us …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Shadow, a concept taken from a book I read, is a hidden part of our subconciousness. It works from the shadows, influencing our actions, our thoughts and our speech. All these happens, unknowing to us, while we are still left thinking we have full control of everything about us.&lt;/p&gt;
&lt;p&gt;These Shadows, which as I will explain later, does not necessarily mean it is evil, as the name "Shadow" seems to suggest. Rather, it is like how shadow is formed by the abscence of light, the Shadow consciousness lurks in the abscence of awareness.&lt;/p&gt;
&lt;p&gt;They are formed by experiences and memories of previous situations we encountered. These reflexes that we learned and adaptations that we took form over time train our subconcious to apply them when faced with a similar situation in the future. Our future is therefore binded tightly to our past.&lt;/p&gt;
&lt;p&gt;So where does the distinction between the Good Shadow and the Bad Shadow come from?&lt;/p&gt;
&lt;p&gt;To begin right from the start, we are all born with inherent goodness. No one taught us to love, yet we know how to. No training was done to teach us how to seek and give love. No conditioning was done to make it feel right to do good unto others. We are born with goodness, but we are unaware of it. The inherent Shadow Goodness.&lt;/p&gt;
&lt;p&gt;Where does the Shadow Badness come from? Notice I did not use the word "inherent" to describe this bad Shadow. It is not inherent, it is a function of the attentiveness and nourishment towards the Shadow Goodness. The lesser goodness we experience, the more room the Shadow badness occupies.&lt;/p&gt;
&lt;p&gt;When we were neglected as children, the goodness of recieving love is neglected, and this trains and conditions the soul to reject love, as if it was a norm. We adapt to the lack of love and guard ourselves against it. We learn the reflexes of not recieving love, and we allow the Shadow of badness to seep in.&lt;/p&gt;
&lt;p&gt;As evil exists in the abscence of good, shadow in the abscence of light, cold in the abscence heat, the Shadow of Badness grows in the abscence of the Shadow of Goodness.&lt;/p&gt;
&lt;p&gt;The way to reconcile with, and to heal the hurtful bad Shadow, is thus then to reinforce the good Shadow, the good unconscious. To nourish what is inherent in us, to feed the soul we were born with. Through mindful good thoughts, actions and speech in the conscious space, the subconscious learns these reflexes and adaptations to love. &lt;/p&gt;
&lt;p&gt;It becomes accustom to give and recieve love, as we were born with the ability to do so right from the start.&lt;/p&gt;</content></entry><entry><title>Religious again?</title><link href="/religious-again.html" rel="alternate"></link><published>2016-12-11T10:16:00+00:00</published><updated>2016-12-11T10:16:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-12-11:/religious-again.html</id><summary type="html">&lt;p&gt;Should I go back to being religious? It seems like I have strayed away from the person I sought myself to be.&lt;/p&gt;
&lt;p&gt;After doing away with religion, I have fallen back on pure logic. Pure naturalistic logic, while at the same time compromising on abstracted morals related to certain actions …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Should I go back to being religious? It seems like I have strayed away from the person I sought myself to be.&lt;/p&gt;
&lt;p&gt;After doing away with religion, I have fallen back on pure logic. Pure naturalistic logic, while at the same time compromising on abstracted morals related to certain actions.&lt;/p&gt;
&lt;p&gt;With no rules, I have taken the bottom up approach, as mentioned in my previous post. My actions are guided from what I think is right, and then I go on to mould and reshape my beliefs to justify them.&lt;/p&gt;
&lt;p&gt;But now I feel that something is wrong. I feel wrong inside. It feels.. unnatural. Ironic, since they are guided by natural instincts.&lt;/p&gt;
&lt;p&gt;If I wish to take the Top-down view of things, the return to religion, it would be optimal.&lt;/p&gt;
&lt;p&gt;The issue here is: the reason I am going back to religion is not because I believe in it. It is not because I fear the consequnces of being a non-believer, but only because it grounds me, and gives me a base, one that I initially sought without religion to much apparent failure, to guide my thoughts and actions.&lt;/p&gt;
&lt;p&gt;Hence, I am being religious not for a religous purpose, but for a moral purpose.&lt;/p&gt;
&lt;p&gt;Which religion should I choose? Prime consideration would be one that has believes I subcribe to. Secondary consideration would be that it has a support group who shares the same spiritual (not religious) belief as I do. Other considerations include doing away with idols and rituals, a non-conformist approach to show devotion, and one that gives me sufficient solace.&lt;/p&gt;
&lt;p&gt;Its time to go back.&lt;/p&gt;</content></entry><entry><title>Top-down or Bottom-up</title><link href="/top-down-or-bottom-up.html" rel="alternate"></link><published>2016-12-02T00:19:00+00:00</published><updated>2016-12-02T00:19:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-12-02:/top-down-or-bottom-up.html</id><summary type="html">&lt;p&gt;Life is a peculiar thing, in which we can have different views about it, and they will all be perfectly valid. The view that it is all about suffering, the view that it is about maximizing pleasure or the view that it has no meaning at all. And these are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Life is a peculiar thing, in which we can have different views about it, and they will all be perfectly valid. The view that it is all about suffering, the view that it is about maximizing pleasure or the view that it has no meaning at all. And these are all perfectly valid views because they come from a collective subjective experience. You can't say it is definitely wrong, because the person has a life as well, and with that, he has every right to see how it is.&lt;/p&gt;
&lt;p&gt;But I would like to focus on two views on life&lt;/p&gt;
&lt;p&gt;1) Top-down view: This view says we first believe in a higher abstracted meaning, and all subsequent actions are justified and adjusted to fulfil that meaning.&lt;/p&gt;
&lt;p&gt;2) Bottom-up view: This view says we still have an abstracted belief, but how we attain it is guided through our actions. In this view, the belief can be modified and changed in order to justify actions.&lt;/p&gt;
&lt;p&gt;In this case, it is best if we all took the Top-down view of things. A Bottom-up view allows you to morph and conjure lies to mask the belief in order to suit your liking. This gives a very dubious and unreliable compass to guide us.&lt;/p&gt;
&lt;p&gt;A Top-down approach on the other hand gives us a staunch and firm ground for us to anchor of decisions and actions on. And all consequential outcomes can be drawn back to a common belief it was derived from, giving us an objective assessment of the belief we were holding. Therefore, if the outcomes were undesirable, either we stop the action, or rebase our beliefs. This is contrast to the moving goal-post of the Bottom-up approach&lt;/p&gt;</content></entry><entry><title>Like Water, Like Life</title><link href="/like-water-like-life.html" rel="alternate"></link><published>2016-11-01T13:05:00+00:00</published><updated>2016-11-01T13:05:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-11-01:/like-water-like-life.html</id><summary type="html">&lt;p&gt;Life is analogous to water.&lt;/p&gt;
&lt;p&gt;Water flows; to give life; to create; to quench a thirst; to show beauty.&lt;/p&gt;
&lt;p&gt;To destroy; to drown; to wash away; to drench a man.&lt;/p&gt;
&lt;p&gt;What does your water flow for?&lt;/p&gt;
&lt;p&gt;What is your life for?&lt;/p&gt;
&lt;p&gt;How you direct your energy of life, decides how …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Life is analogous to water.&lt;/p&gt;
&lt;p&gt;Water flows; to give life; to create; to quench a thirst; to show beauty.&lt;/p&gt;
&lt;p&gt;To destroy; to drown; to wash away; to drench a man.&lt;/p&gt;
&lt;p&gt;What does your water flow for?&lt;/p&gt;
&lt;p&gt;What is your life for?&lt;/p&gt;
&lt;p&gt;How you direct your energy of life, decides how you impact those around you. How you decide to lead your life, impacts all those around you. To what morals you align your life to, influences things around you.&lt;/p&gt;
&lt;p&gt;Water doesn't have any meaning. There is no tangible reality which water emulates to give it meaning.&lt;/p&gt;
&lt;p&gt;Thing that do have meaning, sees itself as a comparison of likeliness to another.&lt;/p&gt;
&lt;p&gt;Smiling means happiness. Frowning means sadness. Banging your fist on the table means anger. Running away means fear.&lt;/p&gt;
&lt;p&gt;Water means?&lt;/p&gt;
&lt;p&gt;But what water lacks in meaning, it compensates with purpose, beneficial or destructive, it has no preference.&lt;/p&gt;
&lt;p&gt;Perhaps, life has no meaning then. For what tangible emulations does life exhibit? What understandable experience can we fit life into? When all possible tangible emulations are contained within, and arises from life, finding a comparison would be illogical.&lt;/p&gt;
&lt;p&gt;Again, like water, life compensates the lack of meaning with purpose, which too has no preference.&lt;/p&gt;
&lt;p&gt;While life then has no preference of a beneficial or destructive purpose, it is guided by the desires of man. And it is here that social dynamics takes place, with our best efforts to achieve what is beneficial to everyone. A rare few have their desires guided towards destruction, and it is those we condemn.&lt;/p&gt;
&lt;p&gt;So, putting it shortly: Life is driven by beneficial purposes.&lt;/p&gt;
&lt;p&gt;Benefits for others.&lt;/p&gt;
&lt;p&gt;Benefits for self.&lt;/p&gt;
&lt;p&gt;Benefits, being entirely qualitative, I shall not attempt to delve into.&lt;/p&gt;
&lt;p&gt;Perhaps then, we should stop asking "What is the meaning of life", for as explained earlier, it is a paradox to caricaturize a thing in itself.&lt;/p&gt;
&lt;p&gt;Instead, we should be asking "What is the purpose of my life". And it is with a strong desire that I hope it is a beneficial one.&lt;/p&gt;
&lt;p&gt;And just as the first drops of water taste the sweetest, despite the lack of taste. Just as the first gush of it is filled with rejuvenation, it slowly turns stale.&lt;/p&gt;
&lt;p&gt;It starts to be a bother. Bloated, over-hydrated. The mouth accustomed to the taste sips it in disdain.&lt;/p&gt;
&lt;p&gt;Life then, is also the sweetest at its inception. The burst of youth and ideas. The jovial experiences. The endearing curiosity of the young man.&lt;/p&gt;
&lt;p&gt;It slows, becomes a burden. The familiarity brings with it disappointment.&lt;/p&gt;
&lt;p&gt;So enjoy the initial taste, for it only comes once.&lt;/p&gt;
&lt;p&gt;And after the bottle is empty, it may be refilled*.&lt;/p&gt;
&lt;p&gt;But those are not for you anymore,&lt;/p&gt;
&lt;p&gt;For you had your fill.&lt;/p&gt;
&lt;p&gt;(* I say this because I do have certain spiritual inclinations. For the non-spiritual, you can view it as new life being brought to earth)&lt;/p&gt;</content></entry><entry><title>Goals, and how to make one</title><link href="/goals-and-how-to-make-one.html" rel="alternate"></link><published>2016-10-21T01:14:00+00:00</published><updated>2016-10-21T01:14:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-10-21:/goals-and-how-to-make-one.html</id><summary type="html">&lt;p&gt;If the essence of life has inherent positivity, then there would be no such thing as boredom.&lt;/p&gt;
&lt;p&gt;Just by mere existence, would bring about satisfaction and content. Just by being, will suffice. But that is never the case.&lt;/p&gt;
&lt;p&gt;We get bored, and we feel valueless when we merely exist. The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If the essence of life has inherent positivity, then there would be no such thing as boredom.&lt;/p&gt;
&lt;p&gt;Just by mere existence, would bring about satisfaction and content. Just by being, will suffice. But that is never the case.&lt;/p&gt;
&lt;p&gt;We get bored, and we feel valueless when we merely exist. The meaning of life has no meaning in just being, and so we seek out to do.We set goals to strive for.&lt;/p&gt;
&lt;p&gt;Goals that are difficult and distance, of which those properties gives us a belief that there would be satisfaction in the end. The harder the goal, the more hope it gives us that happiness can be attained. The more complex and distant the goal, the more we can justify ourselves for being satisfied.&lt;/p&gt;
&lt;p&gt;There are some people, undoubtly, relish in boredom. They do not see a need to strive for a goal, and are satisfied being bored. This aimlessness, I consider a plauge.&lt;/p&gt;
&lt;p&gt;By setting goals that are too easily achieveable, it poses no challenge to us, and gives us little satisfaction. And even if we set a longer and harder goal, there will still be no guarantee it will give us satisfaction when we finally reach it. An unfazed graduate who finished his years of education. A disgruntled super car owner.&lt;/p&gt;
&lt;p&gt;Again, the premise here is that when we set goals, it gives us hope and optimism that it will lead to satisfaction. The strategy here is to set a goal that is impossible to quantify. A goal that is larger than yourself. Abiding by morals, devoting to a religion, patrotism to your country, living for others. And because these are not quantifiable, there will always be hope granted by these goals.&lt;/p&gt;
&lt;p&gt;And as we derive such hopefulness from our goals, we become satisfied with life.&lt;/p&gt;
&lt;p&gt;*(A distinction must be made here between short term goals, and lifelong goals. Short term goals are still practical and necessary. But we must be cautious on what we place our finger on our lifelong goals)&lt;/p&gt;</content></entry><entry><title>Live for today, live for the future</title><link href="/live-for-today-live-for-the-future.html" rel="alternate"></link><published>2016-10-20T13:27:00+00:00</published><updated>2016-10-20T13:27:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-10-20:/live-for-today-live-for-the-future.html</id><summary type="html">&lt;p&gt;There is no point in living in the future, if you're not living for today.&lt;/p&gt;
&lt;p&gt;We've been sold a belief that there is some goal in the future that we must toil for today.&lt;/p&gt;
&lt;p&gt;We've been told to plan and envision where we want to be in the future.&lt;/p&gt;
&lt;p&gt;So …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There is no point in living in the future, if you're not living for today.&lt;/p&gt;
&lt;p&gt;We've been sold a belief that there is some goal in the future that we must toil for today.&lt;/p&gt;
&lt;p&gt;We've been told to plan and envision where we want to be in the future.&lt;/p&gt;
&lt;p&gt;So much emphasis has been placed on something that is just as intangible as the past.&lt;/p&gt;
&lt;p&gt;And when, we finally reach the "future" we've planned for, that's not the end! There is still a next set of futures, and next set of futures, until there comes a day where we must plan our death.&lt;/p&gt;
&lt;p&gt;With this emphasis on the future, we are never really "there", but instead, placed through phases of life that are out of sync, which are always one frame in front of the present.&lt;/p&gt;
&lt;p&gt;Planning for the future is important, but how are you to plan for whats ahead, if you don't know what you have now!&lt;/p&gt;
&lt;p&gt;What point is there to read a map, if your current coordinates are a blur.&lt;/p&gt;
&lt;p&gt;Live for today! Live for the present!&lt;/p&gt;
&lt;p&gt;The future is but a fantasy, a malleable entity shaped by your choices. Choices that you make in the present.&lt;/p&gt;
&lt;p&gt;Instead of frolicking in the future that never seems to come, seize the present, and in it you have the power to make choices to shape the future.&lt;/p&gt;
&lt;p&gt;How do you live for the present?&lt;/p&gt;
&lt;p&gt;Simply be aware of the present.&lt;/p&gt;
&lt;p&gt;The people.&lt;/p&gt;
&lt;p&gt;Your words.&lt;/p&gt;
&lt;p&gt;Your thoughts.&lt;/p&gt;
&lt;p&gt;Your desires.&lt;/p&gt;
&lt;p&gt;Your surroundings.&lt;/p&gt;
&lt;p&gt;Immerse yourself into these immediate entities, and soak in the present.&lt;/p&gt;
&lt;p&gt;These things will never be experienced in the fantasy of the future, but only now.&lt;/p&gt;</content></entry><entry><title>The Subjectivity of Suffering.</title><link href="/the-subjectivity-of-suffering.html" rel="alternate"></link><published>2016-10-10T14:04:00+00:00</published><updated>2016-10-10T14:04:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-10-10:/the-subjectivity-of-suffering.html</id><summary type="html">&lt;p&gt;So i wrote a piece for one of my friend. Initally it had some religious context, but then we spoke about something more general on Suffering:&lt;/p&gt;
&lt;p&gt;How do we come to conclude that a certain event, or despairing predicament a person is in amounts to suffering?&lt;/p&gt;
&lt;p&gt;We know that we …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So i wrote a piece for one of my friend. Initally it had some religious context, but then we spoke about something more general on Suffering:&lt;/p&gt;
&lt;p&gt;How do we come to conclude that a certain event, or despairing predicament a person is in amounts to suffering?&lt;/p&gt;
&lt;p&gt;We know that we are suffering if we feel a certain amount of personal discomfort. The Sun is beating down on your exposed skin. Your legs weary from standing. Your heart aches from a sour relationship. Your stomach growls in emptiness.&lt;/p&gt;
&lt;p&gt;We know for certain when we experience suffering, with our own subjective intangible metrics. Certain lines we cross that our mind tells us “Stop!”. And this threshold changes and varies with so many external factors. Your boss compared to your friend. 8 hours of sleep compared to 3 hours of sleep. An empty stomach compared to a ravanous one.&lt;/p&gt;
&lt;p&gt;Even to ourselves, for which we supposedly know best, cannot concretely define our own suffering, how then do we know for certain if another person is in a state of suffering?&lt;/p&gt;
&lt;p&gt;We see a person in a wheelchair, a disabled person with no arms or even a person without a home, and we immediately think of them as suffering.&lt;/p&gt;
&lt;p&gt;But are they really suffering subjectively? Or do we assume that they are suffering because they do not fit into our ideal visions of happiness?&lt;/p&gt;
&lt;p&gt;“He must be suffering because he is in a wheelchair, and is unable to walk and run.”&lt;/p&gt;
&lt;p&gt;“She must be suffering because she has no home and family to live with”&lt;/p&gt;
&lt;p&gt;Here, we project our beliefs of happiness onto them, and if they do not match any of them, we instinctively think that they are suffering.&lt;/p&gt;
&lt;p&gt;Is a man with no arms suffering, if he has become at peace with it, and lives his life to the fullest?&lt;/p&gt;
&lt;p&gt;What about a man with two functional arms, but with a troubled mind that wears him down everyday?&lt;/p&gt;
&lt;p&gt;And because we do not see the troubled mind, we have no projections of suffering, and we do not emphatize as much. That is the neglect depression suffers endure.&lt;/p&gt;
&lt;p&gt;This projection ultimately originates from ourselves. How we define how happiness should be achieved influences how much suffering we see other people have.&lt;/p&gt;
&lt;p&gt;A simple man sees a simple world, with happiness defined simply. He thus sees less suffering, because the simplest of events matches his views of attaining peace. Being able to eat a meal. Having a shelter over your head. Having a friend.&lt;/p&gt;
&lt;p&gt;A demanding man demands much from the world, with happiness defined complexly. He sees the most suffering, because it is so hard for him to be happy, and no one else should be. You must have a car. You must be earning a certain amount of income.&lt;/p&gt;
&lt;p&gt;I am not saying that there is no suffering. War, famine and death are very real sufferings.&lt;/p&gt;
&lt;p&gt;True sufferings are the ones that we can all relate to.&lt;/p&gt;
&lt;p&gt;Projected sufferings are the ones that don’t fit to our vision.&lt;/p&gt;
&lt;p&gt;That being said, true sufferings or projected sufferings, we must strive to eliminate or at least mitigate them.&lt;/p&gt;</content></entry><entry><title>What should be learnt</title><link href="/what-should-be-learnt.html" rel="alternate"></link><published>2016-10-09T14:55:00+00:00</published><updated>2016-10-09T14:55:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-10-09:/what-should-be-learnt.html</id><summary type="html">&lt;p&gt;Life is but a tiny room. We can't fit a lot in it, so we have to be prudent to choose what we pick to put in the room.&lt;/p&gt;
&lt;p&gt;I believe that technical skills, while important for one to earn his keep and prove his worth, possibly even grow a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Life is but a tiny room. We can't fit a lot in it, so we have to be prudent to choose what we pick to put in the room.&lt;/p&gt;
&lt;p&gt;I believe that technical skills, while important for one to earn his keep and prove his worth, possibly even grow a passion for, should only be considered a tradecraft. A skill to function as a useful person in society.&lt;/p&gt;
&lt;p&gt;However, while we focus much on honing our techincal prowess, we seem to be forgetting a more paramount skill, that of morality, that of widsom, or to cite the 4 virtues, Prudence, Justice, Temperament and Courage.&lt;/p&gt;
&lt;p&gt;What good is it that I can control my weights in the gym, but anger controls me so easily. What good is that I can get along with my boss and people at work, but I can't get along with my conscience. What good is it that people look up to me, but i'm not at peace with myself.&lt;/p&gt;
&lt;p&gt;Work on achieving wisdom, that is life's greatest task, and one which will permeate through your entire life. If you only focus on your technical skills, your achievements will only be tied to the present. Fleeting and transient, but not to say they are not useful.&lt;/p&gt;
&lt;p&gt;Let wisdom be what you seek primarily, while practicing your tradecrafts in idle time, instead of seeking wisdom in idle time. If you do that, you most definitely won't grow wiser, only more skillful.&lt;/p&gt;</content></entry><entry><title>The layers to happiness</title><link href="/the-layers-to-happiness.html" rel="alternate"></link><published>2016-06-05T04:24:00+00:00</published><updated>2016-06-05T04:24:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-06-05:/the-layers-to-happiness.html</id><summary type="html">&lt;p&gt;We always try to find happiness. We try to seek it, as it were an object to endeavor finding. But what if it wasn't an end goal, but a by product? What if it was like a shadow, only appearing in the absence of light, it only appears in the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We always try to find happiness. We try to seek it, as it were an object to endeavor finding. But what if it wasn't an end goal, but a by product? What if it was like a shadow, only appearing in the absence of light, it only appears in the absence of suffering? If that were the case, then just as we need to find the light that creates the shadow, we need to find the sufferings to remove, in order to create happiness.&lt;/p&gt;
&lt;p&gt;Here I would explore ideas that read, which pinpoints human suffering to the struggling definition of oneself. Who am I, and what am I here for?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;I am what I have&lt;/u&gt;&lt;/strong&gt;&lt;br&gt;
In this view, we wrongly define ourselves as our material possessions. The more we own, the more we think we are elevated in societies ranks. The pursuit of wealth and material items, which like a drug, only temporarily satiates the greed of the soul, and more importantly, it know satiates your own soul. It is a selfish and blind endeavour to pursue materials in order to seek definition of oneself.&lt;/p&gt;
&lt;p&gt;You would constantly be caught in a never ending cycle of materialism, and the need to own more as old possessions lose their value. This gives rise to anxiety, something which we wish to disassociate ourselves from.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;I am what I do&lt;/u&gt;&lt;/strong&gt;&lt;br&gt;
While this definition is not as malevolent as the materialistic one, it seems to have misguided many to believe that in order to be productive, I have to be doing something, no matter what it is. We have been convinced to demonise idle time, and we're always looking for something to fill up our time with "stuff" to do. And even if we do not enjoy the things we do, we are deluded into thinking that regardless of enjoyment, the act of nonidleness is a virtue.&lt;/p&gt;
&lt;p&gt;We soldier on, always looking for things to busy our mind, to distract us from the existential crisis we choose to ignore. We get lost in work, and when we snap out of it, we get a false sense of satisfaction. This gives rise to frustration. On an idle weekend, one would beat themselves up for being "unproductive". We struggle to find mindless activities to pass time, or rather, to waste time. Such a struggle is uncalled for, and doing something for the sake of doing it to feel productive is a false lie we must stop believing in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;I am what I am&lt;/u&gt;&lt;/strong&gt;&lt;br&gt;
In the previous 2 definitions, we saw the definition of self from a materialistic perspective, and a narcissistic perspective. This final definition, and the one I believe is the most accurate one, seeks to define a person from within. Not from external powers such as owning materials and pseudo-productive activities. The ultimate aim of us all is to grow and flourish optimally, bounded within the constrains given the situation you are in. This aim should be our definition of ourselves. Do not seek to own more than you want. Do not seek to do more than you want. Own what you will. Do what you will. This is the optimal state for each of us.&lt;/p&gt;
&lt;p&gt;Frustation and anxiety arises when we struggle to own more than we want,  and do more than we want. And we do so because we are wrongly defining ourselves by the first two views. We become torn out from our basic nature,  and wrongly seek validation from the outside. Return back to your innerself. Return back to your basic nature. Who are you?&lt;/p&gt;</content></entry><entry><title>Five actions for happiness (To others and yourself)</title><link href="/five-actions-for-happiness-to-others-and-yourself.html" rel="alternate"></link><published>2016-04-19T11:16:00+00:00</published><updated>2016-04-19T11:16:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-04-19:/five-actions-for-happiness-to-others-and-yourself.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;G.R.E.A.T&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Give&lt;/li&gt;
&lt;li&gt;Relate&lt;/li&gt;
&lt;li&gt;Exercise&lt;/li&gt;
&lt;li&gt;Appreciate&lt;/li&gt;
&lt;li&gt;Teach yourself&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[&lt;strong&gt;Give&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Giving is the greatest way to achieve happiness, both to the receiver and yourself. Giving can be done in many ways, such as money, words, and even time. By giving something you have to another …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;G.R.E.A.T&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Give&lt;/li&gt;
&lt;li&gt;Relate&lt;/li&gt;
&lt;li&gt;Exercise&lt;/li&gt;
&lt;li&gt;Appreciate&lt;/li&gt;
&lt;li&gt;Teach yourself&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[&lt;strong&gt;Give&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Giving is the greatest way to achieve happiness, both to the receiver and yourself. Giving can be done in many ways, such as money, words, and even time. By giving something you have to another person, it makes everyone a little bit happier.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Relate&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Relating and connecting to someone makes the person feel cared for and loved. We humans are social creatures and we desire attention. By relating to someone and making them know we (genuinely) care about them, it makes them happier, and in turn, it makes us happy, because we care about them.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Exercise&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Not only does it improve your physical health, it also improves your mental health. You gain more confidence, and you learn to push your boundaries and break plateaus. A good exercise challenges you both physical and mentally&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Appreciate&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Gratitude. Instead of focusing on what you don't have and your weaknesses, appreciate what you already have, and your strengths. Acknowledge your achievements, and allow that to propel you forward to achieve even more. If you are constantly looking at the gap between what you have and what you want, you're forever stuck in a negative cycle of discontentment. Instead, take time to look back, and let it empower you.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Teach yourself&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Learn new skills every now and then, be it technical skills or people skills. Research well into your profession and learn new things to increase your proficiency. Learn from situations, from people, and from yourself (What pulls your strings? What motivates you? What do you like?).&lt;/p&gt;</content></entry><entry><title>Why I work</title><link href="/why-i-work.html" rel="alternate"></link><published>2016-04-18T15:48:00+00:00</published><updated>2016-04-18T15:48:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-04-18:/why-i-work.html</id><summary type="html">&lt;p&gt;After reading this book (still in progress) called Happiness by Richard Layard, it got me thinking on the subject i've been bothered for quite some time now: Why do we work?&lt;/p&gt;
&lt;p&gt;Here are a few simple points i've gathered:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I work to be a useful contributing member of the society …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;After reading this book (still in progress) called Happiness by Richard Layard, it got me thinking on the subject i've been bothered for quite some time now: Why do we work?&lt;/p&gt;
&lt;p&gt;Here are a few simple points i've gathered:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I work to be a useful contributing member of the society. I find meaning in work that I am doing my part to ensure the proper functioning of the society I am living in.&lt;/li&gt;
&lt;li&gt;I work to gain social status. As a programmer, to be labeled as one, gives me a sense of ingenuity. To feel like I am achieving something, and for personal satisfaction that the work I am engaged in is professional.&lt;/li&gt;
&lt;li&gt;I work for financial stability. To survive in the world, as well as to indulge slightly in the material joys of it. But I have to be cautious not to fall into this trap of overindulgence of material goods, for they only bring about temporary satisfaction. (Much like how you treasure your new phone on the 1st week, but throwing it on the table by the 5th.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As I wrote in my previous post, work, at least where I am right now, is an intractable reality, therefore my expectations towards it should be managed.&lt;/p&gt;
&lt;p&gt;I will not gain immense joy from it, but I should not be suffering.&lt;/p&gt;
&lt;p&gt;I can however, approach the challenges positively, knowing that every hurdle I overcome does a few thing:&lt;/p&gt;
&lt;p&gt;a) It improves the overall functioning of my company.&lt;/p&gt;
&lt;p&gt;b) It allows me to learn and pick up new skills.&lt;/p&gt;
&lt;p&gt;I should therefore focus on these things to gain a more positive attitude.&lt;/p&gt;
&lt;p&gt;Just got an idea. I should buy a notebook (I already have so many... But this is one of the material indulgence), and write down what challenges I face everyday, and how I have overcome them, and also what I have learnt from it.&lt;/p&gt;</content></entry><entry><title>Hemorrhoidectomy</title><link href="/hemorrhoidectomy.html" rel="alternate"></link><published>2016-04-18T15:20:00+00:00</published><updated>2016-04-18T15:20:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-04-18:/hemorrhoidectomy.html</id><summary type="html">&lt;p&gt;Ive always had trouble spelling that word, but after going through it last Sunday (10th April), i've been searching up and reading about it so much, especially the recovery period.&lt;/p&gt;
&lt;p&gt;I'm writing this posts now, because i've been inspired by all other posts by people who have gone through hemorrhoidectomy …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ive always had trouble spelling that word, but after going through it last Sunday (10th April), i've been searching up and reading about it so much, especially the recovery period.&lt;/p&gt;
&lt;p&gt;I'm writing this posts now, because i've been inspired by all other posts by people who have gone through hemorrhoidectomy, and the tips they provide. I feel like i'm passing the flame down. Also, for people suffering hemorrhoids in silence, please do not feel shy about it, and consult a doctor if it starts bleeding.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Background&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;I've been suffering from hemorrhoids for quite awhile now, probably about close to a year. It was one small tiny hemorrhoid that prolapsed whenever i took a dump, but it never really bothered me at all. Every time i wiped my butt, there was blood, but i took it as nothing, and simply pushed the piles back in.&lt;/p&gt;
&lt;p&gt;Until one day, it started to bleed really badly. Blood was dripping non-stop, and the entire toilet bowl was filled with blood. When i stood up, blood was dripping my butt. Obviously this prompted me to go to a hospital (Parkway East) to visit a doctor (Dr Imran Nawaz) immediately, and a surgery was schedule the following day.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Day before surgery&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;Doctor told me not to consume any food, and only to drink clear liquid. I was set to do a colonoscopy, and a &lt;strong&gt;&lt;em&gt;HEMORRHOIDECTOMY.&lt;/em&gt;&lt;/strong&gt; Those words still scare me. I was given a bottle of "Fleet" to drink, which was oral sodium phosphate. Basically, it drains water from your body, and flushes the colon out clean.&lt;/p&gt;
&lt;p&gt;Worst. Night. Ever.&lt;/p&gt;
&lt;p&gt;Every 20 mins, i was rushing to the toilet to let out jets of water out from my butt. I could hardly catch any sleep, even up till 4am. At 5:30am, a nurse came in to give me another half dosage. My surgery was scheduled to be at 9:00am.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Day of surgery&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;I was pretty calm about it. Joking and jesting with the nurses who brought me in to the surgery room (Su, Joseph and Al). It all happened to fast. I was given anesthesia, and fell straight to sleep, and the operation was performed&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[After surgery]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I woke up at about 1030am, and was still a little drowsy from the drugs. I was repeating whatever i heard from the nurses, and mimicking them. I was also telling jokes to the nurses, probably disturbing them working. Kinda embarrassing come to think of it!&lt;/p&gt;
&lt;p&gt;I was to stay in the hospital for one more night for the nurses and doctor to check my wound, in case there was any sudden bleeding, or if i felt unwell. I was promptly discharged the next day.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Day 1 -5 Post surgery&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;I can say i've never ever felt so much pain and discomfort in my life. I never knew this sort of pain was possible to a human. (Okay a little exaggerated.) Every time i had to poop, i was sweating, and my toes were clenched. I would be gritting my teeth and grabbing the walls because of the immense pain. Horrible horrible experience.&lt;/p&gt;
&lt;p&gt;After every poop i had to take a warm bath to calm myself down, and i also had to take a sitz bath, which really helped a lot with the swelling.&lt;/p&gt;
&lt;p&gt;I was constipated once, and it was so bad. Note to readers: Do not get constipated. Ever.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Moving on]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Its day 8 now as of writing this post. The pain has subsided immensely, and i can finally see the light of getting healed. Im starting to do light workouts such as squats and pull ups. I can finally sit up to get out of bed, instead of tumbling and rolling over. I can finally poop without feeling im going to faint from the pain.&lt;/p&gt;
&lt;p&gt;My follow up appointment is on next Monday, and i'm really eager to see how much i've healed by then!&lt;/p&gt;</content></entry><entry><title>Digging into happiness</title><link href="/digging-into-happiness.html" rel="alternate"></link><published>2016-04-06T14:05:00+00:00</published><updated>2016-04-06T14:05:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-04-06:/digging-into-happiness.html</id><summary type="html">&lt;p&gt;I realized that i am writing lesser now. lt appears thet somehow I find it to be a chore. Perhaps I will start writing shorter paragraphs, and more spontaneous posts. Something like tweets.&lt;/p&gt;
&lt;p&gt;These few days I have been thinking about happiness, probably due to my new job. After digging …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I realized that i am writing lesser now. lt appears thet somehow I find it to be a chore. Perhaps I will start writing shorter paragraphs, and more spontaneous posts. Something like tweets.&lt;/p&gt;
&lt;p&gt;These few days I have been thinking about happiness, probably due to my new job. After digging around and picking my brain, heres what I came up with.&lt;/p&gt;
&lt;p&gt;It all starts with dissatisfaction, an unhappiness of sorts towards something, someone or and event. We dislike the process. We dislike the outcome. We dislike our involvement in it. But where does this unhappiness stem from?&lt;/p&gt;
&lt;p&gt;It comes from the mismatch between &lt;strong&gt;reality&lt;/strong&gt; and our &lt;strong&gt;desires&lt;/strong&gt;. We desire for things to go smoothly, for our jobs not to suck, for a loving relationship, for trusting friends. But most of the time, reality is not so kind towards us, and presents us with situations that are often misaligned with our desires.&lt;/p&gt;
&lt;p&gt;So, to get satisfaction and happiness, these reality and desires must be aligned. There are two things you can do here:&lt;/p&gt;
&lt;p&gt;1) Put in effort and work hard, so that the &lt;strong&gt;realities&lt;/strong&gt; shape into your &lt;strong&gt;desires&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You want a good body, you want good grades in school, you want to make money. These things can be actualized through hardwork and effort. These realities can be formed and moulded into your desires. Lets call them &lt;strong&gt;malleable realities&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;2) Recognize that no amount of hardwork and effort can change reality, and change your desires to accept reality, and the beauty of it.&lt;/p&gt;
&lt;p&gt;The world is in a mess, world hunger and global warming plauges us. Your stubborn boss bites at you at every chance. No matter what you do, you cannot change reality. And your desires can never be met. Lets call these &lt;strong&gt;intractable realities&lt;/strong&gt;. They cannot be controlled or directed by your effort, so let them be.&lt;/p&gt;
&lt;p&gt;The key here is to understand which realities are malleable, and which are intractable. By correctly classifying realities, you can then direct your effort to the right places.&lt;/p&gt;
&lt;p&gt;There is much disappointment to be met, when you direct huge effort to an intractable reality. There is much satisfaction to be obtained, when you mould the malleable realities with effort to match your desires.&lt;/p&gt;
&lt;p&gt;As for me now, my job seems... like an intractable reality. I can either change my desires and expectations of the job, or mould reality, and find another that meets my desires.&lt;/p&gt;</content></entry><entry><title>The stresses at work</title><link href="/the-stresses-at-work.html" rel="alternate"></link><published>2016-03-08T15:25:00+00:00</published><updated>2016-03-08T15:25:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-03-08:/the-stresses-at-work.html</id><summary type="html">&lt;p&gt;Does it motivate me?&lt;/p&gt;
&lt;p&gt;Do I wake up dying to go to work, or rather die than go to work?&lt;/p&gt;
&lt;p&gt;Is the process avoidable, or is there anyway I can improve it?&lt;/p&gt;
&lt;p&gt;No. No. No.&lt;/p&gt;
&lt;p&gt;I'm currently reading up on the tradeoffs for high-paying high-stress job, for a low-paying low-stress …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Does it motivate me?&lt;/p&gt;
&lt;p&gt;Do I wake up dying to go to work, or rather die than go to work?&lt;/p&gt;
&lt;p&gt;Is the process avoidable, or is there anyway I can improve it?&lt;/p&gt;
&lt;p&gt;No. No. No.&lt;/p&gt;
&lt;p&gt;I'm currently reading up on the tradeoffs for high-paying high-stress job, for a low-paying low-stress job.&lt;/p&gt;
&lt;p&gt;Will I be willing to take the pay cut?&lt;/p&gt;
&lt;p&gt;Maybe.&lt;/p&gt;
&lt;p&gt;At the same time, i'm starting to discover myself more.&lt;/p&gt;
&lt;p&gt;Working under deadlines, having to face multiple bosses, a dreaded 8:15 - 17:45 lifestyle (The only time I see the sun is during my lunch break). Do I enjoy this lifestyle?&lt;/p&gt;
&lt;p&gt;Maybe not.&lt;/p&gt;
&lt;p&gt;After hearing a respected speaker for Staff Working say this phrase: "That's where my youth went to." It makes me afraid.&lt;/p&gt;
&lt;p&gt;I don't like it here, but will I be willing to take the jump?&lt;/p&gt;
&lt;p&gt;This is probably my first crossroad as an adult, where I have to make a mature decision. One that will alter the course of my life.&lt;/p&gt;
&lt;p&gt;It's one of the many crossroads I will face, and I hope I make the wise decision.&lt;/p&gt;
&lt;p&gt;This will definitely be an experience.&lt;/p&gt;</content></entry><entry><title>The Gusto for life</title><link href="/the-gusto-for-life.html" rel="alternate"></link><published>2016-02-09T10:31:00+00:00</published><updated>2016-02-09T10:31:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-02-09:/the-gusto-for-life.html</id><summary type="html">&lt;p&gt;How do you stay motivated in life? It constantly berates you, constantly throws repulsive things at you. Occasionally it gives you a flower and a lovely sight, but most of the time, believe me you, you'll be in a shit hole. So how does one stay positive in such a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;How do you stay motivated in life? It constantly berates you, constantly throws repulsive things at you. Occasionally it gives you a flower and a lovely sight, but most of the time, believe me you, you'll be in a shit hole. So how does one stay positive in such a situation?&lt;/p&gt;
&lt;p&gt;Well here are a few things we know:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Life's a bitch.&lt;/li&gt;
&lt;li&gt;You're a motherfucking badass.&lt;/li&gt;
&lt;li&gt;Badasses don't take shit from a bitch.&lt;/li&gt;
&lt;li&gt;Badasses fuck bitches up.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Yes, we fuck shit up.&lt;/p&gt;
&lt;p&gt;&lt;img alt="dfdcc5ac07ad9de7f5c5f360e878ae330d83b52a7d10b99f120211f8738a51e3" class="alignnone size-full wp-image-307" height="330" src="https://jayhayche.files.wordpress.com/2016/02/dfdcc5ac07ad9de7f5c5f360e878ae330d83b52a7d10b99f120211f8738a51e3.jpg" width="440"&gt;&lt;/p&gt;
&lt;p&gt;So, now we have our actions on what badasses like us do, lets revisit our predicament again: &lt;strong&gt;We're in a shit hole called life.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's hard to succeed in life, and entirely up to luck. Given the current world population and wealth distribution, you're statistically more likely to be born in a place where you're almost going to fail (as defined from a purely societal construct). So how do we fuck this plan life has for us? A plan for suffering and failure, a plan for destitute and agony? Simple: We point our middle fingers at it, and proceed to &lt;strong&gt;Succeed the shit out of life &lt;/strong&gt; like the rebels we are.&lt;/p&gt;
&lt;p&gt;Anarchy!&lt;/p&gt;
&lt;p&gt;Chaos!&lt;/p&gt;
&lt;p&gt;Life's plan is so hard, it's so easy and normal to just fail. We accept failure. We're told to accept failure. Fuck that. Succeed at all cost. (within legal and moral limits). Fuck life up not by drugs. Doing drugs is easy. Fuck life up by succeeding, because that's life on hard mode.&lt;/p&gt;
&lt;p&gt;&lt;img alt="72ec517e529b2aa68a13a5fe13f521c3" class="alignnone size-full wp-image-321" height="208" src="https://jayhayche.files.wordpress.com/2016/02/72ec517e529b2aa68a13a5fe13f521c3.jpg" width="236"&gt;&lt;/p&gt;</content></entry><entry><title>Identification of Personalities</title><link href="/identification-of-personalities.html" rel="alternate"></link><published>2016-01-26T14:13:00+00:00</published><updated>2016-01-26T14:13:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2016-01-26:/identification-of-personalities.html</id><summary type="html">&lt;p&gt;[Idea taken from Unlimited Power by Anthony Robbins]&lt;/p&gt;
&lt;p&gt;I recently finished reading this book by Anthony Robbins, called Unlimited Power. It teaches a lot of personal mastery techniques which, surprisingly to my highly skeptical nature, actually works!&lt;/p&gt;
&lt;p&gt;Here are a few high level abstractions of the lessons he taught:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;[Changing …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;[Idea taken from Unlimited Power by Anthony Robbins]&lt;/p&gt;
&lt;p&gt;I recently finished reading this book by Anthony Robbins, called Unlimited Power. It teaches a lot of personal mastery techniques which, surprisingly to my highly skeptical nature, actually works!&lt;/p&gt;
&lt;p&gt;Here are a few high level abstractions of the lessons he taught:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;[Changing your internal representation:]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;This lesson was really interesting, because all of us already have internal representations of things, events and people. Also, when new experiences come in, when we meet new people, we form representations of them based on our &lt;strong&gt;previous&lt;/strong&gt; experiences and &lt;strong&gt;prior&lt;/strong&gt; internal representations. So this thing about internal representations is actually really power, thus, knowing how to control it, and tweak it to have &lt;strong&gt;positive&lt;/strong&gt; internal representation of certain things would be immensely helpful.&lt;/p&gt;
&lt;p&gt;[Example:]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;"I dislike my work. I feel that work stressed me out. At the end of the day, I feel extremely tired and unfruitful." For the most of us, that is our current internal representation. So when we go to work, we are casting a &lt;strong&gt;brand new day&lt;/strong&gt; into this negative internal representation. By breaking this internal representation and casting it into a &lt;strong&gt;positive internal representation&lt;/strong&gt;, we will be able to face our challenges in a new way.&lt;/p&gt;
&lt;p&gt;&lt;p style="padding-left:30px;"&gt;
2.  [Pattern Breaking:]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;We are creatures of habit. When we do something, it is mostly likely because it is a habit. This action can be brought over from other events, as the habit is a manifestation of your inner psychology. You over-eat, you over-sleep, you over-do-stuff. This pattern repeats itself over and over again, each time &lt;strong&gt;reinforcing&lt;/strong&gt; this pattern, strengthening the connections within your brain that you &lt;strong&gt;must &lt;/strong&gt;do some actions, when presented with a certain situation. To break this negative cycle, we have to perform &lt;strong&gt;pattern breaking&lt;/strong&gt;. Its pretty simple: confuse the mind. Form new neurological paths when presented with this situation. Do something you've never done before when you face a common vice. Do something &lt;strong&gt;REALLY&lt;/strong&gt; powerful and weird to shock the brain. Feel like smoking? Throw the cigarette on the floor and do a Haka dance and smash it all up.&lt;/p&gt;
&lt;p&gt;[Example:]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;"I'm always feeling sad. When I feel sad, I feel even more helpless and sadder that I can't do anything about it. I feel depressed I can't cheer up." Caught in this cycle? Burst out into laughter. Do a cheerful crazy dance. Go out and sprint as hard and fast as you can, and smile while doing it. These things break the pattern of spiralling sadness. (True story)&lt;/p&gt;
&lt;p&gt;&lt;p style="padding-left:30px;"&gt;
3.  [How to identify a personality:]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;What I feel is the most important lesson from this book, the seven indicators to identify a personality. There won't be any examples for this one because they are pretty self explanatory. Here they are:&lt;/p&gt;
&lt;p&gt;Are you moving towards, or moving away?&lt;/p&gt;
&lt;p&gt;When you perform an action, do you do it because you want to avoid something, or because you want to achieve something? Do you work because you want to grow as a person, or do you wish to avoid living in poverty?&lt;/p&gt;
&lt;p&gt;Do you have a strong internal or external frame of reference?&lt;/p&gt;
&lt;p&gt;How much weight do you put on other people's words? How much weight do you put on your words? If someone said you did a bad job, but you felt you did amazing, would he affect your judgement?&lt;/p&gt;
&lt;p&gt;Do you sort by self or sort by others?&lt;/p&gt;
&lt;p&gt;How oriented are your actions towards to others? Do you do things for the betterment of the group? Or do actions always have to have some form of personal gain?&lt;/p&gt;
&lt;p&gt;Are you a matcher or a mis-matcher?&lt;/p&gt;
&lt;p&gt;When you first see two objects/people, do you first identify their similarities, or their differences? Do you find what contrasts them, or how do they complement each other?&lt;/p&gt;
&lt;p&gt;What does it take to convince you?&lt;/p&gt;
&lt;p&gt;If I told you someone was good at something, what does it take to convince you? Do you have to see him perform it yourself? If so, how many times does he have to do it in-front you before you conclude he is really good at it?&lt;/p&gt;
&lt;p&gt;Do you seek possibilities or necessities?&lt;/p&gt;
&lt;p&gt;Do you find possibilities in your work and life, or do you find necessities? Are you exploratory and find creative means to live your life, or are you satiated with the bare minimum of necessities?&lt;/p&gt;
&lt;p&gt;Are you independent or a group worker?&lt;/p&gt;
&lt;p&gt;Do you like working alone, or in a group? Do you prefer to make your own decisions, or get another person's assurance before doing something? This could be a hybrid, where you get advice from people, but you end up doing the actual work yourself.&lt;/p&gt;
&lt;p style="padding-left:30px;"&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Okay, that's all the lessons I can remember, or bother to type out. It's a really good book if you wish to explore yourself more. These books usually sell themselves as you suddenly being able to break out into a marvellous new person. Not a chance. But there are some golden nuggets there you can pick out, and these are the few I picked :)&lt;/p&gt;</content></entry><entry><title>The I in Me</title><link href="/the-i-in-i.html" rel="alternate"></link><published>2015-12-20T13:59:00+00:00</published><updated>2015-12-20T13:59:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-12-20:/the-i-in-i.html</id><summary type="html">&lt;p&gt;Okay, i think i'm gonna update my blog more often now. And by more often i mean at least once a month. I find i always have all these thoughts in my mind that makes me question many things, but after i get home and play a few rounds of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Okay, i think i'm gonna update my blog more often now. And by more often i mean at least once a month. I find i always have all these thoughts in my mind that makes me question many things, but after i get home and play a few rounds of DOTA, i instantly forget them.&lt;/p&gt;
&lt;p&gt;Without further ado, the topic i thought about today while cycling was the concept of I. Me. Self. So i within my own reasoning and thought process, i came up with this high level abstraction:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Capture" class="alignnone size-full wp-image-155" height="462" src="https://jayhayche.files.wordpress.com/2015/12/capture.png" width="654"&gt;&lt;/p&gt;
&lt;p&gt;So we have the overarching "I", which is just a word thrown around in conversations.&lt;/p&gt;
&lt;p&gt;It then splits down into two "I"s, the "I" in relation to others, and the "I" in relation to self.&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;"I" in relation to others&lt;/strong&gt;]{style="text-decoration:underline;"}&lt;/p&gt;
&lt;p&gt;When a tree falls in the forest, and nobody hears it fall, does it make a sound?&lt;/p&gt;
&lt;p&gt;I'm going to give my own answer here and say: No. (Spare me the philosophical arguments, i'm making another point here)&lt;/p&gt;
&lt;p&gt;So why doesn't it make a sound? Because no one is there to observe it fall. No one is there to internalize the vision and the sound of a falling tree. No one &lt;strong&gt;experiences&lt;/strong&gt; it. And i think that's the crux of the issue, the human experience of things that makes things "exists"&lt;/p&gt;
&lt;p&gt;Now, if a human lives on earth, and it impact no one at all, does it still exist?&lt;/p&gt;
&lt;p&gt;Again from my own argument:No! It may be a living thing going about its daily life, but if it doesn't impact others, and doesn't create &lt;strong&gt;positive experiences &lt;/strong&gt;for others, then it's existence is insignificant. Note that i emphasized on positive, for if it were negative, people would wish we never existed in the first place.&lt;/p&gt;
&lt;p&gt;With this argument, i'm &lt;strong&gt;not&lt;/strong&gt; saying that unless we make an incredibly huge impact like Bill Gates or Ghandi, we're non-existent. As long as we impact the people around us in our daily lives in a positive way, we are existing wholly and fully. As long as we always create positive experiences for others, we will forever exist in the impermanence of their memories, no matter the fate of our physical bodies. Here's a nice post written by Frank Yang on our own self value on our own life.&lt;/p&gt;
&lt;p&gt;https://www.instagram.com/p/-xJmQGkJO2/?taken-by=being_frank_yang&lt;/p&gt;
&lt;p&gt;This is how the "I" in relation to others arises to existence. Through our deeds and actions that impact them. Our birth is significant, because of what lies ahead of us. Our death is significant, because of what lies behind us.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[The "I" in relation to self]{style="text-decoration:underline;"}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The "I" in relation to self splits off into two areas: the "I", and the self. Is there a difference? From what i thought of, yes.&lt;/p&gt;
&lt;p&gt;The "I" that we hold to ourselves the inner self that we use to interact with the outerworld. "I" am feeling hungry. "I" am feeling tired. "I" am feeling stressed. This "I" is highly reactive to the surroundings, and is very primitive.&lt;/p&gt;
&lt;p&gt;The Self however, is something deeper. It's where your morals and values reside. These things are less reactive, and are likely to stay the same regardless of the environment.&lt;/p&gt;
&lt;p&gt;Our focus should therefore lie on the Self, and not the malleable "I". We have to build our inner foundation and strengthen it to live as a person with morals.&lt;/p&gt;
&lt;p&gt;At times we act on the "I", which receives inputs from the external world, and this causes a conflict with our Self. Therein arises guilt and remorse. As the saying goes&lt;/p&gt;
&lt;p&gt;&lt;img alt="check" class="alignnone size-full wp-image-196" height="473" src="https://jayhayche.files.wordpress.com/2015/12/check.jpg" width="625"&gt;&lt;/p&gt;
&lt;p&gt;"Check your&lt;strong&gt;SELF"&lt;/strong&gt;. Which means before you act on the highly reactive "I", you need to take a step back and understand that the "I" is dynamic. Check on your Self. Does it conflict with the inner Self?&lt;/p&gt;
&lt;p&gt;That said, the "I" is not all bad. I think this "I" could represent the gut feeling, which is sometimes a good thing to act upon.&lt;/p&gt;
&lt;p&gt;Alright that's all the arguments and theories I thought about today. Until the next time i start thinking about stuff again.&lt;/p&gt;</content></entry><entry><title>Long term goals and Short term decision dichotomy</title><link href="/long-term-goals-and-short-term-decision-dichotomy.html" rel="alternate"></link><published>2015-09-06T05:43:00+00:00</published><updated>2015-09-06T05:43:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-09-06:/long-term-goals-and-short-term-decision-dichotomy.html</id><summary type="html">&lt;p&gt;When we talk about goal setting, we have our Long term goals that we want to achieve within a certain period of time. The long term goal achievement rate is highly correlated to our short term decision making. However, &lt;strong&gt;the persistent separation of these 2 items can have detrimental effects …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;When we talk about goal setting, we have our Long term goals that we want to achieve within a certain period of time. The long term goal achievement rate is highly correlated to our short term decision making. However, &lt;strong&gt;the persistent separation of these 2 items can have detrimental effects on you achieving your goals as a whole&lt;/strong&gt;. We should therefore align our short term decision making with our long term goals, and in this way, they both complement each other.&lt;/p&gt;
&lt;p&gt;A long term goal would be something you want to achieve in 10 years, or 20 years time. These could be things like saving for retirement, buying a house or a car, or saving for you children's education. A long term goal can also lie within a year, where the goal is to get healthy, or achieve good grades in their final exams.&lt;/p&gt;
&lt;p&gt;Short term decisions are tiny milestones we have that bring us closer towards the long term goal. They could be things like choosing your meals for the day, deciding on what to buy. The devil lies in the short term decision making, because we are influenced by many factors that will cloud our decision. The main game-breaker is the feeling of instant gratification.&lt;/p&gt;
&lt;p&gt;Say we have a goal to lose weight within the next year. The goal set has been &lt;strong&gt;Specific, Measurable, Attainable, Realistic, and Time-bound (SMART framework)&lt;/strong&gt;, and all is set for you to go and achieve it. From now till the next year, countless of decisions will be made, many of which will affect the success factor of the long term goal. Of which they are things like should I head out for an exercise today because the weather is too hot? Should I eat fast-food because the canteen is too crowded? Should I skip a meal because there is too much work to do? As we start to allow instant gratification to influence our short term decision making, it starts to accumulate and fester, and soon enough, you will forget the goal you had in the first place.&lt;/p&gt;
&lt;p&gt;The way to overcome and &lt;strong&gt;block out instant gratification from clouding our short term decision making, is to use short term reasoning&lt;/strong&gt;. We can always reason to ourselves that a fast food today won't hurt, skipping just one running session won't do any harm, or sleeping in for a day is perfectly fine. These will lead to the brain learning the behavior of "Oh, I skipped running last week, and it felt perfectly fine, therefore skipping it this week would be absolutely fine as well." Here, instant gratification of "feeling perfectly fine" clouds our decision making.&lt;/p&gt;
&lt;p&gt;We should start to reason in ways that are aligned with our long term goal. Do not reason to yourself that "Skipping a run will make me feel comfortable at home", or "eating fast-food is convenient due to the crowd". These are thoughts of instant gratification. Instead, reason to yourself that "Running will clear my mind, and make me feel refreshed throughout the day", or "eating fast food will lead me to feel extremely tired and groggy later on, due to the high fat content," "Drinking a can of sugar drink will lead me to have a sugar crash later on in the day". &lt;strong&gt;These short term reasons and short term incentives are aligned with your long term goal of losing weight&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Instead of having the mentality that doing the right thing is hard, "Buying a salad is expensive","running takes up time and it's hot","eating the right food is difficult to choose", we should change our thinking entirely, such that doing the right thing is perfectly reasonable. "Buying a salad is healthy and keeps me refreshed","Running clears up my mind and allows me to destress","eating the right food is cheaper than fast food". If we constantly think that the right thing to do is hard, and we have to come up with reasons to do it, our brain will eventually think that doing the right thing is wrong.&lt;/p&gt;
&lt;p&gt;Therefore, &lt;strong&gt;we should not think of reasons why, but reasons why not&lt;/strong&gt;. If we change our short term decision making by removing instant gratification with positive reasoning, we will be on the right track. &lt;strong&gt;Come up with short term incentives to entice the brain to do the right thing&lt;/strong&gt;. If we allow instant gratification to influence our short term decisions, and we come up with reasons not to do it, we will eventually fail.&lt;/p&gt;</content></entry><entry><title>Three pins to two holes</title><link href="/three-pins-to-two-holes.html" rel="alternate"></link><published>2015-05-11T17:19:00+00:00</published><updated>2015-05-11T17:19:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-05-11:/three-pins-to-two-holes.html</id><summary type="html">&lt;p&gt;Know that this world was not made to accomodate you. Not everything will go according to your plan. Not all of your hopes will come true. Not everyone will like you.&lt;/p&gt;
&lt;p&gt;Reality is truely different from how we wish it to be, and often it can be hurting. We may …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Know that this world was not made to accomodate you. Not everything will go according to your plan. Not all of your hopes will come true. Not everyone will like you.&lt;/p&gt;
&lt;p&gt;Reality is truely different from how we wish it to be, and often it can be hurting. We may feel agitated, regret, and anger, but we must always remember, we were born out of the circumstances of the world, and we are subjects to these circumstances. We may try to control it and manipulate it, but in the end, we will lose.&lt;/p&gt;
&lt;p&gt;The hardest part of it all is acceptance. To accept and humble ourselves that we were wrong in our views. To accept that some of our hopes can never be realized. To accept that we are wrong, and no matter how much effort we put in, we must accept that there is a possibility of it have no result. That is what we must accept. No amount of motivation or determination will allow you to achieve everything that you want. If hardwork and determination always guaranteed success, then a hardworking mule would be the king of the jungle, instead of the worthy lion.&lt;/p&gt;
&lt;p&gt;We are just like 3 pin plugs, and not all sockets in the world have 3 holes. We will not be able to fit into every socket, but for those that we do, we must treasure and appreciate dearly. Not all sockets were made for us, and we were not made for all sockets. Trying forcible to fit into a 2 holed socket would only cause nothing but damage. You would never succeed.&lt;/p&gt;
&lt;p&gt;I believe the greatest lie told to mankind was that you would always succeed if you put in effort. That is why we have so many people who cannot accept rejection and failure. Instead, we must teach the people that rejection is part of life, and it is only through rejection that we know our place.&lt;/p&gt;
&lt;p&gt;We are creatures of failure, but it is imperative that we fail, for it is where we learn the grratest lessons from.&lt;/p&gt;</content></entry><entry><title>"Finding meaning and purpose in our lives -- importance of hope and idealism" Seeing more in others</title><link href="/finding-meaning-and-purpose-in-our-lives-importance-of-hope-and-idealism-seeing-more-in-others.html" rel="alternate"></link><published>2015-05-11T04:35:00+00:00</published><updated>2015-05-11T04:35:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-05-11:/finding-meaning-and-purpose-in-our-lives-importance-of-hope-and-idealism-seeing-more-in-others.html</id><summary type="html">&lt;p&gt;https://youtu.be/p9sMoRUJQGA&lt;/p&gt;
&lt;p&gt;I find this video holding a lot of truth to it. It says that if we see someone for who they actually are, we are not doing justice to them. We are taking them merely at face value, which holds very little information or moral description …&lt;/p&gt;</summary><content type="html">&lt;p&gt;https://youtu.be/p9sMoRUJQGA&lt;/p&gt;
&lt;p&gt;I find this video holding a lot of truth to it. It says that if we see someone for who they actually are, we are not doing justice to them. We are taking them merely at face value, which holds very little information or moral description. If we take someone only for who they are, be it physically or merely by their occupation, we are overlooking the vast complexity of thoughts and potentials in their life. That is to say, if i told you i am a student, and you proceed to form judgements and perspectives solely based on that fact, it would do me absolutely no justice. Like the plane, if we only look straight ahead for who a person is, we will end up reaching a low level of conclusion.&lt;/p&gt;
&lt;p&gt;We must therefore take people for more than who they are, more than what we see in them. If we see a student, we must look deeper and appreciate their complexity of life and thoughts. When we do that, we will see who they really are, just like reaching the destination if we look higher to compensate for the crosswinds.&lt;/p&gt;
&lt;p&gt;This can be said to be not judging a book by its cover, but i think that it covers a broader area which says that, we must proactively assume people to be of a higher value. Once we someone to be greater, it automatically diffuses into their subconscious, and they will feel confident about their skills and character, thus making it a self fulfilling prophecy. If we constantly put someone down and look lowly of them, it will eat away at their soul, making them regress deeper into your negative views.&lt;/p&gt;
&lt;p&gt;In short; everyone around you is a teacher and greater than what you percieve, and you should make it known to them. (But caution not to make it excessive flattery)&lt;/p&gt;</content></entry><entry><title>The separation of Primal wants with Moral needs</title><link href="/the-separation-of-primal-wants-with-moral-needs.html" rel="alternate"></link><published>2015-04-25T16:12:00+00:00</published><updated>2015-04-25T16:12:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-04-25:/the-separation-of-primal-wants-with-moral-needs.html</id><summary type="html">&lt;p&gt;Part of me connects with the universe, understanding that the human life is fleeting and insignficant, that life should never be taken so seriously, because in the end, no one remembers the trivial bickerings but your own memory, which disappears with you as you perish in this vast planet floating …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Part of me connects with the universe, understanding that the human life is fleeting and insignficant, that life should never be taken so seriously, because in the end, no one remembers the trivial bickerings but your own memory, which disappears with you as you perish in this vast planet floating in the eternal abyss of cosmological darkness.&lt;/p&gt;
&lt;p&gt;This cosmological connection i have makes me adopt the attitude of alturism, knowing that since my time is limited, i must be perfection, or at least try to be. I strive for knowledge and justice, for they are the eternal constants in this impermanat world. That is the Moral need that i adopt, because it is a neccesity as a living human. The world has given us life, and we must uphold its sanctity. I love everyone, because everyone suffers the same predicament as me, and not everyone is aware of it. Which brings me to my other self, the Primal wants.&lt;/p&gt;
&lt;p&gt;Those who indulge in their Primal wants, materialism, mediocre media indulgence, sex and alcohol, petty menial bickerings, fail to see the Moral needs that they need to adopt. And sometimes i indulge in my Primal wants as well, because i am only human. I judge people, i get irritated, i do things of folly, i get emotionally charged and do foolish things that hurt others. And at the end of the day, when i get in touch with my other self, i feel a wave of regret. That is because the Primal wants and Moral needs currently lie in ditchotomy for me. I need to find a way to amalgamate them together as great men did. Where the causes of great men were also their Primal wants, and  not moments of motivation. That is true greatness, and that is what i, and everyone else should strive for. The Primal-Moral essence.&lt;/p&gt;</content></entry><entry><title>The Self-Competition</title><link href="/the-self-competition.html" rel="alternate"></link><published>2015-04-09T15:46:00+00:00</published><updated>2015-04-09T15:46:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-04-09:/the-self-competition.html</id><summary type="html">&lt;p&gt;The world is absolutely relative. Kind of an oxymoron, but absolutely true. We find no worth in things, unless it is relative to something else. There needs to be a comparison to show the contrast, to show the greater value over something. Relativity thus requires at least one object in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The world is absolutely relative. Kind of an oxymoron, but absolutely true. We find no worth in things, unless it is relative to something else. There needs to be a comparison to show the contrast, to show the greater value over something. Relativity thus requires at least one object in comparison to be the "losing" one in someway or another.&lt;/p&gt;
&lt;p&gt;If we have an abundance of something, with nothing to compare it to, the value will no longer be recognized. It can no longer stand out amongst the mass of substandard goods, and we hold no relativistic value to it. With that in mind, we as humans also hold a certain value. Although it is morally questionable to put down one humans value relative to another, it is done all the time. And in many cases, it is ourselves who perform this relative value assessment through introspection.&lt;/p&gt;
&lt;p&gt;To us, our worth is measured, broadly classified, in four areas:&lt;/p&gt;
&lt;p&gt;1) Professional&lt;br&gt;
2) Social&lt;br&gt;
3) Spiritual&lt;br&gt;
4) Romance&lt;/p&gt;
&lt;p&gt;The intersection of these 4 areas collectively leads to the 5th element which we humans value so much: Self-esteem. We hold certain beliefs about ourselves, how good we are, how much we're worth, and how valuable we are to people. But these measurements mean absolutely nothing if measure alone. Without relative measurements of skills, social connections and love, we will never know where we stand, or how good is our good. Therefore, our self-esteem is also measured relativistically with other people.&lt;/p&gt;
&lt;p&gt;We always seem to be caught in comparison with someone else, and that gives us a certain goal we will work towards. We compare ourselves with the rich, and strive towards their statuses. We compare ourselves with the smart, and work towards their intelligence. We compare ourselves to the less fortunate, and become satisfied with our current situation. But more often than not, we find ourselves unhappy when comparing against others. Even once we reach the desired status, we feel the need to compare ourselves with another higher goal to validate ourselves. It then becomes a never ending cycle of comparison.&lt;/p&gt;
&lt;p&gt;There are millions of people out there we can compare ourselves to, and we have to realize that comparing and competing with others is inherently toxic. It brings us only temporary joy when we equal or best our reference. It gives us a fleeting moment of bliss, but it quickly disappears and gets consumed by another person to compare with. We become unable to reach a satiated state, but forever trapped in the carrot-chasing limbo of achieving something. Comparison can be healthy in some ways. It motivates us to do something about ourselves, but when there no end in sight, we must break out of the cycle. We must first compare with ourselves.&lt;/p&gt;
&lt;p&gt;Instead of competing and looking outward towards the world and their achievements, we should first recognize our own achievements, and set to overcome them. We should view our past selves as separate entities to defeat and to overcome, and every day is an opportunity to do so.&lt;/p&gt;
&lt;p&gt;Physically: Become stronger, healthier and more active. Take care of your body. Eat right, sleep right and be productive in your movements.&lt;br&gt;
Mentally: Become smarter. Become knowledgable. Read areas you have never heard of before. Real about the world and it's history. Read about the great people and learn from them.&lt;br&gt;
Socially: Make more friends. Talk to strangers. Be able to express yourself and your ideas. Reach out to people who need help. Connect with old friends, revitalize existing ones.&lt;/p&gt;
&lt;p&gt;There are so many more realms we can cover, and it is up to you to decide which part of you that you wish to overcome. Do not be intimidated by others, for they are not you, nor you they. look inwards. There you will find the most important questions, and only you can come up with the most relevant answers.&lt;/p&gt;</content><category term="competition"></category><category term="improvement"></category><category term="self"></category></entry><entry><title>Our life is a stage.</title><link href="/our-life-is-a-stage.html" rel="alternate"></link><published>2015-02-15T16:27:00+00:00</published><updated>2015-02-15T16:27:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-02-15:/our-life-is-a-stage.html</id><summary type="html">&lt;p&gt;Our life is a stage. A play directed and acted by us and us alone. We are the main characters in our play, and all the other people in our lives are calefares. Sure, there are some really important people in your life, like family, friends and lovers. They are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Our life is a stage. A play directed and acted by us and us alone. We are the main characters in our play, and all the other people in our lives are calefares. Sure, there are some really important people in your life, like family, friends and lovers. They are not main characters, but important characters that influences how you direct and act out your play. Ultimately, you are in control of everything.&lt;/p&gt;
&lt;p&gt;Holding that view, we must almost understand that everyone else has their own stages, and in their stage and play, &lt;em&gt;YOU &lt;/em&gt;are the calefare. You may be an important character in some people's play, or you may be a fleeting character, that comes and goes as quick as the wind. It is necessary to understand this, as it gives us a deeper understanding of how and why others act differently, and it is simply because they are in their stage, and you are in yours. Different directors, different settings, different scenarios. Other times, it may also be the &lt;em&gt;other&lt;/em&gt; person who is confused by your actions, and you must know that perhaps it is because &lt;em&gt;he&lt;/em&gt; is not in your stage, and therefore you cannot assume he knows the reasons for your actions in entirety.&lt;/p&gt;
&lt;p&gt;In some cases, as lovers or with people you really care about, you may want to enter their stage as a main character. You may wish to want to stay longer in their stage and act out the important parts in their play. But it is ultimately &lt;em&gt;their&lt;/em&gt; stage, and some people will let you stay, while others will not, and you &lt;em&gt;MUST&lt;/em&gt; accept their decision, because it is not your stage! We may think and reminisce about the play, just like how we think about a movie we have just watched. But in the end we must move on to our own stage. It is therefore empowering to know that &lt;em&gt;YOU &lt;/em&gt;have that exact same power in your stage. Remove the bad actors! Remove the naysayers! Remove the hecklers! Leave behind only those who appreciate your play.&lt;/p&gt;
&lt;p&gt;Our live should therefore be aimed towards perfecting our play. Making our show as interesting as possible. As lively as possible. The more interesting your show is, the more people will come to watch it. We must focus on our stage, and do our best to create the best scenes. Do not criticize other people's stage. Do not destroy other people's stage, Do not be so bothered in other people's stage that you neglect your own. Tend to your play, because when the curtains fall, people will throw flowers at it, and the curtains will never open again.&lt;/p&gt;</content><category term="Life"></category><category term="people"></category><category term="self"></category><category term="society"></category></entry><entry><title>On Governance</title><link href="/on-governance.html" rel="alternate"></link><published>2015-01-27T14:26:00+00:00</published><updated>2015-01-27T14:26:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2015-01-27:/on-governance.html</id><summary type="html">&lt;p&gt;The more incessant the denigration of government and duty, the quicker the domino pieces would fall, with the last and cardinal piece being the very defense of the nation.&lt;/p&gt;
&lt;p&gt;Pillars such as economics and social stability will be shaken in the absence of national identity, when you start hearing people …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The more incessant the denigration of government and duty, the quicker the domino pieces would fall, with the last and cardinal piece being the very defense of the nation.&lt;/p&gt;
&lt;p&gt;Pillars such as economics and social stability will be shaken in the absence of national identity, when you start hearing people saying they would not fight for their own country. Even if the threat of conventional war is minimal in this day and age, the nation must have a certain level of conviction and pride in their own land they were born in. Your parents brought you to the world, and we are grateful for them. So why is it that we are not grateful for the country that brought us up?&lt;/p&gt;
&lt;p&gt;There is already a substantial amount of hate and anger from the population towards the leaders of this country. We nitpick on trivial issues, shooting the government down at every opportunity we can. Train break downs, fare hikes and other matters that hinder us only slightly are the loudest talking points for the population.&lt;/p&gt;
&lt;p&gt;When most of the people scoff at government sector jobs, mocking it as lacking ambition. When people don't understand the notion of purpose towards an ideal, and everything they work on is for personal gain. When people seek not what they can do for the society, but is constantly complaining about and criticizing the system. That is when society begins to become unstable.&lt;/p&gt;
&lt;p&gt;There is constant comparison to the western ideas, and the western policies. I would say that those policies and ideas were made for a liberal country and for liberal minded people. And i would also go another step to say that Singapore is not entirely liberal, but pseudo-liberal. Those policies and ideas would not be effective here.&lt;/p&gt;
&lt;p&gt;What is missing from us is national pride. How many of us hang the national flag outside our houses on national day? How many of us are able to recite the national anthem? How many of us are truly concerned about the defense of the nation? Most of us are not even remotely proud about our country, and they view Singapore as a stepping stone to a bigger global stage. What this leaves is with is a population looking away from Singapore, even though they are in it.&lt;/p&gt;
&lt;p&gt;It is therefore the duty of the government to instill a national pride into the people. To create a place that we are proud of, and that we want to show off. To move away from the profit making agendas and discover more of the peoples wants and needs. But all of that is not possible only from one side. It takes two hands to clap, and actions from the government alone will not change the society, because the government IS the society. We cannot wrongly view the government as at the top of the ladder, and that all the actions trickle down in a diminishing fashion to the people. That dichotomic view of governance is wrong. The government is not in charge of the people, but they are supposed to be a representative of the people, which leads us to a sad case when the people themselves have no faith in the government, and what is reflected are faithless policies. When the people are greedy and selfish and hateful. When we bicker on unintelligent issues, least to say in an unintelligent way. The people in power are the very same people you sit beside the train. The only difference is our job scope, and maybe much about the pay controversially so.&lt;/p&gt;
&lt;p&gt;That is to say, to even speak of changing the way the government is running, we have to change ourselves first. We have to change our expectations, our selfish way of thinking only about profitability, our bickering about ridiculously trivial things. The people gets the government they deserve. In a corrupted country, you get a corrupted government. In a liberal country, you get a liberal government. And in a money minded country, you get a money minded government. Its is never the case where it is the other way around, where a corrupt government creates a corrupt country. Corrupted officials in Singapore are promptly removed, and that is commendable. It shows that they do not influence the general population to their believes. The only other time this was done was by a man named Adolf Hitler, but even in his case, the people already held steadfast believes that were in tune with his.&lt;/p&gt;
&lt;p&gt;Therefore, to see a change in the government, we have to change ourselves. If we bring in a government with the perfect ideals, but it conflicts with ours, we would not accept him, and that ultimately defeats the purpose.&lt;/p&gt;</content><category term="governance"></category><category term="government"></category><category term="society"></category></entry><entry><title>Swimmers Body Illusion.</title><link href="/swimmers-body-illusion.html" rel="alternate"></link><published>2014-05-14T14:13:00+00:00</published><updated>2014-05-14T14:13:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2014-05-14:/swimmers-body-illusion.html</id><summary type="html">&lt;blockquote&gt;
&lt;h2 id="theswimmers-body-illusion.--rolf-dobelli" style="color:#c9d9fb;"&gt;The Swimmers Body Illusion. - &lt;a href="http://www.dobelli.com/"&gt;Rolf Dobelli&lt;/a&gt;&lt;/h2&gt;
&lt;/blockquote&gt;
&lt;p&gt;Are swimmer's body good looking because of their constant swimming activities? Or do they excel in swimming because of their good physic? It is important not to confuse the cause with the effect, but apparently it is happening almost everywhere.&lt;/p&gt;
&lt;p&gt;Education: People tend to …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;h2 id="theswimmers-body-illusion.--rolf-dobelli" style="color:#c9d9fb;"&gt;The Swimmers Body Illusion. - &lt;a href="http://www.dobelli.com/"&gt;Rolf Dobelli&lt;/a&gt;&lt;/h2&gt;
&lt;/blockquote&gt;
&lt;p&gt;Are swimmer's body good looking because of their constant swimming activities? Or do they excel in swimming because of their good physic? It is important not to confuse the cause with the effect, but apparently it is happening almost everywhere.&lt;/p&gt;
&lt;p&gt;Education: People tend to confuse hard work with smartness, although smartness tends to be more sought after than hard work. If you can't outsmart them, out work them. Not everyone is born with the same mental capacity to grasp concepts easily. Some people just need to hear it once, and that is all it takes for them to fully understand. Likewise, not everyone is able to commit and put it a lot of effort to understand something. Lets be real, we get a bit lazy sometimes. So we have to evaluate ourselves, how smart are we? How hardworking are we? It seems it's harder to improve your cognitive abilities to be "Smarter", therefore, if we are lacking in any areas, we can only put in hard work. Do not look at others in envy and say "Oh, he does not study yet his results are fantastic." Do not attempt to adopt his studying methods. Do attempt to replicate his schedule and life. All of his time management and choices were made to be suited for him, and not for you. Just as a swimmers body was made for swimming, and not the converse.&lt;/p&gt;
&lt;p&gt;Fitness: How we train affects how we look. The more we train and the harder we train, the better the results. But how our bodies are in turn affects how we must train. A skinny body should cut down on cardiovascular activities, and focus more on gaining mass. A bulky body should not be focusing on lifting heavy weights, but engage in cardiovascular exercises. There is no one-size-fit-all training regime, because all our sizes are different, and its impossible to see the the same results from each different body given the same training regime. Instead of studying how others train, seek to understand your own body first. Your structural imbalances ( hip anterior/posterior tilts), your weaknesses (legs, arms), your own body size (endo, meso, ecto), your lifestyle (working adult, sedentary, very active). The list is not exhaustive, and there are countless of other factors that will affect your gains. Only once your have understood your body, you have then obtained the question, and the next step is to seek the answer. Do not look at bodybuilders and follow their regime. Their job is to build their body for competitions, thus their lifestyle is intrinsically different from yours, unless of course you are a bodybuilder yourself. Seek for more attainable goals and answers. Find a training regime to suit your lifestyle. Some bodies and lives were made for a good physic, and not the other way around.&lt;/p&gt;
&lt;p&gt;For now I have only gave these two examples, for they dominate most of my life at the moment (I'm a student who workouts often). But just give it a thought and you will see how the Swimmers body illusion really affects many areas in life. Just to throw out a few more: Work, Character, Affluence, Family relations.&lt;/p&gt;
&lt;p&gt;I think the bottom line of this is that, we should stop following people. Their lives and circumstances are entirely different from ours. We have our own lives that we have to find out for ourselves how the puzzles fits. There is no singular perfect answer for all our problems. Just because they succeeded, does not mean you will. (The Survivors Bias)&lt;/p&gt;</content><category term="Life"></category><category term="Rolf Dobelli"></category><category term="Swimmers body Illusion"></category></entry><entry><title>A Conversation with my Professor</title><link href="/a-conversation-with-my-professor.html" rel="alternate"></link><published>2014-01-26T06:54:00+00:00</published><updated>2014-01-26T06:54:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2014-01-26:/a-conversation-with-my-professor.html</id><summary type="html">&lt;div dir="ltr"&gt;

Below is the email conversation between me and professor regard the realism and non-realism view on religion. Realism views that a person who subscribes to religion attributes his faith solely in a divine being, while non-realism attributes it to human experiences and human feelings that they would search for a …&lt;/div&gt;</summary><content type="html">&lt;div dir="ltr"&gt;

Below is the email conversation between me and professor regard the realism and non-realism view on religion. Realism views that a person who subscribes to religion attributes his faith solely in a divine being, while non-realism attributes it to human experiences and human feelings that they would search for a religion. I for one hold the non-realism view on religion. I thought it was interesting so I'm sharing it.

&lt;/div&gt;

&lt;div dir="ltr"&gt;

 

&lt;/div&gt;

&lt;div dir="ltr"&gt;

*Good day Professor Andres,*
&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*It was an interesting discussion we had today in the Faith and Reason seminar, although slightly more dense and harder to grasp then the previous seminar.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*I would like to extend the discussion on realism and non-realism school of thoughts as it strikes deeply with me and is the possible reason why I am in this course.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*I hold the non-realism view on religion and would attribute all religious persuasions to purely human experience, and that also religion is a product of human conciousness. *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*I draw reference to Daniel C. Dennett's essay "An Evolutionary Account of Religion", in which he states in the section "The Roots of Religion" last paragraph, that "At the root of human belief in gods lies an instinct on hair trigger: the disposition to attribute agency - beliefs and desires and other mental states - to anything complicated that moves ...". Here, I would think that the subject matter would be anything complicated, and that would encompass human consciousness, human anatomy, works of nature etc. Thus, it is because we as humans with our limited knowledge cannot comprehend the entire mechanics of the cosmos, and it being complicated, we therefore attribute some form of agency to it, which is God.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*In an argument made by Leonard Mlodinow in the book "Is God an Illusion?", it is argued that when Reductionist reaches a certain point in which they can no longer find any plausible explanations, religion takes the opportunity to step in. An example would be the breaking down of the atom to protons, to quarks, to gluons and finally to strings. When science is unable to explain what happens at the string level (aside from the unproven string theory), religion is then quick to fill in the shoes and explain this phenomenon through supernatural means.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*I thus propose that it is human experiences, be it the dissatisfaction in the inability to explain a complex system through logical means, or the feeling of fear of death and uncertainty, that would lead us to seek answers that science cannot explain, and religion insofar provides some of the "best" explanations. Religion is able to quell these uncertainties and fears by providing religious explanations, and since science cannot disprove it, it is mostly accepted. In fact, as an atheist who subscribes to Humanistic Naturalism, we too have a set of beliefs to quell these fears and uncertainties, just that in doing so, we employ a non-supernatural approach (drawing instead from human values, knowledge and morality). Thus being a Naturalist is no different as being a Christian, even if they both provide radically different teachings, as both provides a common sense of comfort and suppresses the fear and uncertainty that science and reason cannot explain. It is at essence human experiences that drives us to seek answers, and this leads us to accept different teachings.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Also, in the class we had this problem with the non-realist view, as a person (Agnes, in our class) was willing to give up her religion if and only if Christianity was proven to be undoubtedly wrong. However, I would argue that since Christianity is simply an outlet for quelling human fears/uncertainties (something which I find possible with Naturalism as well), if she were to give up Christianity, she would then find another school of teaching that has not yet been proven false to answer her questions and doubts. Since at its rudimentary level it is driven by human experiences, religion is only one of the possible cures for our existential ailments. Non-religious approaches can also be employed to tackle this problem, as evident from the growing number of atheist in the world (Third biggest "religion" just behind Christianity and Islam &lt;http://www.dailymail.co.uk/news/article-2250096/You-wouldnt-believe-atheism-worlds-biggest-faith-Christianity-Islam.html&gt;).*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Finally, we also had one problem on non-realism that the believe in God extends beyond human experiences. I would argue that once a person is satisfied with an answer religion provides in one area, they subscribe to it entirely (and not cherry-pick). I would then refer to the essay "Thinking About God" in the section "What is Philosophy on Religion?" where it mentions implications, and that "... if a person believes x, what other beliefs must she logically accept, whether she realizes it or not?". Thus for the case of Agnes, if she believes and accepts the answers that Christianity provides for her mortal dilemmas (x), she must then implicitly accept that God exists in order to provide the answers (y), and further accept God's historical account that stretches beyond the manifestation of human conciousness back to before the Big Bang(z). Thus through the concepts of implications we can solve this issue.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*In simple conclusion, I believe in the non-realist view on religion, and that all religious devotions and convictions can be traced back to a fundamental human experience fuelling it. Fear would be the most common human feeling which would persuade one to subscribe to religion.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Apologies for the long letter and I appreciate your time spent in reading and trying to make sense of my argument (if any). I would wholeheartedly accept any counter arguments you provide and study them with due diligence.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Your ever curious student in Religion,*

&lt;/div&gt;

&lt;div&gt;

*Chan Jin Hao*

&lt;/div&gt;

&lt;/div&gt;

&lt;div dir="ltr"&gt;

 

&lt;/div&gt;

&lt;div dir="ltr"&gt;

*\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_*

&lt;/div&gt;

&lt;div dir="ltr"&gt;

*Dear Jin Hao, *
&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*These are very thoughtful comments. I love it! *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*I would encourage you to review the distinction between religious realism and religious nonrealism. The difference between the two views is not that religious nonrealism says religious beliefs are "products of human consciousness," while realism denies this. The two views conflict over the question of what religious beliefs are about. Religious realists think that religious beliefs are, in part, about an independently existing supernatural reality. Religious nonrealists deny this, and insist that religious beliefs are only about human experience.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Agnes said that she would abandon her faith if it were proven that there is no supernatural being called 'God' who pre-existed humankind, who created the universe, and who is all-knowing, all-powerful, and perfectly good. She said that she would abandon her faith, because she sincerely believes that this supernatural being exists, and if it turned out that God didn't exist, she would have no reason to continue believing in God. This suggests that Agnes's belief in God is really about an independently existing supernatural being, and not just about her experience. If Agnes's belief were really just about her own human experience, then her reason for having that belief wouldn't be extinguished by the discovery that God doesn't exist; instead her reason for believing in God would remain intact, provided that the belief continued to relate to her experience in the right way. *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*You may be right that if Agnes did one day abandon her belief in God, she would adopt a different set of beliefs to relieve her "existential ailments." But that doesn't show that her belief in God wasn't about a supernatural entity: the belief could serve the function of alleviating her existential ailments, while at the same time being about a supernatural entity. This is entirely compatible with religious realism. *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Like you, I think some hypothesis similar to Dennett's explanation of why people have religious beliefs is probably correct. This explanation is compatible with religious realism. I think religious nonrealism confuses the causes of a belief and the content of that belief. Experiences of dependence and vulnerability may cause a person to believe in God. But the content of that belief is something else--the content of the belief in God is WHAT is believed. And as Agnes freely told us, WHAT she believes is that there exists a supernatural entity called 'God.' The difference between the cause of a belief and its content is brilliantly explained by Roger Trigg in his "Defense of Religious Realism." *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Incidentally, the survey you mentioned doesn't say that atheism is the third largest "faith." Rather, the category is people who have no religious affiliation. They may include atheists, agnostics, people who have no opinion on spiritual matters, and people who have spiritual beliefs (like a belief in God) but don't identify themselves as members of any established religion. *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*On another topic, I disagree that human values, knowledge, and morality cannot be explained by reason and science. I think science is part of our knowledge, and a product of our capacity for reason. Knowledge of values and morality can also be attained through reason. *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Moreover, I even think questions of morality can be answered through scientific analysis. If you wish to watch it, here is a nice TED talk by Sam Harris that defends a view very similar to mine: &lt;http://www.ted.com/talks/sam_harris_science_can_show_what_s_right.html&gt; *

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Thanks for your note, I enjoyed reading it very much.*

&lt;/div&gt;

&lt;div&gt;

* *

&lt;/div&gt;

&lt;div&gt;

*Best,*

&lt;/div&gt;

&lt;div&gt;

*Andres Luco*

&lt;/div&gt;

&lt;/div&gt;

&lt;div&gt;

&gt; &lt;div dir="ltr"&gt;
&gt;
&gt;  
&gt;
&gt; &lt;/div&gt;

&lt;/div&gt;</content><category term="non-realism"></category><category term="philosophy"></category><category term="realism"></category><category term="religion"></category></entry><entry><title>A Theistic affair for an Atheist P.1</title><link href="/a-theistic-affair-for-an-atheist-p-1.html" rel="alternate"></link><published>2014-01-20T13:26:00+00:00</published><updated>2014-01-20T13:26:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2014-01-20:/a-theistic-affair-for-an-atheist-p-1.html</id><summary type="html">&lt;p&gt;My interest in religion has always been immensely vast. I've always been asking questions about the meaning of life and what happens after death, and apparently religion is the ONLY outlet that (attempts) to answer these variants of question.&lt;/p&gt;
&lt;p&gt;I've been a Buddhist for quite some time, say around 18-20 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My interest in religion has always been immensely vast. I've always been asking questions about the meaning of life and what happens after death, and apparently religion is the ONLY outlet that (attempts) to answer these variants of question.&lt;/p&gt;
&lt;p&gt;I've been a Buddhist for quite some time, say around 18-20 years, but that was only by label. I did not really have any true conviction for Buddhism. And the reason I was a Buddhist was not because I found it interesting and picked it up, but rather it was forced upon me by my mother (Of which to this day I am furious about). I did learn a fair bit about Buddhism during those years. Concepts of Karma, reincarnation, the afterlife etc. But I guess you could attribute my sudden severance with the religion with a sudden onset of critical thinking. At some point in my life I think I "matured" mentally, and started realizing that life isn't all fun and games. There are real problems which will come my way sooner or later, and there are answers which I must actively seek and evaluate for myself. The road isn't paved for me, I must toil and create it.&lt;/p&gt;
&lt;p&gt;That questioning period was probably when I started to doubt Buddhism and it's teachings. It contained many mythological aspects to it that are present in other religions which would warrant me to be an unbeliever. I saw no distinct differences between Buddhism and other religions, which troubled me deeply. How can I proclaim my religion is true which dismissing the other religions, when at the heart of it all there is nothing I can put on the table to boost my credibility. And if I can't proclaim it to be true, I will not dedicate my life to something false. I must, however, give my respects to the teachings it has taught me. The Five Precepts; No killing, No stealing, No lying, No abuse of drugs, No sexual misconduct. And also the art of meditation, which has brought about tremendous benefits to me. But aside from that, I am an atheist.&lt;/p&gt;
&lt;p&gt;That was when I started reading books such as "Is God An Illusion" by Deepak Chopra and Leonard Mlodinow, discussing and debating about various real world issues. From there I learnt that religion still plays a very important role in today's society, and has its roots set deep into many minds of the masses, as much as I would like to ignore it from the stance of an atheist. I then went on to register for a module in my course named "Faith and Reason". It really should be named Religion and Logic based on the syllabus and the argumentative environment the course has adopted.&lt;/p&gt;
&lt;p&gt;So while chatting with my friend Matthias, who happens to be a very staunch Christian, I show and complained to him about the absurd amount of money I forked out to buy the textbook for the module. I also showed him the other book "Is God An Illusion" to him, to which he invited me to his church. I responded politely with a 5 second video of me shaking my head (Snapchatting). After which he messaged me: "At least experience both sides of the argument.". That sentence really struck me deep, as I realized how selfish and at the same time elitist about my atheistic persuasion I was. I had to give them a chance. They had as much a conviction to God as I had to the absence of it/him/her. And so I made arrangements with him and I was due to arrive at the church on Sunday, 19/1/2014.&lt;/p&gt;
&lt;p&gt;I was supposed to meet him 10am at Potong Pasir, and when the day came, I woke up late. I had half the mind to tell him that "I would not be able to make it", but then my inner soul made me add "in time" to the end of the excuse.&lt;/p&gt;</content><category term="Atheist"></category><category term="Christianity"></category><category term="Chruch"></category></entry><entry><title>About</title><link href="/about.html" rel="alternate"></link><published>2014-01-18T08:01:00+00:00</published><updated>2014-01-18T08:01:00+00:00</updated><author><name>jinhaochan</name></author><id>tag:None,2014-01-18:/about.html</id><summary type="html">&lt;p&gt;This is an example of a page. Unlike posts, which are displayed on your blog’s front page in the order they’re published, pages are better suited for more timeless content that you want to be easily accessible, like your About or Contact information. Click the Edit link to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is an example of a page. Unlike posts, which are displayed on your blog’s front page in the order they’re published, pages are better suited for more timeless content that you want to be easily accessible, like your About or Contact information. Click the Edit link to make changes to this page or &lt;a href="/wp-admin/post-new.php?post_type=page" title="Direct link to Add New in the Admin Dashboard"&gt;add another page&lt;/a&gt;.&lt;/p&gt;</content></entry></feed>